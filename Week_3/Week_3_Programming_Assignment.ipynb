{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "coursera": {
      "course_slug": "tensor-flow-2-1",
      "graded_item_id": "mtZ4n",
      "launcher_item_id": "WphgK"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Week 3 Programming Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Crtnb3v_-QN8",
        "colab_type": "text"
      },
      "source": [
        "# Programming Assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5lhOgL2-QN9",
        "colab_type": "text"
      },
      "source": [
        "## Model validation on the Iris dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mu5pYMU-QN-",
        "colab_type": "text"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "In this notebook, you will build, compile and fit a neural network model to the Iris dataset. You will also implement validation, regularisation and callbacks to improve your model.\n",
        "\n",
        "Some code cells are provided you in the notebook. You should avoid editing provided code, and make sure to execute the cells in order to avoid unexpected errors. Some cells begin with the line: \n",
        "\n",
        "`#### GRADED CELL ####`\n",
        "\n",
        "Don't move or edit this first line - this is what the automatic grader looks for to recognise graded cells. These cells require you to write your own code to complete them, and are automatically graded when you submit the notebook. Don't edit the function name or signature provided in these cells, otherwise the automatic grader might not function properly. Inside these graded cells, you can use any functions or classes that are imported below, but make sure you don't use any variables that are outside the scope of the function.\n",
        "\n",
        "### How to submit\n",
        "\n",
        "Complete all the tasks you are asked for in the worksheet. When you have finished and are happy with your code, press the **Submit Assignment** button at the top of this notebook.\n",
        "\n",
        "### Let's get started!\n",
        "\n",
        "We'll start running some imports, and loading the dataset. Do not edit the existing imports in the following cell. If you would like to make further Tensorflow imports, you should add them here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcJ88o-A-QOA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### PACKAGE IMPORTS ####\n",
        "\n",
        "# Run this cell first to import all required packages. Do not make any imports elsewhere in the notebook\n",
        "from numpy.random import seed\n",
        "seed(8)\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets, model_selection \n",
        "%matplotlib inline\n",
        "\n",
        "# If you would like to make further imports from tensorflow, add them here\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVxBqpU_-QOF",
        "colab_type": "text"
      },
      "source": [
        "#### The Iris dataset\n",
        "\n",
        "In this assignment, you will use the [Iris dataset](https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html). It consists of 50 samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters. For a reference, see the following papers:\n",
        "\n",
        "- R. A. Fisher. \"The use of multiple measurements in taxonomic problems\". Annals of Eugenics. 7 (2): 179â€“188, 1936.\n",
        "\n",
        "Your goal is to construct a neural network that classifies each sample into the correct class, as well as applying validation and regularisation techniques."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcDc7CXG-QOG",
        "colab_type": "text"
      },
      "source": [
        "#### Load and preprocess the data\n",
        "\n",
        "First read in the Iris dataset using `datasets.load_iris()`, and split the dataset into training and test sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QCdzIiC-QOH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### GRADED CELL ####\n",
        "\n",
        "# Complete the following function. \n",
        "# Make sure to not change the function name or arguments.\n",
        "\n",
        "def read_in_and_split_data(iris_data):\n",
        "    \"\"\"\n",
        "    This function takes the Iris dataset as loaded by sklearn.datasets.load_iris(), and then \n",
        "    splits so that the training set includes 90% of the full dataset, with the test set \n",
        "    making up the remaining 10%.\n",
        "    Your function should return a tuple (train_data, test_data, train_targets, test_targets) \n",
        "    of appropriately split training and test data and targets.\n",
        "    \n",
        "    If you would like to import any further packages to aid you in this task, please do so in the \n",
        "    Package Imports cell above.\n",
        "    \"\"\"\n",
        "    data = iris_data['data']\n",
        "    targets = iris_data['target']\n",
        "    train_data, test_data, train_targets, test_targets = train_test_split(data, targets, test_size = 0.1)\n",
        "    return (train_data, test_data, train_targets, test_targets)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVTDnj1W-QOJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run your function to generate the test and training data.\n",
        "\n",
        "iris_data = datasets.load_iris()\n",
        "train_data, test_data, train_targets, test_targets = read_in_and_split_data(iris_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7i_TGqos-QON",
        "colab_type": "text"
      },
      "source": [
        "We will now convert the training and test targets using a one hot encoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uolvGsLl-QOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert targets to a one-hot encoding\n",
        "\n",
        "train_targets = tf.keras.utils.to_categorical(np.array(train_targets))\n",
        "test_targets = tf.keras.utils.to_categorical(np.array(test_targets))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6i8xjbh-QOR",
        "colab_type": "text"
      },
      "source": [
        "#### Build the neural network model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDQeTk4u-QOT",
        "colab_type": "text"
      },
      "source": [
        "You can now construct a model to fit to the data. Using the Sequential API, build your model according to the following specifications:\n",
        "\n",
        "* The model should use the `input_shape` in the function argument to set the input size in the first layer.\n",
        "* The first layer should be a dense layer with 64 units.\n",
        "* The weights of the first layer should be initialised with the He uniform initializer.\n",
        "* The biases of the first layer should be all initially equal to one.\n",
        "* There should then be a further four dense layers, each with 128 units.\n",
        "* This should be followed with four dense layers, each with 64 units.\n",
        "* All of these Dense layers should use the ReLU activation function.\n",
        "* The output Dense layer should have 3 units and the softmax activation function.\n",
        "\n",
        "In total, the network should have 10 layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOCmCe2l-QOU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### GRADED CELL ####\n",
        "\n",
        "# Complete the following function. \n",
        "# Make sure to not change the function name or arguments.\n",
        "\n",
        "def get_model(input_shape):\n",
        "    \"\"\"\n",
        "    This function should build a Sequential model according to the above specification. Ensure the \n",
        "    weights are initialised by providing the input_shape argument in the first layer, given by the\n",
        "    function argument.\n",
        "    Your function should return the model.\n",
        "    \"\"\"\n",
        "    model = Sequential([\n",
        "                        Dense(64, activation = 'relu', kernel_initializer = 'he_uniform', bias_initializer = 'ones', input_shape = input_shape),\n",
        "                        Dense(128, activation = 'relu'),\n",
        "                        Dense(128, activation = 'relu'),\n",
        "                        Dense(128, activation = 'relu'),\n",
        "                        Dense(128, activation = 'relu'),\n",
        "                        Dense(64, activation = 'relu'),\n",
        "                        Dense(64, activation = 'relu'),\n",
        "                        Dense(64, activation = 'relu'),\n",
        "                        Dense(64, activation = 'relu'),\n",
        "                        Dense(3, activation = 'softmax')\n",
        "    ])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEnEugVV-QOX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run your function to get the model\n",
        "\n",
        "model = get_model(train_data[0].shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BC0h-ud1-QOa",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "#### Compile the model\n",
        "\n",
        "You should now compile the model using the `compile` method. Remember that you need to specify an optimizer, a loss function and a metric to judge the performance of your model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReHF4llc-QOa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### GRADED CELL ####\n",
        "\n",
        "# Complete the following function. \n",
        "# Make sure to not change the function name or arguments.\n",
        "\n",
        "def compile_model(model):\n",
        "    \"\"\"\n",
        "    This function takes in the model returned from your get_model function, and compiles it with an optimiser,\n",
        "    loss function and metric.\n",
        "    Compile the model using the Adam optimiser (with learning rate set to 0.0001), \n",
        "    the categorical crossentropy loss function and accuracy as the only metric. \n",
        "    Your function doesn't need to return anything; the model will be compiled in-place.\n",
        "    \"\"\"\n",
        "    model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0001), loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qJOJunW-QOd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run your function to compile the model\n",
        "\n",
        "compile_model(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWxL16Hk-QOh",
        "colab_type": "text"
      },
      "source": [
        "#### Fit the model to the training data\n",
        "\n",
        "Now you should train the model on the Iris dataset, using the model's `fit` method. \n",
        "* Run the training for a fixed number of epochs, given by the function's `epochs` argument.\n",
        "* Return the training history to be used for plotting the learning curves.\n",
        "* Set the batch size to 40.\n",
        "* Set the validation set to be 15% of the training set.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYTwJVXq-QOi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### GRADED CELL ####\n",
        "\n",
        "# Complete the following function. \n",
        "# Make sure to not change the function name or arguments.\n",
        "\n",
        "def train_model(model, train_data, train_targets, epochs):\n",
        "    \"\"\"\n",
        "    This function should train the model for the given number of epochs on the \n",
        "    train_data and train_targets. \n",
        "    Your function should return the training history, as returned by model.fit.\n",
        "    \"\"\"\n",
        "    history = model.fit(train_data, train_targets, epochs = epochs, batch_size = 40, validation_split = 0.15)\n",
        "    return history\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOE4iz_w-QOl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "351b7d70-d7d9-46ad-9b84-36c815539673"
      },
      "source": [
        "# Run your function to train the model\n",
        "\n",
        "history = train_model(model, train_data, train_targets, epochs=800)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/800\n",
            "3/3 [==============================] - 0s 75ms/step - loss: 1.1515 - accuracy: 0.3509 - val_loss: 1.1801 - val_accuracy: 0.1905\n",
            "Epoch 2/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.0871 - accuracy: 0.3509 - val_loss: 1.1341 - val_accuracy: 0.1905\n",
            "Epoch 3/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 1.0498 - accuracy: 0.3509 - val_loss: 1.0983 - val_accuracy: 0.1905\n",
            "Epoch 4/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.0196 - accuracy: 0.3509 - val_loss: 1.0734 - val_accuracy: 0.1905\n",
            "Epoch 5/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.9962 - accuracy: 0.3509 - val_loss: 1.0530 - val_accuracy: 0.1905\n",
            "Epoch 6/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.9685 - accuracy: 0.3509 - val_loss: 1.0283 - val_accuracy: 0.2381\n",
            "Epoch 7/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.9397 - accuracy: 0.3860 - val_loss: 1.0063 - val_accuracy: 0.2381\n",
            "Epoch 8/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.9123 - accuracy: 0.4649 - val_loss: 0.9846 - val_accuracy: 0.2857\n",
            "Epoch 9/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.8843 - accuracy: 0.6140 - val_loss: 0.9600 - val_accuracy: 0.5238\n",
            "Epoch 10/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.8545 - accuracy: 0.6667 - val_loss: 0.9338 - val_accuracy: 0.6667\n",
            "Epoch 11/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.8225 - accuracy: 0.7807 - val_loss: 0.9050 - val_accuracy: 0.7619\n",
            "Epoch 12/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.7920 - accuracy: 0.8860 - val_loss: 0.8766 - val_accuracy: 0.8095\n",
            "Epoch 13/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.7601 - accuracy: 0.9123 - val_loss: 0.8477 - val_accuracy: 0.9048\n",
            "Epoch 14/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.7276 - accuracy: 0.9298 - val_loss: 0.8164 - val_accuracy: 0.9048\n",
            "Epoch 15/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.6969 - accuracy: 0.9386 - val_loss: 0.7866 - val_accuracy: 0.8571\n",
            "Epoch 16/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.6663 - accuracy: 0.9561 - val_loss: 0.7589 - val_accuracy: 0.8571\n",
            "Epoch 17/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.6384 - accuracy: 0.9649 - val_loss: 0.7352 - val_accuracy: 0.8571\n",
            "Epoch 18/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.6121 - accuracy: 0.9649 - val_loss: 0.7113 - val_accuracy: 0.8571\n",
            "Epoch 19/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.5859 - accuracy: 0.9649 - val_loss: 0.6867 - val_accuracy: 0.9048\n",
            "Epoch 20/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.5626 - accuracy: 0.9386 - val_loss: 0.6615 - val_accuracy: 0.9524\n",
            "Epoch 21/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.5378 - accuracy: 0.9649 - val_loss: 0.6350 - val_accuracy: 0.9048\n",
            "Epoch 22/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.5147 - accuracy: 0.9737 - val_loss: 0.6090 - val_accuracy: 0.9048\n",
            "Epoch 23/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.4892 - accuracy: 0.9649 - val_loss: 0.5851 - val_accuracy: 0.9524\n",
            "Epoch 24/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.4671 - accuracy: 0.9386 - val_loss: 0.5594 - val_accuracy: 0.9524\n",
            "Epoch 25/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.4418 - accuracy: 0.9386 - val_loss: 0.5282 - val_accuracy: 0.9048\n",
            "Epoch 26/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.4156 - accuracy: 0.9825 - val_loss: 0.5008 - val_accuracy: 0.9048\n",
            "Epoch 27/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.3946 - accuracy: 0.9737 - val_loss: 0.4727 - val_accuracy: 0.9048\n",
            "Epoch 28/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.3694 - accuracy: 0.9649 - val_loss: 0.4500 - val_accuracy: 0.9524\n",
            "Epoch 29/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.3512 - accuracy: 0.9474 - val_loss: 0.4225 - val_accuracy: 0.9524\n",
            "Epoch 30/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.3251 - accuracy: 0.9649 - val_loss: 0.3989 - val_accuracy: 0.9048\n",
            "Epoch 31/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.3067 - accuracy: 0.9649 - val_loss: 0.3762 - val_accuracy: 0.9524\n",
            "Epoch 32/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.2881 - accuracy: 0.9561 - val_loss: 0.3577 - val_accuracy: 0.9048\n",
            "Epoch 33/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.2699 - accuracy: 0.9825 - val_loss: 0.3371 - val_accuracy: 0.9524\n",
            "Epoch 34/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.2549 - accuracy: 0.9386 - val_loss: 0.3214 - val_accuracy: 0.9524\n",
            "Epoch 35/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.2412 - accuracy: 0.9561 - val_loss: 0.3069 - val_accuracy: 0.9048\n",
            "Epoch 36/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.2232 - accuracy: 0.9649 - val_loss: 0.2944 - val_accuracy: 0.9048\n",
            "Epoch 37/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.2104 - accuracy: 0.9825 - val_loss: 0.2797 - val_accuracy: 0.9048\n",
            "Epoch 38/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1980 - accuracy: 0.9649 - val_loss: 0.2683 - val_accuracy: 0.9048\n",
            "Epoch 39/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1864 - accuracy: 0.9649 - val_loss: 0.2564 - val_accuracy: 0.9524\n",
            "Epoch 40/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1755 - accuracy: 0.9649 - val_loss: 0.2508 - val_accuracy: 0.9048\n",
            "Epoch 41/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1668 - accuracy: 0.9649 - val_loss: 0.2446 - val_accuracy: 0.9048\n",
            "Epoch 42/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.1576 - accuracy: 0.9825 - val_loss: 0.2395 - val_accuracy: 0.9048\n",
            "Epoch 43/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.1520 - accuracy: 0.9649 - val_loss: 0.2269 - val_accuracy: 0.9524\n",
            "Epoch 44/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.1490 - accuracy: 0.9561 - val_loss: 0.2361 - val_accuracy: 0.9048\n",
            "Epoch 45/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.1351 - accuracy: 0.9825 - val_loss: 0.2204 - val_accuracy: 0.9048\n",
            "Epoch 46/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.1318 - accuracy: 0.9561 - val_loss: 0.2093 - val_accuracy: 0.9524\n",
            "Epoch 47/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.1257 - accuracy: 0.9561 - val_loss: 0.2234 - val_accuracy: 0.9048\n",
            "Epoch 48/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1217 - accuracy: 0.9825 - val_loss: 0.2237 - val_accuracy: 0.9048\n",
            "Epoch 49/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1144 - accuracy: 0.9825 - val_loss: 0.2155 - val_accuracy: 0.9048\n",
            "Epoch 50/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1091 - accuracy: 0.9737 - val_loss: 0.2065 - val_accuracy: 0.9524\n",
            "Epoch 51/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1078 - accuracy: 0.9737 - val_loss: 0.2031 - val_accuracy: 0.9524\n",
            "Epoch 52/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.1021 - accuracy: 0.9737 - val_loss: 0.2181 - val_accuracy: 0.9048\n",
            "Epoch 53/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.1008 - accuracy: 0.9825 - val_loss: 0.2281 - val_accuracy: 0.9048\n",
            "Epoch 54/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0979 - accuracy: 0.9737 - val_loss: 0.2002 - val_accuracy: 0.9524\n",
            "Epoch 55/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0936 - accuracy: 0.9737 - val_loss: 0.2047 - val_accuracy: 0.9524\n",
            "Epoch 56/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0907 - accuracy: 0.9825 - val_loss: 0.2180 - val_accuracy: 0.9048\n",
            "Epoch 57/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0887 - accuracy: 0.9825 - val_loss: 0.2091 - val_accuracy: 0.9048\n",
            "Epoch 58/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0890 - accuracy: 0.9649 - val_loss: 0.2054 - val_accuracy: 0.9524\n",
            "Epoch 59/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0809 - accuracy: 0.9737 - val_loss: 0.2293 - val_accuracy: 0.9048\n",
            "Epoch 60/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0849 - accuracy: 0.9825 - val_loss: 0.2306 - val_accuracy: 0.9048\n",
            "Epoch 61/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0774 - accuracy: 0.9825 - val_loss: 0.1959 - val_accuracy: 0.9524\n",
            "Epoch 62/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0831 - accuracy: 0.9649 - val_loss: 0.1943 - val_accuracy: 0.9524\n",
            "Epoch 63/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0774 - accuracy: 0.9649 - val_loss: 0.2419 - val_accuracy: 0.9048\n",
            "Epoch 64/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0777 - accuracy: 0.9825 - val_loss: 0.2230 - val_accuracy: 0.9048\n",
            "Epoch 65/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0737 - accuracy: 0.9737 - val_loss: 0.1973 - val_accuracy: 0.9524\n",
            "Epoch 66/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0781 - accuracy: 0.9737 - val_loss: 0.2244 - val_accuracy: 0.9048\n",
            "Epoch 67/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0682 - accuracy: 0.9825 - val_loss: 0.2078 - val_accuracy: 0.9524\n",
            "Epoch 68/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0680 - accuracy: 0.9825 - val_loss: 0.2040 - val_accuracy: 0.9524\n",
            "Epoch 69/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0663 - accuracy: 0.9825 - val_loss: 0.2228 - val_accuracy: 0.9524\n",
            "Epoch 70/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0681 - accuracy: 0.9825 - val_loss: 0.2302 - val_accuracy: 0.9048\n",
            "Epoch 71/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0641 - accuracy: 0.9825 - val_loss: 0.2040 - val_accuracy: 0.9524\n",
            "Epoch 72/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0692 - accuracy: 0.9825 - val_loss: 0.1929 - val_accuracy: 0.9524\n",
            "Epoch 73/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0608 - accuracy: 0.9737 - val_loss: 0.2368 - val_accuracy: 0.9048\n",
            "Epoch 74/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0660 - accuracy: 0.9825 - val_loss: 0.2608 - val_accuracy: 0.9048\n",
            "Epoch 75/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0620 - accuracy: 0.9825 - val_loss: 0.2122 - val_accuracy: 0.9524\n",
            "Epoch 76/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0728 - accuracy: 0.9649 - val_loss: 0.1881 - val_accuracy: 0.9524\n",
            "Epoch 77/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0612 - accuracy: 0.9825 - val_loss: 0.2493 - val_accuracy: 0.9048\n",
            "Epoch 78/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0725 - accuracy: 0.9825 - val_loss: 0.2583 - val_accuracy: 0.9048\n",
            "Epoch 79/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0558 - accuracy: 0.9912 - val_loss: 0.1941 - val_accuracy: 0.9524\n",
            "Epoch 80/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0681 - accuracy: 0.9649 - val_loss: 0.2026 - val_accuracy: 0.9524\n",
            "Epoch 81/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0517 - accuracy: 0.9825 - val_loss: 0.2475 - val_accuracy: 0.9048\n",
            "Epoch 82/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0563 - accuracy: 0.9825 - val_loss: 0.2503 - val_accuracy: 0.9048\n",
            "Epoch 83/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0583 - accuracy: 0.9825 - val_loss: 0.2414 - val_accuracy: 0.9524\n",
            "Epoch 84/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0534 - accuracy: 0.9825 - val_loss: 0.2064 - val_accuracy: 0.9524\n",
            "Epoch 85/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0549 - accuracy: 0.9825 - val_loss: 0.2173 - val_accuracy: 0.9524\n",
            "Epoch 86/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0503 - accuracy: 0.9912 - val_loss: 0.2591 - val_accuracy: 0.9048\n",
            "Epoch 87/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0544 - accuracy: 0.9825 - val_loss: 0.2383 - val_accuracy: 0.9524\n",
            "Epoch 88/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0494 - accuracy: 0.9825 - val_loss: 0.2208 - val_accuracy: 0.9524\n",
            "Epoch 89/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0494 - accuracy: 0.9825 - val_loss: 0.2245 - val_accuracy: 0.9524\n",
            "Epoch 90/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0475 - accuracy: 0.9912 - val_loss: 0.2352 - val_accuracy: 0.9524\n",
            "Epoch 91/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0494 - accuracy: 0.9825 - val_loss: 0.2497 - val_accuracy: 0.9524\n",
            "Epoch 92/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0481 - accuracy: 0.9825 - val_loss: 0.2194 - val_accuracy: 0.9524\n",
            "Epoch 93/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0481 - accuracy: 0.9912 - val_loss: 0.2224 - val_accuracy: 0.9524\n",
            "Epoch 94/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0466 - accuracy: 0.9825 - val_loss: 0.2489 - val_accuracy: 0.9524\n",
            "Epoch 95/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0459 - accuracy: 0.9825 - val_loss: 0.2442 - val_accuracy: 0.9524\n",
            "Epoch 96/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0431 - accuracy: 0.9825 - val_loss: 0.2284 - val_accuracy: 0.9524\n",
            "Epoch 97/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0464 - accuracy: 0.9825 - val_loss: 0.2230 - val_accuracy: 0.9524\n",
            "Epoch 98/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0453 - accuracy: 0.9825 - val_loss: 0.2540 - val_accuracy: 0.9524\n",
            "Epoch 99/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0446 - accuracy: 0.9825 - val_loss: 0.2415 - val_accuracy: 0.9524\n",
            "Epoch 100/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0414 - accuracy: 0.9912 - val_loss: 0.2227 - val_accuracy: 0.9524\n",
            "Epoch 101/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0465 - accuracy: 0.9737 - val_loss: 0.2448 - val_accuracy: 0.9524\n",
            "Epoch 102/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0425 - accuracy: 0.9912 - val_loss: 0.2320 - val_accuracy: 0.9524\n",
            "Epoch 103/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0408 - accuracy: 0.9912 - val_loss: 0.2541 - val_accuracy: 0.9524\n",
            "Epoch 104/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0443 - accuracy: 0.9825 - val_loss: 0.2565 - val_accuracy: 0.9524\n",
            "Epoch 105/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0466 - accuracy: 0.9825 - val_loss: 0.2176 - val_accuracy: 0.9524\n",
            "Epoch 106/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0410 - accuracy: 0.9912 - val_loss: 0.2478 - val_accuracy: 0.9524\n",
            "Epoch 107/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0539 - accuracy: 0.9825 - val_loss: 0.2770 - val_accuracy: 0.9524\n",
            "Epoch 108/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0508 - accuracy: 0.9737 - val_loss: 0.2179 - val_accuracy: 0.9524\n",
            "Epoch 109/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0478 - accuracy: 0.9825 - val_loss: 0.2494 - val_accuracy: 0.9524\n",
            "Epoch 110/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0395 - accuracy: 0.9825 - val_loss: 0.2388 - val_accuracy: 0.9524\n",
            "Epoch 111/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0367 - accuracy: 0.9912 - val_loss: 0.2525 - val_accuracy: 0.9524\n",
            "Epoch 112/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0400 - accuracy: 0.9825 - val_loss: 0.2637 - val_accuracy: 0.9524\n",
            "Epoch 113/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0404 - accuracy: 0.9912 - val_loss: 0.2351 - val_accuracy: 0.9524\n",
            "Epoch 114/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0366 - accuracy: 0.9912 - val_loss: 0.2461 - val_accuracy: 0.9524\n",
            "Epoch 115/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0350 - accuracy: 0.9825 - val_loss: 0.2632 - val_accuracy: 0.9524\n",
            "Epoch 116/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0365 - accuracy: 0.9825 - val_loss: 0.2648 - val_accuracy: 0.9524\n",
            "Epoch 117/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0348 - accuracy: 0.9825 - val_loss: 0.2457 - val_accuracy: 0.9524\n",
            "Epoch 118/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0420 - accuracy: 0.9825 - val_loss: 0.2390 - val_accuracy: 0.9524\n",
            "Epoch 119/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0342 - accuracy: 0.9825 - val_loss: 0.2864 - val_accuracy: 0.9524\n",
            "Epoch 120/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0399 - accuracy: 0.9825 - val_loss: 0.2823 - val_accuracy: 0.9524\n",
            "Epoch 121/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0422 - accuracy: 0.9825 - val_loss: 0.2338 - val_accuracy: 0.9524\n",
            "Epoch 122/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0361 - accuracy: 0.9825 - val_loss: 0.2574 - val_accuracy: 0.9524\n",
            "Epoch 123/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0327 - accuracy: 0.9912 - val_loss: 0.2681 - val_accuracy: 0.9524\n",
            "Epoch 124/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0344 - accuracy: 0.9825 - val_loss: 0.2598 - val_accuracy: 0.9524\n",
            "Epoch 125/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0336 - accuracy: 0.9825 - val_loss: 0.2670 - val_accuracy: 0.9524\n",
            "Epoch 126/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0320 - accuracy: 0.9825 - val_loss: 0.2616 - val_accuracy: 0.9524\n",
            "Epoch 127/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0326 - accuracy: 0.9912 - val_loss: 0.2469 - val_accuracy: 0.9524\n",
            "Epoch 128/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0316 - accuracy: 0.9912 - val_loss: 0.2630 - val_accuracy: 0.9524\n",
            "Epoch 129/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0323 - accuracy: 0.9825 - val_loss: 0.2690 - val_accuracy: 0.9524\n",
            "Epoch 130/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0308 - accuracy: 0.9825 - val_loss: 0.2649 - val_accuracy: 0.9524\n",
            "Epoch 131/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0305 - accuracy: 0.9912 - val_loss: 0.2571 - val_accuracy: 0.9524\n",
            "Epoch 132/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0303 - accuracy: 0.9912 - val_loss: 0.2628 - val_accuracy: 0.9524\n",
            "Epoch 133/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0294 - accuracy: 0.9825 - val_loss: 0.2726 - val_accuracy: 0.9524\n",
            "Epoch 134/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0302 - accuracy: 0.9825 - val_loss: 0.2699 - val_accuracy: 0.9524\n",
            "Epoch 135/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0295 - accuracy: 0.9825 - val_loss: 0.2592 - val_accuracy: 0.9524\n",
            "Epoch 136/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0315 - accuracy: 0.9912 - val_loss: 0.2596 - val_accuracy: 0.9524\n",
            "Epoch 137/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0316 - accuracy: 0.9825 - val_loss: 0.2846 - val_accuracy: 0.9524\n",
            "Epoch 138/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0332 - accuracy: 0.9825 - val_loss: 0.2755 - val_accuracy: 0.9524\n",
            "Epoch 139/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0331 - accuracy: 0.9912 - val_loss: 0.2343 - val_accuracy: 0.9524\n",
            "Epoch 140/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0398 - accuracy: 0.9825 - val_loss: 0.2741 - val_accuracy: 0.9524\n",
            "Epoch 141/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0286 - accuracy: 0.9825 - val_loss: 0.2776 - val_accuracy: 0.9524\n",
            "Epoch 142/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0299 - accuracy: 0.9825 - val_loss: 0.2757 - val_accuracy: 0.9524\n",
            "Epoch 143/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0287 - accuracy: 0.9825 - val_loss: 0.2460 - val_accuracy: 0.9524\n",
            "Epoch 144/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0309 - accuracy: 0.9912 - val_loss: 0.2634 - val_accuracy: 0.9524\n",
            "Epoch 145/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0276 - accuracy: 0.9825 - val_loss: 0.2927 - val_accuracy: 0.9524\n",
            "Epoch 146/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0368 - accuracy: 0.9825 - val_loss: 0.2924 - val_accuracy: 0.9524\n",
            "Epoch 147/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0279 - accuracy: 0.9825 - val_loss: 0.2414 - val_accuracy: 0.9524\n",
            "Epoch 148/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0341 - accuracy: 0.9825 - val_loss: 0.2585 - val_accuracy: 0.9524\n",
            "Epoch 149/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0292 - accuracy: 0.9912 - val_loss: 0.2910 - val_accuracy: 0.9524\n",
            "Epoch 150/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0283 - accuracy: 0.9825 - val_loss: 0.2737 - val_accuracy: 0.9524\n",
            "Epoch 151/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0266 - accuracy: 0.9912 - val_loss: 0.2629 - val_accuracy: 0.9524\n",
            "Epoch 152/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 0.2729 - val_accuracy: 0.9524\n",
            "Epoch 153/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0255 - accuracy: 0.9912 - val_loss: 0.2814 - val_accuracy: 0.9524\n",
            "Epoch 154/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0260 - accuracy: 0.9825 - val_loss: 0.2756 - val_accuracy: 0.9524\n",
            "Epoch 155/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0252 - accuracy: 0.9912 - val_loss: 0.2762 - val_accuracy: 0.9524\n",
            "Epoch 156/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 0.2711 - val_accuracy: 0.9524\n",
            "Epoch 157/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0258 - accuracy: 0.9825 - val_loss: 0.2841 - val_accuracy: 0.9524\n",
            "Epoch 158/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0259 - accuracy: 0.9825 - val_loss: 0.2794 - val_accuracy: 0.9524\n",
            "Epoch 159/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 0.2581 - val_accuracy: 0.9524\n",
            "Epoch 160/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 0.2714 - val_accuracy: 0.9524\n",
            "Epoch 161/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 0.2841 - val_accuracy: 0.9524\n",
            "Epoch 162/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0267 - accuracy: 0.9825 - val_loss: 0.2859 - val_accuracy: 0.9524\n",
            "Epoch 163/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0246 - accuracy: 0.9912 - val_loss: 0.2731 - val_accuracy: 0.9524\n",
            "Epoch 164/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0261 - accuracy: 1.0000 - val_loss: 0.2753 - val_accuracy: 0.9524\n",
            "Epoch 165/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 0.2793 - val_accuracy: 0.9524\n",
            "Epoch 166/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0280 - accuracy: 0.9825 - val_loss: 0.3038 - val_accuracy: 0.9524\n",
            "Epoch 167/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0245 - accuracy: 0.9825 - val_loss: 0.2775 - val_accuracy: 0.9524\n",
            "Epoch 168/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0454 - accuracy: 0.9912 - val_loss: 0.2569 - val_accuracy: 0.9524\n",
            "Epoch 169/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.3391 - val_accuracy: 0.9524\n",
            "Epoch 170/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0515 - accuracy: 0.9825 - val_loss: 0.3346 - val_accuracy: 0.9524\n",
            "Epoch 171/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0427 - accuracy: 0.9825 - val_loss: 0.2517 - val_accuracy: 0.9524\n",
            "Epoch 172/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0375 - accuracy: 0.9825 - val_loss: 0.2609 - val_accuracy: 0.9524\n",
            "Epoch 173/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0385 - accuracy: 0.9912 - val_loss: 0.3484 - val_accuracy: 0.9524\n",
            "Epoch 174/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0430 - accuracy: 0.9825 - val_loss: 0.3206 - val_accuracy: 0.9524\n",
            "Epoch 175/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0286 - accuracy: 0.9825 - val_loss: 0.2549 - val_accuracy: 0.9524\n",
            "Epoch 176/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0291 - accuracy: 0.9912 - val_loss: 0.2670 - val_accuracy: 0.9524\n",
            "Epoch 177/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0264 - accuracy: 0.9912 - val_loss: 0.2945 - val_accuracy: 0.9524\n",
            "Epoch 178/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0235 - accuracy: 0.9825 - val_loss: 0.2894 - val_accuracy: 0.9524\n",
            "Epoch 179/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.2712 - val_accuracy: 0.9524\n",
            "Epoch 180/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 0.2727 - val_accuracy: 0.9524\n",
            "Epoch 181/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.2940 - val_accuracy: 0.9524\n",
            "Epoch 182/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0303 - accuracy: 0.9825 - val_loss: 0.3126 - val_accuracy: 0.9524\n",
            "Epoch 183/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0221 - accuracy: 0.9912 - val_loss: 0.2709 - val_accuracy: 0.9524\n",
            "Epoch 184/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0307 - accuracy: 0.9825 - val_loss: 0.2662 - val_accuracy: 0.9524\n",
            "Epoch 185/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0232 - accuracy: 0.9912 - val_loss: 0.3166 - val_accuracy: 0.9524\n",
            "Epoch 186/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0268 - accuracy: 0.9825 - val_loss: 0.3048 - val_accuracy: 0.9524\n",
            "Epoch 187/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0219 - accuracy: 0.9825 - val_loss: 0.2874 - val_accuracy: 0.9524\n",
            "Epoch 188/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.2642 - val_accuracy: 0.9524\n",
            "Epoch 189/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0270 - accuracy: 0.9912 - val_loss: 0.2819 - val_accuracy: 0.9524\n",
            "Epoch 190/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0214 - accuracy: 0.9912 - val_loss: 0.3117 - val_accuracy: 0.9524\n",
            "Epoch 191/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0245 - accuracy: 0.9825 - val_loss: 0.2924 - val_accuracy: 0.9524\n",
            "Epoch 192/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0200 - accuracy: 0.9912 - val_loss: 0.2850 - val_accuracy: 0.9524\n",
            "Epoch 193/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.2801 - val_accuracy: 0.9524\n",
            "Epoch 194/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 0.2797 - val_accuracy: 0.9524\n",
            "Epoch 195/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.2953 - val_accuracy: 0.9524\n",
            "Epoch 196/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0204 - accuracy: 0.9912 - val_loss: 0.3080 - val_accuracy: 0.9524\n",
            "Epoch 197/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0220 - accuracy: 0.9825 - val_loss: 0.2951 - val_accuracy: 0.9524\n",
            "Epoch 198/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.2749 - val_accuracy: 0.9524\n",
            "Epoch 199/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 0.2908 - val_accuracy: 0.9524\n",
            "Epoch 200/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.2917 - val_accuracy: 0.9524\n",
            "Epoch 201/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.2916 - val_accuracy: 0.9524\n",
            "Epoch 202/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.2879 - val_accuracy: 0.9524\n",
            "Epoch 203/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.2996 - val_accuracy: 0.9524\n",
            "Epoch 204/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.2975 - val_accuracy: 0.9524\n",
            "Epoch 205/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.2895 - val_accuracy: 0.9524\n",
            "Epoch 206/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.2906 - val_accuracy: 0.9524\n",
            "Epoch 207/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.2981 - val_accuracy: 0.9524\n",
            "Epoch 208/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.2908 - val_accuracy: 0.9524\n",
            "Epoch 209/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.3027 - val_accuracy: 0.9524\n",
            "Epoch 210/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0197 - accuracy: 0.9912 - val_loss: 0.3049 - val_accuracy: 0.9524\n",
            "Epoch 211/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.2878 - val_accuracy: 0.9524\n",
            "Epoch 212/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.2858 - val_accuracy: 0.9524\n",
            "Epoch 213/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.3129 - val_accuracy: 0.9524\n",
            "Epoch 214/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0217 - accuracy: 0.9825 - val_loss: 0.3134 - val_accuracy: 0.9524\n",
            "Epoch 215/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.2916 - val_accuracy: 0.9524\n",
            "Epoch 216/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.2868 - val_accuracy: 0.9524\n",
            "Epoch 217/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.3099 - val_accuracy: 0.9524\n",
            "Epoch 218/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.3142 - val_accuracy: 0.9524\n",
            "Epoch 219/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0183 - accuracy: 0.9912 - val_loss: 0.3008 - val_accuracy: 0.9524\n",
            "Epoch 220/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.2968 - val_accuracy: 0.9524\n",
            "Epoch 221/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.3086 - val_accuracy: 0.9524\n",
            "Epoch 222/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.3136 - val_accuracy: 0.9524\n",
            "Epoch 223/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.3001 - val_accuracy: 0.9524\n",
            "Epoch 224/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.3017 - val_accuracy: 0.9524\n",
            "Epoch 225/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.3124 - val_accuracy: 0.9524\n",
            "Epoch 226/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.3025 - val_accuracy: 0.9524\n",
            "Epoch 227/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.2979 - val_accuracy: 0.9524\n",
            "Epoch 228/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.3149 - val_accuracy: 0.9524\n",
            "Epoch 229/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.3114 - val_accuracy: 0.9524\n",
            "Epoch 230/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.3116 - val_accuracy: 0.9524\n",
            "Epoch 231/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.3086 - val_accuracy: 0.9524\n",
            "Epoch 232/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.3081 - val_accuracy: 0.9524\n",
            "Epoch 233/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.3025 - val_accuracy: 0.9524\n",
            "Epoch 234/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.3061 - val_accuracy: 0.9524\n",
            "Epoch 235/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.3190 - val_accuracy: 0.9524\n",
            "Epoch 236/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.3009 - val_accuracy: 0.9524\n",
            "Epoch 237/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.3188 - val_accuracy: 0.9524\n",
            "Epoch 238/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.3219 - val_accuracy: 0.9524\n",
            "Epoch 239/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.3142 - val_accuracy: 0.9524\n",
            "Epoch 240/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.3086 - val_accuracy: 0.9524\n",
            "Epoch 241/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.3133 - val_accuracy: 0.9524\n",
            "Epoch 242/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.3144 - val_accuracy: 0.9524\n",
            "Epoch 243/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.3117 - val_accuracy: 0.9524\n",
            "Epoch 244/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.3192 - val_accuracy: 0.9524\n",
            "Epoch 245/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.3256 - val_accuracy: 0.9524\n",
            "Epoch 246/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.3096 - val_accuracy: 0.9524\n",
            "Epoch 247/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.3166 - val_accuracy: 0.9524\n",
            "Epoch 248/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.3250 - val_accuracy: 0.9524\n",
            "Epoch 249/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.3234 - val_accuracy: 0.9524\n",
            "Epoch 250/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.3128 - val_accuracy: 0.9524\n",
            "Epoch 251/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.3196 - val_accuracy: 0.9524\n",
            "Epoch 252/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.3196 - val_accuracy: 0.9524\n",
            "Epoch 253/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.3249 - val_accuracy: 0.9524\n",
            "Epoch 254/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0143 - accuracy: 0.9912 - val_loss: 0.3361 - val_accuracy: 0.9524\n",
            "Epoch 255/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.3168 - val_accuracy: 0.9524\n",
            "Epoch 256/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.3211 - val_accuracy: 0.9524\n",
            "Epoch 257/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0219 - accuracy: 0.9825 - val_loss: 0.3420 - val_accuracy: 0.9524\n",
            "Epoch 258/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.3093 - val_accuracy: 0.9048\n",
            "Epoch 259/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.3239 - val_accuracy: 0.9524\n",
            "Epoch 260/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.3380 - val_accuracy: 0.9524\n",
            "Epoch 261/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0164 - accuracy: 0.9912 - val_loss: 0.3428 - val_accuracy: 0.9524\n",
            "Epoch 262/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.3156 - val_accuracy: 0.9524\n",
            "Epoch 263/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0225 - accuracy: 0.9912 - val_loss: 0.3186 - val_accuracy: 0.9524\n",
            "Epoch 264/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0138 - accuracy: 0.9912 - val_loss: 0.3515 - val_accuracy: 0.9524\n",
            "Epoch 265/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0159 - accuracy: 0.9825 - val_loss: 0.3363 - val_accuracy: 0.9524\n",
            "Epoch 266/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.3077 - val_accuracy: 0.9048\n",
            "Epoch 267/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0209 - accuracy: 0.9912 - val_loss: 0.3322 - val_accuracy: 0.9524\n",
            "Epoch 268/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0148 - accuracy: 0.9825 - val_loss: 0.3493 - val_accuracy: 0.9524\n",
            "Epoch 269/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0155 - accuracy: 0.9912 - val_loss: 0.3266 - val_accuracy: 0.9524\n",
            "Epoch 270/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.3230 - val_accuracy: 0.9524\n",
            "Epoch 271/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.3348 - val_accuracy: 0.9524\n",
            "Epoch 272/800\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.3463 - val_accuracy: 0.9524\n",
            "Epoch 273/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.3339 - val_accuracy: 0.9524\n",
            "Epoch 274/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.3238 - val_accuracy: 0.9524\n",
            "Epoch 275/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.3437 - val_accuracy: 0.9524\n",
            "Epoch 276/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0169 - accuracy: 0.9825 - val_loss: 0.3453 - val_accuracy: 0.9524\n",
            "Epoch 277/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.3207 - val_accuracy: 0.9048\n",
            "Epoch 278/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.3521 - val_accuracy: 0.9524\n",
            "Epoch 279/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0236 - accuracy: 0.9825 - val_loss: 0.3566 - val_accuracy: 0.9524\n",
            "Epoch 280/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.3176 - val_accuracy: 0.9048\n",
            "Epoch 281/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0212 - accuracy: 0.9912 - val_loss: 0.3280 - val_accuracy: 0.9524\n",
            "Epoch 282/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.3585 - val_accuracy: 0.9524\n",
            "Epoch 283/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0143 - accuracy: 0.9912 - val_loss: 0.3416 - val_accuracy: 0.9524\n",
            "Epoch 284/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.3301 - val_accuracy: 0.9524\n",
            "Epoch 285/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.3388 - val_accuracy: 0.9524\n",
            "Epoch 286/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.3484 - val_accuracy: 0.9524\n",
            "Epoch 287/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0138 - accuracy: 0.9912 - val_loss: 0.3480 - val_accuracy: 0.9524\n",
            "Epoch 288/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.3296 - val_accuracy: 0.9048\n",
            "Epoch 289/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.3415 - val_accuracy: 0.9524\n",
            "Epoch 290/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.3621 - val_accuracy: 0.9524\n",
            "Epoch 291/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0153 - accuracy: 0.9825 - val_loss: 0.3489 - val_accuracy: 0.9524\n",
            "Epoch 292/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.3277 - val_accuracy: 0.9048\n",
            "Epoch 293/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.3481 - val_accuracy: 0.9524\n",
            "Epoch 294/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0145 - accuracy: 0.9912 - val_loss: 0.3609 - val_accuracy: 0.9524\n",
            "Epoch 295/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.3365 - val_accuracy: 0.9524\n",
            "Epoch 296/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.3352 - val_accuracy: 0.9048\n",
            "Epoch 297/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.3576 - val_accuracy: 0.9524\n",
            "Epoch 298/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.3486 - val_accuracy: 0.9524\n",
            "Epoch 299/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.3349 - val_accuracy: 0.9048\n",
            "Epoch 300/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.3575 - val_accuracy: 0.9524\n",
            "Epoch 301/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0167 - accuracy: 0.9825 - val_loss: 0.3624 - val_accuracy: 0.9524\n",
            "Epoch 302/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.3395 - val_accuracy: 0.9048\n",
            "Epoch 303/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.3413 - val_accuracy: 0.9048\n",
            "Epoch 304/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.3657 - val_accuracy: 0.9524\n",
            "Epoch 305/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0133 - accuracy: 0.9912 - val_loss: 0.3608 - val_accuracy: 0.9524\n",
            "Epoch 306/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.3396 - val_accuracy: 0.9048\n",
            "Epoch 307/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.3498 - val_accuracy: 0.9524\n",
            "Epoch 308/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.3680 - val_accuracy: 0.9524\n",
            "Epoch 309/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0132 - accuracy: 0.9912 - val_loss: 0.3640 - val_accuracy: 0.9524\n",
            "Epoch 310/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.3475 - val_accuracy: 0.9524\n",
            "Epoch 311/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.3433 - val_accuracy: 0.9048\n",
            "Epoch 312/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.3547 - val_accuracy: 0.9524\n",
            "Epoch 313/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.3657 - val_accuracy: 0.9524\n",
            "Epoch 314/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.3482 - val_accuracy: 0.9048\n",
            "Epoch 315/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.3478 - val_accuracy: 0.9048\n",
            "Epoch 316/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.3608 - val_accuracy: 0.9524\n",
            "Epoch 317/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.3662 - val_accuracy: 0.9524\n",
            "Epoch 318/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.3557 - val_accuracy: 0.9524\n",
            "Epoch 319/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.3550 - val_accuracy: 0.9524\n",
            "Epoch 320/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.3584 - val_accuracy: 0.9524\n",
            "Epoch 321/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.3613 - val_accuracy: 0.9524\n",
            "Epoch 322/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.3613 - val_accuracy: 0.9524\n",
            "Epoch 323/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.3566 - val_accuracy: 0.9524\n",
            "Epoch 324/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.3621 - val_accuracy: 0.9524\n",
            "Epoch 325/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.3635 - val_accuracy: 0.9524\n",
            "Epoch 326/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.3633 - val_accuracy: 0.9524\n",
            "Epoch 327/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.3557 - val_accuracy: 0.9048\n",
            "Epoch 328/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.3702 - val_accuracy: 0.9524\n",
            "Epoch 329/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.3673 - val_accuracy: 0.9524\n",
            "Epoch 330/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.3641 - val_accuracy: 0.9524\n",
            "Epoch 331/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.3629 - val_accuracy: 0.9524\n",
            "Epoch 332/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.3688 - val_accuracy: 0.9524\n",
            "Epoch 333/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.3726 - val_accuracy: 0.9524\n",
            "Epoch 334/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.3623 - val_accuracy: 0.9048\n",
            "Epoch 335/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.3664 - val_accuracy: 0.9524\n",
            "Epoch 336/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.3679 - val_accuracy: 0.9524\n",
            "Epoch 337/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.3665 - val_accuracy: 0.9524\n",
            "Epoch 338/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.3726 - val_accuracy: 0.9524\n",
            "Epoch 339/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.3723 - val_accuracy: 0.9524\n",
            "Epoch 340/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.3694 - val_accuracy: 0.9524\n",
            "Epoch 341/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.3719 - val_accuracy: 0.9524\n",
            "Epoch 342/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.3724 - val_accuracy: 0.9524\n",
            "Epoch 343/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.3781 - val_accuracy: 0.9524\n",
            "Epoch 344/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.3775 - val_accuracy: 0.9524\n",
            "Epoch 345/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.3757 - val_accuracy: 0.9524\n",
            "Epoch 346/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.3765 - val_accuracy: 0.9524\n",
            "Epoch 347/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.3751 - val_accuracy: 0.9524\n",
            "Epoch 348/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.3792 - val_accuracy: 0.9524\n",
            "Epoch 349/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.3774 - val_accuracy: 0.9524\n",
            "Epoch 350/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.3770 - val_accuracy: 0.9524\n",
            "Epoch 351/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.3810 - val_accuracy: 0.9524\n",
            "Epoch 352/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.3824 - val_accuracy: 0.9524\n",
            "Epoch 353/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.3814 - val_accuracy: 0.9524\n",
            "Epoch 354/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.3834 - val_accuracy: 0.9524\n",
            "Epoch 355/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.3859 - val_accuracy: 0.9524\n",
            "Epoch 356/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.3809 - val_accuracy: 0.9048\n",
            "Epoch 357/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.3863 - val_accuracy: 0.9524\n",
            "Epoch 358/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.3893 - val_accuracy: 0.9524\n",
            "Epoch 359/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.3819 - val_accuracy: 0.9048\n",
            "Epoch 360/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.3862 - val_accuracy: 0.9524\n",
            "Epoch 361/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.3962 - val_accuracy: 0.9524\n",
            "Epoch 362/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.3891 - val_accuracy: 0.9524\n",
            "Epoch 363/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.3895 - val_accuracy: 0.9524\n",
            "Epoch 364/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.3957 - val_accuracy: 0.9524\n",
            "Epoch 365/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.3945 - val_accuracy: 0.9524\n",
            "Epoch 366/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.3903 - val_accuracy: 0.9048\n",
            "Epoch 367/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.3924 - val_accuracy: 0.9524\n",
            "Epoch 368/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.3987 - val_accuracy: 0.9524\n",
            "Epoch 369/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.3939 - val_accuracy: 0.9524\n",
            "Epoch 370/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.3938 - val_accuracy: 0.9048\n",
            "Epoch 371/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.3981 - val_accuracy: 0.9524\n",
            "Epoch 372/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.3975 - val_accuracy: 0.9524\n",
            "Epoch 373/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.3956 - val_accuracy: 0.9048\n",
            "Epoch 374/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.3975 - val_accuracy: 0.9524\n",
            "Epoch 375/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.3989 - val_accuracy: 0.9524\n",
            "Epoch 376/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.4022 - val_accuracy: 0.9524\n",
            "Epoch 377/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.3999 - val_accuracy: 0.9524\n",
            "Epoch 378/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.3994 - val_accuracy: 0.9048\n",
            "Epoch 379/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.4010 - val_accuracy: 0.9524\n",
            "Epoch 380/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.4013 - val_accuracy: 0.9524\n",
            "Epoch 381/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.4053 - val_accuracy: 0.9524\n",
            "Epoch 382/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.4047 - val_accuracy: 0.9524\n",
            "Epoch 383/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.4035 - val_accuracy: 0.9524\n",
            "Epoch 384/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.4041 - val_accuracy: 0.9524\n",
            "Epoch 385/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.4065 - val_accuracy: 0.9524\n",
            "Epoch 386/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.4066 - val_accuracy: 0.9524\n",
            "Epoch 387/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.4075 - val_accuracy: 0.9524\n",
            "Epoch 388/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.4068 - val_accuracy: 0.9048\n",
            "Epoch 389/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.4084 - val_accuracy: 0.9524\n",
            "Epoch 390/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.4120 - val_accuracy: 0.9524\n",
            "Epoch 391/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.4103 - val_accuracy: 0.9524\n",
            "Epoch 392/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.4097 - val_accuracy: 0.9048\n",
            "Epoch 393/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.4104 - val_accuracy: 0.9048\n",
            "Epoch 394/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.4125 - val_accuracy: 0.9524\n",
            "Epoch 395/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.4129 - val_accuracy: 0.9524\n",
            "Epoch 396/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.4131 - val_accuracy: 0.9048\n",
            "Epoch 397/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.4141 - val_accuracy: 0.9524\n",
            "Epoch 398/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.4163 - val_accuracy: 0.9524\n",
            "Epoch 399/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.4156 - val_accuracy: 0.9048\n",
            "Epoch 400/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.4165 - val_accuracy: 0.9524\n",
            "Epoch 401/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.4173 - val_accuracy: 0.9524\n",
            "Epoch 402/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.4167 - val_accuracy: 0.9524\n",
            "Epoch 403/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.4174 - val_accuracy: 0.9524\n",
            "Epoch 404/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.4194 - val_accuracy: 0.9524\n",
            "Epoch 405/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.4194 - val_accuracy: 0.9524\n",
            "Epoch 406/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.4195 - val_accuracy: 0.9524\n",
            "Epoch 407/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.4205 - val_accuracy: 0.9524\n",
            "Epoch 408/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.4212 - val_accuracy: 0.9524\n",
            "Epoch 409/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.4224 - val_accuracy: 0.9524\n",
            "Epoch 410/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.4226 - val_accuracy: 0.9524\n",
            "Epoch 411/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.4232 - val_accuracy: 0.9524\n",
            "Epoch 412/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.4238 - val_accuracy: 0.9524\n",
            "Epoch 413/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.4245 - val_accuracy: 0.9524\n",
            "Epoch 414/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.4251 - val_accuracy: 0.9524\n",
            "Epoch 415/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.4289 - val_accuracy: 0.9524\n",
            "Epoch 416/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.4266 - val_accuracy: 0.9524\n",
            "Epoch 417/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.4272 - val_accuracy: 0.9048\n",
            "Epoch 418/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.4278 - val_accuracy: 0.9048\n",
            "Epoch 419/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.4326 - val_accuracy: 0.9524\n",
            "Epoch 420/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.4293 - val_accuracy: 0.9524\n",
            "Epoch 421/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.4300 - val_accuracy: 0.9524\n",
            "Epoch 422/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.4310 - val_accuracy: 0.9524\n",
            "Epoch 423/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.4314 - val_accuracy: 0.9524\n",
            "Epoch 424/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.4325 - val_accuracy: 0.9524\n",
            "Epoch 425/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.4328 - val_accuracy: 0.9524\n",
            "Epoch 426/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.4339 - val_accuracy: 0.9524\n",
            "Epoch 427/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.4341 - val_accuracy: 0.9524\n",
            "Epoch 428/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.4348 - val_accuracy: 0.9524\n",
            "Epoch 429/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.4356 - val_accuracy: 0.9524\n",
            "Epoch 430/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.4367 - val_accuracy: 0.9524\n",
            "Epoch 431/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.4376 - val_accuracy: 0.9524\n",
            "Epoch 432/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.4386 - val_accuracy: 0.9048\n",
            "Epoch 433/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.4388 - val_accuracy: 0.9524\n",
            "Epoch 434/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.4396 - val_accuracy: 0.9524\n",
            "Epoch 435/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.4415 - val_accuracy: 0.9524\n",
            "Epoch 436/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.4424 - val_accuracy: 0.9048\n",
            "Epoch 437/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.4421 - val_accuracy: 0.9524\n",
            "Epoch 438/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4432 - val_accuracy: 0.9524\n",
            "Epoch 439/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.4450 - val_accuracy: 0.9524\n",
            "Epoch 440/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.4447 - val_accuracy: 0.9524\n",
            "Epoch 441/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.4460 - val_accuracy: 0.9048\n",
            "Epoch 442/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.4469 - val_accuracy: 0.9524\n",
            "Epoch 443/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.4473 - val_accuracy: 0.9524\n",
            "Epoch 444/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4480 - val_accuracy: 0.9048\n",
            "Epoch 445/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.4489 - val_accuracy: 0.9048\n",
            "Epoch 446/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.4506 - val_accuracy: 0.9524\n",
            "Epoch 447/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.4499 - val_accuracy: 0.9524\n",
            "Epoch 448/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4516 - val_accuracy: 0.9048\n",
            "Epoch 449/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4510 - val_accuracy: 0.9524\n",
            "Epoch 450/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4526 - val_accuracy: 0.9524\n",
            "Epoch 451/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.4524 - val_accuracy: 0.9524\n",
            "Epoch 452/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4537 - val_accuracy: 0.9048\n",
            "Epoch 453/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4548 - val_accuracy: 0.9048\n",
            "Epoch 454/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4544 - val_accuracy: 0.9524\n",
            "Epoch 455/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4553 - val_accuracy: 0.9524\n",
            "Epoch 456/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4559 - val_accuracy: 0.9524\n",
            "Epoch 457/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4578 - val_accuracy: 0.9048\n",
            "Epoch 458/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4569 - val_accuracy: 0.9524\n",
            "Epoch 459/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4582 - val_accuracy: 0.9524\n",
            "Epoch 460/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4583 - val_accuracy: 0.9524\n",
            "Epoch 461/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4645 - val_accuracy: 0.9048\n",
            "Epoch 462/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.4603 - val_accuracy: 0.9048\n",
            "Epoch 463/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.4624 - val_accuracy: 0.9524\n",
            "Epoch 464/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.4613 - val_accuracy: 0.9524\n",
            "Epoch 465/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4659 - val_accuracy: 0.9048\n",
            "Epoch 466/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.4640 - val_accuracy: 0.9048\n",
            "Epoch 467/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4633 - val_accuracy: 0.9524\n",
            "Epoch 468/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4636 - val_accuracy: 0.9524\n",
            "Epoch 469/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4643 - val_accuracy: 0.9524\n",
            "Epoch 470/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4649 - val_accuracy: 0.9524\n",
            "Epoch 471/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4671 - val_accuracy: 0.9048\n",
            "Epoch 472/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4666 - val_accuracy: 0.9048\n",
            "Epoch 473/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4667 - val_accuracy: 0.9524\n",
            "Epoch 474/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4673 - val_accuracy: 0.9524\n",
            "Epoch 475/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4683 - val_accuracy: 0.9524\n",
            "Epoch 476/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4690 - val_accuracy: 0.9524\n",
            "Epoch 477/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4690 - val_accuracy: 0.9524\n",
            "Epoch 478/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4699 - val_accuracy: 0.9524\n",
            "Epoch 479/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4717 - val_accuracy: 0.9048\n",
            "Epoch 480/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4709 - val_accuracy: 0.9524\n",
            "Epoch 481/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4717 - val_accuracy: 0.9524\n",
            "Epoch 482/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4726 - val_accuracy: 0.9524\n",
            "Epoch 483/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4769 - val_accuracy: 0.9048\n",
            "Epoch 484/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4733 - val_accuracy: 0.9524\n",
            "Epoch 485/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4738 - val_accuracy: 0.9524\n",
            "Epoch 486/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4748 - val_accuracy: 0.9524\n",
            "Epoch 487/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4760 - val_accuracy: 0.9048\n",
            "Epoch 488/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4761 - val_accuracy: 0.9524\n",
            "Epoch 489/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.4796 - val_accuracy: 0.9048\n",
            "Epoch 490/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4766 - val_accuracy: 0.9524\n",
            "Epoch 491/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4774 - val_accuracy: 0.9524\n",
            "Epoch 492/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4800 - val_accuracy: 0.9048\n",
            "Epoch 493/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4808 - val_accuracy: 0.9048\n",
            "Epoch 494/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4791 - val_accuracy: 0.9524\n",
            "Epoch 495/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4796 - val_accuracy: 0.9524\n",
            "Epoch 496/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4823 - val_accuracy: 0.9048\n",
            "Epoch 497/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4841 - val_accuracy: 0.9048\n",
            "Epoch 498/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4817 - val_accuracy: 0.9524\n",
            "Epoch 499/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4818 - val_accuracy: 0.9524\n",
            "Epoch 500/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4844 - val_accuracy: 0.9048\n",
            "Epoch 501/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4856 - val_accuracy: 0.9048\n",
            "Epoch 502/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4837 - val_accuracy: 0.9524\n",
            "Epoch 503/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4867 - val_accuracy: 0.9048\n",
            "Epoch 504/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4871 - val_accuracy: 0.9048\n",
            "Epoch 505/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4853 - val_accuracy: 0.9524\n",
            "Epoch 506/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4892 - val_accuracy: 0.9048\n",
            "Epoch 507/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4897 - val_accuracy: 0.9048\n",
            "Epoch 508/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4870 - val_accuracy: 0.9524\n",
            "Epoch 509/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4872 - val_accuracy: 0.9524\n",
            "Epoch 510/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4902 - val_accuracy: 0.9048\n",
            "Epoch 511/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4894 - val_accuracy: 0.9524\n",
            "Epoch 512/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4900 - val_accuracy: 0.9524\n",
            "Epoch 513/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4930 - val_accuracy: 0.9048\n",
            "Epoch 514/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4915 - val_accuracy: 0.9524\n",
            "Epoch 515/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4911 - val_accuracy: 0.9524\n",
            "Epoch 516/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4933 - val_accuracy: 0.9524\n",
            "Epoch 517/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4932 - val_accuracy: 0.9524\n",
            "Epoch 518/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4931 - val_accuracy: 0.9524\n",
            "Epoch 519/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4935 - val_accuracy: 0.9524\n",
            "Epoch 520/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4941 - val_accuracy: 0.9524\n",
            "Epoch 521/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4952 - val_accuracy: 0.9524\n",
            "Epoch 522/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4997 - val_accuracy: 0.9048\n",
            "Epoch 523/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4961 - val_accuracy: 0.9524\n",
            "Epoch 524/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4954 - val_accuracy: 0.9524\n",
            "Epoch 525/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4982 - val_accuracy: 0.9048\n",
            "Epoch 526/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5022 - val_accuracy: 0.9048\n",
            "Epoch 527/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4983 - val_accuracy: 0.9524\n",
            "Epoch 528/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4974 - val_accuracy: 0.9524\n",
            "Epoch 529/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4998 - val_accuracy: 0.9524\n",
            "Epoch 530/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5015 - val_accuracy: 0.9048\n",
            "Epoch 531/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5009 - val_accuracy: 0.9524\n",
            "Epoch 532/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5010 - val_accuracy: 0.9524\n",
            "Epoch 533/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5001 - val_accuracy: 0.9524\n",
            "Epoch 534/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5006 - val_accuracy: 0.9524\n",
            "Epoch 535/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5080 - val_accuracy: 0.9048\n",
            "Epoch 536/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5041 - val_accuracy: 0.9048\n",
            "Epoch 537/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5028 - val_accuracy: 0.9524\n",
            "Epoch 538/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5028 - val_accuracy: 0.9524\n",
            "Epoch 539/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5044 - val_accuracy: 0.9524\n",
            "Epoch 540/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5103 - val_accuracy: 0.9048\n",
            "Epoch 541/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5053 - val_accuracy: 0.9524\n",
            "Epoch 542/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5052 - val_accuracy: 0.9524\n",
            "Epoch 543/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5063 - val_accuracy: 0.9524\n",
            "Epoch 544/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5082 - val_accuracy: 0.9048\n",
            "Epoch 545/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5080 - val_accuracy: 0.9524\n",
            "Epoch 546/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5106 - val_accuracy: 0.9048\n",
            "Epoch 547/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5094 - val_accuracy: 0.9524\n",
            "Epoch 548/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5080 - val_accuracy: 0.9524\n",
            "Epoch 549/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5099 - val_accuracy: 0.9524\n",
            "Epoch 550/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5136 - val_accuracy: 0.9048\n",
            "Epoch 551/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5138 - val_accuracy: 0.9048\n",
            "Epoch 552/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5099 - val_accuracy: 0.9524\n",
            "Epoch 553/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5108 - val_accuracy: 0.9524\n",
            "Epoch 554/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5151 - val_accuracy: 0.9048\n",
            "Epoch 555/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5211 - val_accuracy: 0.9048\n",
            "Epoch 556/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5184 - val_accuracy: 0.9048\n",
            "Epoch 557/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5178 - val_accuracy: 0.9524\n",
            "Epoch 558/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5202 - val_accuracy: 0.9524\n",
            "Epoch 559/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5247 - val_accuracy: 0.9048\n",
            "Epoch 560/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5279 - val_accuracy: 0.9048\n",
            "Epoch 561/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 9.6551e-04 - accuracy: 1.0000 - val_loss: 0.5275 - val_accuracy: 0.9524\n",
            "Epoch 562/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 9.9058e-04 - accuracy: 1.0000 - val_loss: 0.5296 - val_accuracy: 0.9524\n",
            "Epoch 563/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5312 - val_accuracy: 0.9524\n",
            "Epoch 564/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 9.7386e-04 - accuracy: 1.0000 - val_loss: 0.5366 - val_accuracy: 0.9048\n",
            "Epoch 565/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 9.5064e-04 - accuracy: 1.0000 - val_loss: 0.5388 - val_accuracy: 0.9048\n",
            "Epoch 566/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 9.1398e-04 - accuracy: 1.0000 - val_loss: 0.5372 - val_accuracy: 0.9524\n",
            "Epoch 567/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5379 - val_accuracy: 0.9524\n",
            "Epoch 568/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 8.0257e-04 - accuracy: 1.0000 - val_loss: 0.5415 - val_accuracy: 0.9048\n",
            "Epoch 569/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 8.4983e-04 - accuracy: 1.0000 - val_loss: 0.5475 - val_accuracy: 0.9048\n",
            "Epoch 570/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5452 - val_accuracy: 0.9048\n",
            "Epoch 571/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 8.0891e-04 - accuracy: 1.0000 - val_loss: 0.5417 - val_accuracy: 0.9524\n",
            "Epoch 572/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 9.9814e-04 - accuracy: 1.0000 - val_loss: 0.5425 - val_accuracy: 0.9524\n",
            "Epoch 573/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 9.2532e-04 - accuracy: 1.0000 - val_loss: 0.5447 - val_accuracy: 0.9524\n",
            "Epoch 574/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 8.7489e-04 - accuracy: 1.0000 - val_loss: 0.5482 - val_accuracy: 0.9048\n",
            "Epoch 575/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 8.2426e-04 - accuracy: 1.0000 - val_loss: 0.5462 - val_accuracy: 0.9524\n",
            "Epoch 576/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 8.3384e-04 - accuracy: 1.0000 - val_loss: 0.5458 - val_accuracy: 0.9524\n",
            "Epoch 577/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 8.1986e-04 - accuracy: 1.0000 - val_loss: 0.5484 - val_accuracy: 0.9524\n",
            "Epoch 578/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 7.8077e-04 - accuracy: 1.0000 - val_loss: 0.5493 - val_accuracy: 0.9524\n",
            "Epoch 579/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 8.0899e-04 - accuracy: 1.0000 - val_loss: 0.5484 - val_accuracy: 0.9524\n",
            "Epoch 580/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 7.8161e-04 - accuracy: 1.0000 - val_loss: 0.5497 - val_accuracy: 0.9524\n",
            "Epoch 581/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 7.4800e-04 - accuracy: 1.0000 - val_loss: 0.5510 - val_accuracy: 0.9524\n",
            "Epoch 582/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 7.7967e-04 - accuracy: 1.0000 - val_loss: 0.5507 - val_accuracy: 0.9524\n",
            "Epoch 583/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 8.5224e-04 - accuracy: 1.0000 - val_loss: 0.5510 - val_accuracy: 0.9524\n",
            "Epoch 584/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 7.3874e-04 - accuracy: 1.0000 - val_loss: 0.5567 - val_accuracy: 0.9048\n",
            "Epoch 585/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 8.4272e-04 - accuracy: 1.0000 - val_loss: 0.5558 - val_accuracy: 0.9048\n",
            "Epoch 586/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 8.0823e-04 - accuracy: 1.0000 - val_loss: 0.5524 - val_accuracy: 0.9524\n",
            "Epoch 587/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 7.5049e-04 - accuracy: 1.0000 - val_loss: 0.5529 - val_accuracy: 0.9524\n",
            "Epoch 588/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 7.6401e-04 - accuracy: 1.0000 - val_loss: 0.5561 - val_accuracy: 0.9048\n",
            "Epoch 589/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 7.3369e-04 - accuracy: 1.0000 - val_loss: 0.5569 - val_accuracy: 0.9048\n",
            "Epoch 590/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 7.6902e-04 - accuracy: 1.0000 - val_loss: 0.5550 - val_accuracy: 0.9524\n",
            "Epoch 591/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 7.6033e-04 - accuracy: 1.0000 - val_loss: 0.5564 - val_accuracy: 0.9524\n",
            "Epoch 592/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.8804e-04 - accuracy: 1.0000 - val_loss: 0.5572 - val_accuracy: 0.9524\n",
            "Epoch 593/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 7.0775e-04 - accuracy: 1.0000 - val_loss: 0.5579 - val_accuracy: 0.9524\n",
            "Epoch 594/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 7.6893e-04 - accuracy: 1.0000 - val_loss: 0.5599 - val_accuracy: 0.9048\n",
            "Epoch 595/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.8035e-04 - accuracy: 1.0000 - val_loss: 0.5583 - val_accuracy: 0.9524\n",
            "Epoch 596/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 7.2172e-04 - accuracy: 1.0000 - val_loss: 0.5581 - val_accuracy: 0.9524\n",
            "Epoch 597/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 7.3904e-04 - accuracy: 1.0000 - val_loss: 0.5605 - val_accuracy: 0.9524\n",
            "Epoch 598/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 7.1753e-04 - accuracy: 1.0000 - val_loss: 0.5605 - val_accuracy: 0.9524\n",
            "Epoch 599/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.5744e-04 - accuracy: 1.0000 - val_loss: 0.5621 - val_accuracy: 0.9524\n",
            "Epoch 600/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 6.6591e-04 - accuracy: 1.0000 - val_loss: 0.5623 - val_accuracy: 0.9524\n",
            "Epoch 601/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.6404e-04 - accuracy: 1.0000 - val_loss: 0.5615 - val_accuracy: 0.9524\n",
            "Epoch 602/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.8836e-04 - accuracy: 1.0000 - val_loss: 0.5624 - val_accuracy: 0.9524\n",
            "Epoch 603/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 7.0436e-04 - accuracy: 1.0000 - val_loss: 0.5627 - val_accuracy: 0.9524\n",
            "Epoch 604/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.0996e-04 - accuracy: 1.0000 - val_loss: 0.5654 - val_accuracy: 0.9048\n",
            "Epoch 605/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.3793e-04 - accuracy: 1.0000 - val_loss: 0.5674 - val_accuracy: 0.9048\n",
            "Epoch 606/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 6.5294e-04 - accuracy: 1.0000 - val_loss: 0.5664 - val_accuracy: 0.9048\n",
            "Epoch 607/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.3902e-04 - accuracy: 1.0000 - val_loss: 0.5653 - val_accuracy: 0.9524\n",
            "Epoch 608/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.1366e-04 - accuracy: 1.0000 - val_loss: 0.5651 - val_accuracy: 0.9524\n",
            "Epoch 609/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.2027e-04 - accuracy: 1.0000 - val_loss: 0.5652 - val_accuracy: 0.9524\n",
            "Epoch 610/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 7.3515e-04 - accuracy: 1.0000 - val_loss: 0.5659 - val_accuracy: 0.9524\n",
            "Epoch 611/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.7184e-04 - accuracy: 1.0000 - val_loss: 0.5726 - val_accuracy: 0.9048\n",
            "Epoch 612/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.9305e-04 - accuracy: 1.0000 - val_loss: 0.5721 - val_accuracy: 0.9048\n",
            "Epoch 613/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.4339e-04 - accuracy: 1.0000 - val_loss: 0.5685 - val_accuracy: 0.9524\n",
            "Epoch 614/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.7777e-04 - accuracy: 1.0000 - val_loss: 0.5679 - val_accuracy: 0.9524\n",
            "Epoch 615/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.9548e-04 - accuracy: 1.0000 - val_loss: 0.5682 - val_accuracy: 0.9524\n",
            "Epoch 616/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.9748e-04 - accuracy: 1.0000 - val_loss: 0.5712 - val_accuracy: 0.9524\n",
            "Epoch 617/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.7888e-04 - accuracy: 1.0000 - val_loss: 0.5768 - val_accuracy: 0.9048\n",
            "Epoch 618/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.3665e-04 - accuracy: 1.0000 - val_loss: 0.5731 - val_accuracy: 0.9048\n",
            "Epoch 619/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.9505e-04 - accuracy: 1.0000 - val_loss: 0.5706 - val_accuracy: 0.9524\n",
            "Epoch 620/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 6.2313e-04 - accuracy: 1.0000 - val_loss: 0.5719 - val_accuracy: 0.9524\n",
            "Epoch 621/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 6.4253e-04 - accuracy: 1.0000 - val_loss: 0.5748 - val_accuracy: 0.9048\n",
            "Epoch 622/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.7762e-04 - accuracy: 1.0000 - val_loss: 0.5744 - val_accuracy: 0.9524\n",
            "Epoch 623/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 5.5187e-04 - accuracy: 1.0000 - val_loss: 0.5737 - val_accuracy: 0.9524\n",
            "Epoch 624/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.0582e-04 - accuracy: 1.0000 - val_loss: 0.5739 - val_accuracy: 0.9524\n",
            "Epoch 625/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.5107e-04 - accuracy: 1.0000 - val_loss: 0.5774 - val_accuracy: 0.9048\n",
            "Epoch 626/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.6819e-04 - accuracy: 1.0000 - val_loss: 0.5790 - val_accuracy: 0.9048\n",
            "Epoch 627/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.5442e-04 - accuracy: 1.0000 - val_loss: 0.5768 - val_accuracy: 0.9524\n",
            "Epoch 628/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 5.2172e-04 - accuracy: 1.0000 - val_loss: 0.5760 - val_accuracy: 0.9524\n",
            "Epoch 629/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 5.9526e-04 - accuracy: 1.0000 - val_loss: 0.5758 - val_accuracy: 0.9524\n",
            "Epoch 630/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 5.4964e-04 - accuracy: 1.0000 - val_loss: 0.5790 - val_accuracy: 0.9524\n",
            "Epoch 631/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 5.2682e-04 - accuracy: 1.0000 - val_loss: 0.5804 - val_accuracy: 0.9048\n",
            "Epoch 632/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.7552e-04 - accuracy: 1.0000 - val_loss: 0.5815 - val_accuracy: 0.9048\n",
            "Epoch 633/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.1057e-04 - accuracy: 1.0000 - val_loss: 0.5780 - val_accuracy: 0.9524\n",
            "Epoch 634/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 5.7117e-04 - accuracy: 1.0000 - val_loss: 0.5797 - val_accuracy: 0.9524\n",
            "Epoch 635/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 5.1948e-04 - accuracy: 1.0000 - val_loss: 0.5802 - val_accuracy: 0.9524\n",
            "Epoch 636/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.2582e-04 - accuracy: 1.0000 - val_loss: 0.5829 - val_accuracy: 0.9048\n",
            "Epoch 637/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.3409e-04 - accuracy: 1.0000 - val_loss: 0.5833 - val_accuracy: 0.9048\n",
            "Epoch 638/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.9360e-04 - accuracy: 1.0000 - val_loss: 0.5814 - val_accuracy: 0.9524\n",
            "Epoch 639/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 5.0948e-04 - accuracy: 1.0000 - val_loss: 0.5819 - val_accuracy: 0.9524\n",
            "Epoch 640/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.2192e-04 - accuracy: 1.0000 - val_loss: 0.5827 - val_accuracy: 0.9524\n",
            "Epoch 641/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.1946e-04 - accuracy: 1.0000 - val_loss: 0.5833 - val_accuracy: 0.9524\n",
            "Epoch 642/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.8724e-04 - accuracy: 1.0000 - val_loss: 0.5835 - val_accuracy: 0.9524\n",
            "Epoch 643/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.8948e-04 - accuracy: 1.0000 - val_loss: 0.5848 - val_accuracy: 0.9524\n",
            "Epoch 644/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 4.9357e-04 - accuracy: 1.0000 - val_loss: 0.5854 - val_accuracy: 0.9524\n",
            "Epoch 645/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.7546e-04 - accuracy: 1.0000 - val_loss: 0.5856 - val_accuracy: 0.9524\n",
            "Epoch 646/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.8084e-04 - accuracy: 1.0000 - val_loss: 0.5852 - val_accuracy: 0.9524\n",
            "Epoch 647/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 4.9247e-04 - accuracy: 1.0000 - val_loss: 0.5858 - val_accuracy: 0.9524\n",
            "Epoch 648/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 4.7349e-04 - accuracy: 1.0000 - val_loss: 0.5869 - val_accuracy: 0.9524\n",
            "Epoch 649/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 4.8434e-04 - accuracy: 1.0000 - val_loss: 0.5896 - val_accuracy: 0.9048\n",
            "Epoch 650/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.9313e-04 - accuracy: 1.0000 - val_loss: 0.5882 - val_accuracy: 0.9524\n",
            "Epoch 651/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 4.8717e-04 - accuracy: 1.0000 - val_loss: 0.5877 - val_accuracy: 0.9524\n",
            "Epoch 652/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 4.6080e-04 - accuracy: 1.0000 - val_loss: 0.5896 - val_accuracy: 0.9524\n",
            "Epoch 653/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 4.9202e-04 - accuracy: 1.0000 - val_loss: 0.5893 - val_accuracy: 0.9524\n",
            "Epoch 654/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 4.4360e-04 - accuracy: 1.0000 - val_loss: 0.5908 - val_accuracy: 0.9524\n",
            "Epoch 655/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 4.5501e-04 - accuracy: 1.0000 - val_loss: 0.5919 - val_accuracy: 0.9048\n",
            "Epoch 656/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.9112e-04 - accuracy: 1.0000 - val_loss: 0.5914 - val_accuracy: 0.9524\n",
            "Epoch 657/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.7826e-04 - accuracy: 1.0000 - val_loss: 0.5895 - val_accuracy: 0.9524\n",
            "Epoch 658/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 4.8246e-04 - accuracy: 1.0000 - val_loss: 0.5916 - val_accuracy: 0.9524\n",
            "Epoch 659/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.3951e-04 - accuracy: 1.0000 - val_loss: 0.5919 - val_accuracy: 0.9524\n",
            "Epoch 660/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 4.4825e-04 - accuracy: 1.0000 - val_loss: 0.5931 - val_accuracy: 0.9524\n",
            "Epoch 661/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 4.3830e-04 - accuracy: 1.0000 - val_loss: 0.5938 - val_accuracy: 0.9524\n",
            "Epoch 662/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 4.6398e-04 - accuracy: 1.0000 - val_loss: 0.5960 - val_accuracy: 0.9048\n",
            "Epoch 663/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.4897e-04 - accuracy: 1.0000 - val_loss: 0.5941 - val_accuracy: 0.9524\n",
            "Epoch 664/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.3260e-04 - accuracy: 1.0000 - val_loss: 0.5933 - val_accuracy: 0.9524\n",
            "Epoch 665/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.5288e-04 - accuracy: 1.0000 - val_loss: 0.5955 - val_accuracy: 0.9524\n",
            "Epoch 666/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.2495e-04 - accuracy: 1.0000 - val_loss: 0.5960 - val_accuracy: 0.9524\n",
            "Epoch 667/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 4.1452e-04 - accuracy: 1.0000 - val_loss: 0.5965 - val_accuracy: 0.9524\n",
            "Epoch 668/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 4.2594e-04 - accuracy: 1.0000 - val_loss: 0.5963 - val_accuracy: 0.9524\n",
            "Epoch 669/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 4.1955e-04 - accuracy: 1.0000 - val_loss: 0.5966 - val_accuracy: 0.9524\n",
            "Epoch 670/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.0376e-04 - accuracy: 1.0000 - val_loss: 0.5981 - val_accuracy: 0.9524\n",
            "Epoch 671/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.1803e-04 - accuracy: 1.0000 - val_loss: 0.5981 - val_accuracy: 0.9524\n",
            "Epoch 672/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.0347e-04 - accuracy: 1.0000 - val_loss: 0.5989 - val_accuracy: 0.9524\n",
            "Epoch 673/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.1349e-04 - accuracy: 1.0000 - val_loss: 0.5995 - val_accuracy: 0.9524\n",
            "Epoch 674/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.1926e-04 - accuracy: 1.0000 - val_loss: 0.5973 - val_accuracy: 0.9524\n",
            "Epoch 675/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.2896e-04 - accuracy: 1.0000 - val_loss: 0.6013 - val_accuracy: 0.9048\n",
            "Epoch 676/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.0015e-04 - accuracy: 1.0000 - val_loss: 0.6024 - val_accuracy: 0.9048\n",
            "Epoch 677/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 4.1315e-04 - accuracy: 1.0000 - val_loss: 0.6014 - val_accuracy: 0.9524\n",
            "Epoch 678/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.9384e-04 - accuracy: 1.0000 - val_loss: 0.6012 - val_accuracy: 0.9524\n",
            "Epoch 679/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.9445e-04 - accuracy: 1.0000 - val_loss: 0.6014 - val_accuracy: 0.9524\n",
            "Epoch 680/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.7952e-04 - accuracy: 1.0000 - val_loss: 0.6027 - val_accuracy: 0.9524\n",
            "Epoch 681/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.9051e-04 - accuracy: 1.0000 - val_loss: 0.6036 - val_accuracy: 0.9524\n",
            "Epoch 682/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.8421e-04 - accuracy: 1.0000 - val_loss: 0.6044 - val_accuracy: 0.9524\n",
            "Epoch 683/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.9489e-04 - accuracy: 1.0000 - val_loss: 0.6045 - val_accuracy: 0.9524\n",
            "Epoch 684/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.7340e-04 - accuracy: 1.0000 - val_loss: 0.6035 - val_accuracy: 0.9524\n",
            "Epoch 685/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.9342e-04 - accuracy: 1.0000 - val_loss: 0.6028 - val_accuracy: 0.9524\n",
            "Epoch 686/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 3.8204e-04 - accuracy: 1.0000 - val_loss: 0.6041 - val_accuracy: 0.9524\n",
            "Epoch 687/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.7535e-04 - accuracy: 1.0000 - val_loss: 0.6063 - val_accuracy: 0.9524\n",
            "Epoch 688/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.1607e-04 - accuracy: 1.0000 - val_loss: 0.6093 - val_accuracy: 0.9048\n",
            "Epoch 689/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.7547e-04 - accuracy: 1.0000 - val_loss: 0.6062 - val_accuracy: 0.9524\n",
            "Epoch 690/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.5362e-04 - accuracy: 1.0000 - val_loss: 0.6046 - val_accuracy: 0.9524\n",
            "Epoch 691/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.9253e-04 - accuracy: 1.0000 - val_loss: 0.6047 - val_accuracy: 0.9524\n",
            "Epoch 692/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.7315e-04 - accuracy: 1.0000 - val_loss: 0.6072 - val_accuracy: 0.9524\n",
            "Epoch 693/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.7801e-04 - accuracy: 1.0000 - val_loss: 0.6106 - val_accuracy: 0.9048\n",
            "Epoch 694/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.1615e-04 - accuracy: 1.0000 - val_loss: 0.6109 - val_accuracy: 0.9048\n",
            "Epoch 695/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.6006e-04 - accuracy: 1.0000 - val_loss: 0.6068 - val_accuracy: 0.9524\n",
            "Epoch 696/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.8043e-04 - accuracy: 1.0000 - val_loss: 0.6066 - val_accuracy: 0.9524\n",
            "Epoch 697/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.8432e-04 - accuracy: 1.0000 - val_loss: 0.6094 - val_accuracy: 0.9524\n",
            "Epoch 698/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.6722e-04 - accuracy: 1.0000 - val_loss: 0.6134 - val_accuracy: 0.9048\n",
            "Epoch 699/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.6746e-04 - accuracy: 1.0000 - val_loss: 0.6128 - val_accuracy: 0.9048\n",
            "Epoch 700/800\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.6354e-04 - accuracy: 1.0000 - val_loss: 0.6097 - val_accuracy: 0.9524\n",
            "Epoch 701/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.5468e-04 - accuracy: 1.0000 - val_loss: 0.6107 - val_accuracy: 0.9524\n",
            "Epoch 702/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.4376e-04 - accuracy: 1.0000 - val_loss: 0.6108 - val_accuracy: 0.9524\n",
            "Epoch 703/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.5651e-04 - accuracy: 1.0000 - val_loss: 0.6120 - val_accuracy: 0.9524\n",
            "Epoch 704/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.3799e-04 - accuracy: 1.0000 - val_loss: 0.6146 - val_accuracy: 0.9048\n",
            "Epoch 705/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.4020e-04 - accuracy: 1.0000 - val_loss: 0.6148 - val_accuracy: 0.9048\n",
            "Epoch 706/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.7253e-04 - accuracy: 1.0000 - val_loss: 0.6123 - val_accuracy: 0.9524\n",
            "Epoch 707/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.2840e-04 - accuracy: 1.0000 - val_loss: 0.6133 - val_accuracy: 0.9524\n",
            "Epoch 708/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.6283e-04 - accuracy: 1.0000 - val_loss: 0.6166 - val_accuracy: 0.9048\n",
            "Epoch 709/800\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.4046e-04 - accuracy: 1.0000 - val_loss: 0.6150 - val_accuracy: 0.9524\n",
            "Epoch 710/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.6901e-04 - accuracy: 1.0000 - val_loss: 0.6132 - val_accuracy: 0.9524\n",
            "Epoch 711/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.5071e-04 - accuracy: 1.0000 - val_loss: 0.6147 - val_accuracy: 0.9524\n",
            "Epoch 712/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.5529e-04 - accuracy: 1.0000 - val_loss: 0.6174 - val_accuracy: 0.9524\n",
            "Epoch 713/800\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.2101e-04 - accuracy: 1.0000 - val_loss: 0.6160 - val_accuracy: 0.9524\n",
            "Epoch 714/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.1844e-04 - accuracy: 1.0000 - val_loss: 0.6154 - val_accuracy: 0.9524\n",
            "Epoch 715/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.2510e-04 - accuracy: 1.0000 - val_loss: 0.6162 - val_accuracy: 0.9524\n",
            "Epoch 716/800\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.1132e-04 - accuracy: 1.0000 - val_loss: 0.6177 - val_accuracy: 0.9524\n",
            "Epoch 717/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.1090e-04 - accuracy: 1.0000 - val_loss: 0.6182 - val_accuracy: 0.9524\n",
            "Epoch 718/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.1257e-04 - accuracy: 1.0000 - val_loss: 0.6179 - val_accuracy: 0.9524\n",
            "Epoch 719/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.1895e-04 - accuracy: 1.0000 - val_loss: 0.6191 - val_accuracy: 0.9524\n",
            "Epoch 720/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.1284e-04 - accuracy: 1.0000 - val_loss: 0.6195 - val_accuracy: 0.9524\n",
            "Epoch 721/800\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.2326e-04 - accuracy: 1.0000 - val_loss: 0.6181 - val_accuracy: 0.9524\n",
            "Epoch 722/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.2958e-04 - accuracy: 1.0000 - val_loss: 0.6205 - val_accuracy: 0.9524\n",
            "Epoch 723/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.0190e-04 - accuracy: 1.0000 - val_loss: 0.6207 - val_accuracy: 0.9524\n",
            "Epoch 724/800\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 2.9641e-04 - accuracy: 1.0000 - val_loss: 0.6203 - val_accuracy: 0.9524\n",
            "Epoch 725/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.1812e-04 - accuracy: 1.0000 - val_loss: 0.6214 - val_accuracy: 0.9524\n",
            "Epoch 726/800\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.9423e-04 - accuracy: 1.0000 - val_loss: 0.6204 - val_accuracy: 0.9524\n",
            "Epoch 727/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.1221e-04 - accuracy: 1.0000 - val_loss: 0.6205 - val_accuracy: 0.9524\n",
            "Epoch 728/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.1180e-04 - accuracy: 1.0000 - val_loss: 0.6230 - val_accuracy: 0.9524\n",
            "Epoch 729/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.9340e-04 - accuracy: 1.0000 - val_loss: 0.6234 - val_accuracy: 0.9524\n",
            "Epoch 730/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.0009e-04 - accuracy: 1.0000 - val_loss: 0.6225 - val_accuracy: 0.9524\n",
            "Epoch 731/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.8615e-04 - accuracy: 1.0000 - val_loss: 0.6232 - val_accuracy: 0.9524\n",
            "Epoch 732/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.9775e-04 - accuracy: 1.0000 - val_loss: 0.6247 - val_accuracy: 0.9524\n",
            "Epoch 733/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.8954e-04 - accuracy: 1.0000 - val_loss: 0.6239 - val_accuracy: 0.9524\n",
            "Epoch 734/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.8714e-04 - accuracy: 1.0000 - val_loss: 0.6235 - val_accuracy: 0.9524\n",
            "Epoch 735/800\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.9508e-04 - accuracy: 1.0000 - val_loss: 0.6251 - val_accuracy: 0.9524\n",
            "Epoch 736/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.8186e-04 - accuracy: 1.0000 - val_loss: 0.6254 - val_accuracy: 0.9524\n",
            "Epoch 737/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.8210e-04 - accuracy: 1.0000 - val_loss: 0.6257 - val_accuracy: 0.9524\n",
            "Epoch 738/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.8321e-04 - accuracy: 1.0000 - val_loss: 0.6250 - val_accuracy: 0.9524\n",
            "Epoch 739/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.8388e-04 - accuracy: 1.0000 - val_loss: 0.6262 - val_accuracy: 0.9524\n",
            "Epoch 740/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 2.7164e-04 - accuracy: 1.0000 - val_loss: 0.6270 - val_accuracy: 0.9524\n",
            "Epoch 741/800\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.7469e-04 - accuracy: 1.0000 - val_loss: 0.6280 - val_accuracy: 0.9524\n",
            "Epoch 742/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.7352e-04 - accuracy: 1.0000 - val_loss: 0.6274 - val_accuracy: 0.9524\n",
            "Epoch 743/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.7429e-04 - accuracy: 1.0000 - val_loss: 0.6280 - val_accuracy: 0.9524\n",
            "Epoch 744/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.7251e-04 - accuracy: 1.0000 - val_loss: 0.6278 - val_accuracy: 0.9524\n",
            "Epoch 745/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.7272e-04 - accuracy: 1.0000 - val_loss: 0.6286 - val_accuracy: 0.9524\n",
            "Epoch 746/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.7383e-04 - accuracy: 1.0000 - val_loss: 0.6296 - val_accuracy: 0.9524\n",
            "Epoch 747/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.8012e-04 - accuracy: 1.0000 - val_loss: 0.6286 - val_accuracy: 0.9524\n",
            "Epoch 748/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.6227e-04 - accuracy: 1.0000 - val_loss: 0.6299 - val_accuracy: 0.9524\n",
            "Epoch 749/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 2.5987e-04 - accuracy: 1.0000 - val_loss: 0.6318 - val_accuracy: 0.9524\n",
            "Epoch 750/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.6672e-04 - accuracy: 1.0000 - val_loss: 0.6322 - val_accuracy: 0.9524\n",
            "Epoch 751/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.8655e-04 - accuracy: 1.0000 - val_loss: 0.6302 - val_accuracy: 0.9524\n",
            "Epoch 752/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.6723e-04 - accuracy: 1.0000 - val_loss: 0.6317 - val_accuracy: 0.9524\n",
            "Epoch 753/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.5958e-04 - accuracy: 1.0000 - val_loss: 0.6317 - val_accuracy: 0.9524\n",
            "Epoch 754/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.5594e-04 - accuracy: 1.0000 - val_loss: 0.6320 - val_accuracy: 0.9524\n",
            "Epoch 755/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 2.5205e-04 - accuracy: 1.0000 - val_loss: 0.6316 - val_accuracy: 0.9524\n",
            "Epoch 756/800\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.5611e-04 - accuracy: 1.0000 - val_loss: 0.6323 - val_accuracy: 0.9524\n",
            "Epoch 757/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.5218e-04 - accuracy: 1.0000 - val_loss: 0.6327 - val_accuracy: 0.9524\n",
            "Epoch 758/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.5190e-04 - accuracy: 1.0000 - val_loss: 0.6342 - val_accuracy: 0.9524\n",
            "Epoch 759/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.6899e-04 - accuracy: 1.0000 - val_loss: 0.6333 - val_accuracy: 0.9524\n",
            "Epoch 760/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.4726e-04 - accuracy: 1.0000 - val_loss: 0.6344 - val_accuracy: 0.9524\n",
            "Epoch 761/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.4455e-04 - accuracy: 1.0000 - val_loss: 0.6358 - val_accuracy: 0.9524\n",
            "Epoch 762/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.4782e-04 - accuracy: 1.0000 - val_loss: 0.6359 - val_accuracy: 0.9524\n",
            "Epoch 763/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.4469e-04 - accuracy: 1.0000 - val_loss: 0.6355 - val_accuracy: 0.9524\n",
            "Epoch 764/800\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 2.4453e-04 - accuracy: 1.0000 - val_loss: 0.6354 - val_accuracy: 0.9524\n",
            "Epoch 765/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.4845e-04 - accuracy: 1.0000 - val_loss: 0.6369 - val_accuracy: 0.9524\n",
            "Epoch 766/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.4465e-04 - accuracy: 1.0000 - val_loss: 0.6372 - val_accuracy: 0.9524\n",
            "Epoch 767/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 2.4155e-04 - accuracy: 1.0000 - val_loss: 0.6361 - val_accuracy: 0.9524\n",
            "Epoch 768/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.3935e-04 - accuracy: 1.0000 - val_loss: 0.6365 - val_accuracy: 0.9524\n",
            "Epoch 769/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.4015e-04 - accuracy: 1.0000 - val_loss: 0.6370 - val_accuracy: 0.9524\n",
            "Epoch 770/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.3735e-04 - accuracy: 1.0000 - val_loss: 0.6386 - val_accuracy: 0.9524\n",
            "Epoch 771/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.3433e-04 - accuracy: 1.0000 - val_loss: 0.6393 - val_accuracy: 0.9524\n",
            "Epoch 772/800\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.3244e-04 - accuracy: 1.0000 - val_loss: 0.6391 - val_accuracy: 0.9524\n",
            "Epoch 773/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.4989e-04 - accuracy: 1.0000 - val_loss: 0.6380 - val_accuracy: 0.9524\n",
            "Epoch 774/800\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 2.2956e-04 - accuracy: 1.0000 - val_loss: 0.6391 - val_accuracy: 0.9524\n",
            "Epoch 775/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.2769e-04 - accuracy: 1.0000 - val_loss: 0.6407 - val_accuracy: 0.9524\n",
            "Epoch 776/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.3459e-04 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 0.9524\n",
            "Epoch 777/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.3754e-04 - accuracy: 1.0000 - val_loss: 0.6406 - val_accuracy: 0.9524\n",
            "Epoch 778/800\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 2.2953e-04 - accuracy: 1.0000 - val_loss: 0.6409 - val_accuracy: 0.9524\n",
            "Epoch 779/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.3436e-04 - accuracy: 1.0000 - val_loss: 0.6407 - val_accuracy: 0.9524\n",
            "Epoch 780/800\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 2.2601e-04 - accuracy: 1.0000 - val_loss: 0.6424 - val_accuracy: 0.9524\n",
            "Epoch 781/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.2270e-04 - accuracy: 1.0000 - val_loss: 0.6426 - val_accuracy: 0.9524\n",
            "Epoch 782/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.2519e-04 - accuracy: 1.0000 - val_loss: 0.6428 - val_accuracy: 0.9524\n",
            "Epoch 783/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.3952e-04 - accuracy: 1.0000 - val_loss: 0.6418 - val_accuracy: 0.9524\n",
            "Epoch 784/800\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.1810e-04 - accuracy: 1.0000 - val_loss: 0.6431 - val_accuracy: 0.9524\n",
            "Epoch 785/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.2027e-04 - accuracy: 1.0000 - val_loss: 0.6447 - val_accuracy: 0.9524\n",
            "Epoch 786/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 2.2495e-04 - accuracy: 1.0000 - val_loss: 0.6439 - val_accuracy: 0.9524\n",
            "Epoch 787/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.1752e-04 - accuracy: 1.0000 - val_loss: 0.6446 - val_accuracy: 0.9524\n",
            "Epoch 788/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.1559e-04 - accuracy: 1.0000 - val_loss: 0.6444 - val_accuracy: 0.9524\n",
            "Epoch 789/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.1723e-04 - accuracy: 1.0000 - val_loss: 0.6448 - val_accuracy: 0.9524\n",
            "Epoch 790/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.2076e-04 - accuracy: 1.0000 - val_loss: 0.6455 - val_accuracy: 0.9524\n",
            "Epoch 791/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.2151e-04 - accuracy: 1.0000 - val_loss: 0.6447 - val_accuracy: 0.9524\n",
            "Epoch 792/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.1272e-04 - accuracy: 1.0000 - val_loss: 0.6454 - val_accuracy: 0.9524\n",
            "Epoch 793/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.0690e-04 - accuracy: 1.0000 - val_loss: 0.6468 - val_accuracy: 0.9524\n",
            "Epoch 794/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.0818e-04 - accuracy: 1.0000 - val_loss: 0.6477 - val_accuracy: 0.9524\n",
            "Epoch 795/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.1096e-04 - accuracy: 1.0000 - val_loss: 0.6485 - val_accuracy: 0.9524\n",
            "Epoch 796/800\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.1626e-04 - accuracy: 1.0000 - val_loss: 0.6472 - val_accuracy: 0.9524\n",
            "Epoch 797/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.0660e-04 - accuracy: 1.0000 - val_loss: 0.6473 - val_accuracy: 0.9524\n",
            "Epoch 798/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.0550e-04 - accuracy: 1.0000 - val_loss: 0.6480 - val_accuracy: 0.9524\n",
            "Epoch 799/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.0577e-04 - accuracy: 1.0000 - val_loss: 0.6485 - val_accuracy: 0.9524\n",
            "Epoch 800/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.0712e-04 - accuracy: 1.0000 - val_loss: 0.6499 - val_accuracy: 0.9524\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssIHu5cM-QOn",
        "colab_type": "text"
      },
      "source": [
        "#### Plot the learning curves\n",
        "\n",
        "We will now plot two graphs:\n",
        "* Epoch vs accuracy\n",
        "* Epoch vs loss\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRFBWnUX-QOo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "5971e020-e5f2-4ee2-af37-97beca71fd6d"
      },
      "source": [
        "#Run this cell to plot the epoch vs accuracy graph\n",
        "\n",
        "try:\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "except KeyError:\n",
        "    plt.plot(history.history['acc'])\n",
        "    plt.plot(history.history['val_acc'])\n",
        "plt.title('Accuracy vs. epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='lower right')\n",
        "plt.show() "
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tj0Ir6Sr-QOq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "b0a34bcc-396b-484e-dc79-9892d1a90c46"
      },
      "source": [
        "#Run this cell to plot the epoch vs loss graph\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Loss vs. epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper right')\n",
        "plt.show() "
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrsUWJwj-QOr",
        "colab_type": "text"
      },
      "source": [
        "Oh no! We have overfit our dataset. You should now try to now try to mitigate this overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6N_uo6m-QOs",
        "colab_type": "text"
      },
      "source": [
        "#### Reducing overfitting in the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGME_x9a-QOs",
        "colab_type": "text"
      },
      "source": [
        "You should now define a new regularised model.\n",
        "The specs for the regularised model are the same as our original model, with the addition of two dropout layers, weight decay, and a batch normalisation layer. \n",
        "\n",
        "In particular:\n",
        "\n",
        "* Add a dropout layer after the 3rd Dense layer\n",
        "* Then there should be two more Dense layers with 128 units before a batch normalisation layer\n",
        "* Following this, two more Dense layers with 64 units and then another Dropout layer\n",
        "* Two more Dense layers with 64 units and then the final 3-way softmax layer\n",
        "* Add weight decay (l2 kernel regularisation) in all Dense layers except the final softmax layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYytfpmm-QOv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### GRADED CELL ####\n",
        "\n",
        "# Complete the following function. \n",
        "# Make sure to not change the function name or arguments.\n",
        "\n",
        "def get_regularised_model(input_shape, dropout_rate, weight_decay):\n",
        "    \"\"\"\n",
        "    This function should build a regularised Sequential model according to the above specification. \n",
        "    The dropout_rate argument in the function should be used to set the Dropout rate for all Dropout layers.\n",
        "    L2 kernel regularisation (weight decay) should be added using the weight_decay argument to \n",
        "    set the weight decay coefficient in all Dense layers that use L2 regularisation.\n",
        "    Ensure the weights are initialised by providing the input_shape argument in the first layer, given by the\n",
        "    function argument input_shape.\n",
        "    Your function should return the model.\n",
        "    \"\"\"\n",
        "    model = Sequential([\n",
        "                        Dense(64, activation = 'relu', kernel_initializer = 'he_uniform', kernel_regularizer=tf.keras.regularizers.l2(weight_decay), bias_initializer = 'ones', input_shape = input_shape),\n",
        "                        Dense(128, activation = 'relu', kernel_regularizer=tf.keras.regularizers.l2(weight_decay)),\n",
        "                        Dense(128, activation = 'relu', kernel_regularizer=tf.keras.regularizers.l2(weight_decay)),\n",
        "                        Dropout(dropout_rate),\n",
        "                        Dense(128, activation = 'relu', kernel_regularizer=tf.keras.regularizers.l2(weight_decay)),\n",
        "                        Dense(128, activation = 'relu', kernel_regularizer=tf.keras.regularizers.l2(weight_decay)),\n",
        "                        BatchNormalization(),\n",
        "                        Dense(64, activation = 'relu', kernel_regularizer=tf.keras.regularizers.l2(weight_decay)),\n",
        "                        Dense(64, activation = 'relu', kernel_regularizer=tf.keras.regularizers.l2(weight_decay)),\n",
        "                        Dropout(dropout_rate),\n",
        "                        Dense(64, activation = 'relu', kernel_regularizer=tf.keras.regularizers.l2(weight_decay)),\n",
        "                        Dense(64, activation = 'relu', kernel_regularizer=tf.keras.regularizers.l2(weight_decay)),\n",
        "                        Dense(3, activation = 'softmax')\n",
        "                        ])\n",
        "\n",
        "    return model\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qw79AOPy-QOx",
        "colab_type": "text"
      },
      "source": [
        "#### Instantiate, compile and train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iO8JYVXB-QOz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate the model, using a dropout rate of 0.3 and weight decay coefficient of 0.001\n",
        "\n",
        "reg_model = get_regularised_model(train_data[0].shape, 0.3, 0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOEqCQ3I-QO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the model\n",
        "\n",
        "compile_model(reg_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Eg83stX-QO6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c9605eee-f6ef-45d8-b347-10fbecf7fc0b"
      },
      "source": [
        "# Train the model\n",
        "\n",
        "reg_history = train_model(reg_model, train_data, train_targets, epochs=800)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/800\n",
            "3/3 [==============================] - 0s 76ms/step - loss: 9.9747 - accuracy: 0.2982 - val_loss: 9.8814 - val_accuracy: 0.0476\n",
            "Epoch 2/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 9.9531 - accuracy: 0.2807 - val_loss: 9.8486 - val_accuracy: 0.2381\n",
            "Epoch 3/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 9.9197 - accuracy: 0.2719 - val_loss: 9.8162 - val_accuracy: 0.4286\n",
            "Epoch 4/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 9.8460 - accuracy: 0.3333 - val_loss: 9.7865 - val_accuracy: 0.4286\n",
            "Epoch 5/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 9.8467 - accuracy: 0.2719 - val_loss: 9.7568 - val_accuracy: 0.4286\n",
            "Epoch 6/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 9.7852 - accuracy: 0.3070 - val_loss: 9.7280 - val_accuracy: 0.4286\n",
            "Epoch 7/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 9.7971 - accuracy: 0.3070 - val_loss: 9.6995 - val_accuracy: 0.4286\n",
            "Epoch 8/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 9.7558 - accuracy: 0.3860 - val_loss: 9.6686 - val_accuracy: 0.4286\n",
            "Epoch 9/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 9.7015 - accuracy: 0.3421 - val_loss: 9.6373 - val_accuracy: 0.4286\n",
            "Epoch 10/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 9.7192 - accuracy: 0.3158 - val_loss: 9.6044 - val_accuracy: 0.4286\n",
            "Epoch 11/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 9.6911 - accuracy: 0.3947 - val_loss: 9.5732 - val_accuracy: 0.4286\n",
            "Epoch 12/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 9.6377 - accuracy: 0.3947 - val_loss: 9.5450 - val_accuracy: 0.4286\n",
            "Epoch 13/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 9.6111 - accuracy: 0.4123 - val_loss: 9.5167 - val_accuracy: 0.4286\n",
            "Epoch 14/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 9.5868 - accuracy: 0.3860 - val_loss: 9.4889 - val_accuracy: 0.4286\n",
            "Epoch 15/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 9.5664 - accuracy: 0.3596 - val_loss: 9.4605 - val_accuracy: 0.4286\n",
            "Epoch 16/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 9.5105 - accuracy: 0.4737 - val_loss: 9.4321 - val_accuracy: 0.4286\n",
            "Epoch 17/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 9.4833 - accuracy: 0.5000 - val_loss: 9.4047 - val_accuracy: 0.4286\n",
            "Epoch 18/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 9.4824 - accuracy: 0.4211 - val_loss: 9.3762 - val_accuracy: 0.4286\n",
            "Epoch 19/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 9.4584 - accuracy: 0.4386 - val_loss: 9.3481 - val_accuracy: 0.4286\n",
            "Epoch 20/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 9.4134 - accuracy: 0.5175 - val_loss: 9.3227 - val_accuracy: 0.4286\n",
            "Epoch 21/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 9.3841 - accuracy: 0.4561 - val_loss: 9.2987 - val_accuracy: 0.4286\n",
            "Epoch 22/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 9.3877 - accuracy: 0.4386 - val_loss: 9.2763 - val_accuracy: 0.4286\n",
            "Epoch 23/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 9.2880 - accuracy: 0.5877 - val_loss: 9.2523 - val_accuracy: 0.4286\n",
            "Epoch 24/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 9.3238 - accuracy: 0.4825 - val_loss: 9.2268 - val_accuracy: 0.4286\n",
            "Epoch 25/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 9.2699 - accuracy: 0.6228 - val_loss: 9.2000 - val_accuracy: 0.4286\n",
            "Epoch 26/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 9.2957 - accuracy: 0.4737 - val_loss: 9.1726 - val_accuracy: 0.4286\n",
            "Epoch 27/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 9.2138 - accuracy: 0.6053 - val_loss: 9.1450 - val_accuracy: 0.4286\n",
            "Epoch 28/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 9.1816 - accuracy: 0.5702 - val_loss: 9.1165 - val_accuracy: 0.4286\n",
            "Epoch 29/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 9.1519 - accuracy: 0.6842 - val_loss: 9.0884 - val_accuracy: 0.4762\n",
            "Epoch 30/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 9.1473 - accuracy: 0.5702 - val_loss: 9.0606 - val_accuracy: 0.4762\n",
            "Epoch 31/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 9.0982 - accuracy: 0.5965 - val_loss: 9.0319 - val_accuracy: 0.4762\n",
            "Epoch 32/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 9.0522 - accuracy: 0.6491 - val_loss: 9.0003 - val_accuracy: 0.4762\n",
            "Epoch 33/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 9.0553 - accuracy: 0.5965 - val_loss: 8.9677 - val_accuracy: 0.4762\n",
            "Epoch 34/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 9.0230 - accuracy: 0.6140 - val_loss: 8.9349 - val_accuracy: 0.5714\n",
            "Epoch 35/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 8.9576 - accuracy: 0.6930 - val_loss: 8.9044 - val_accuracy: 0.5714\n",
            "Epoch 36/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 8.9505 - accuracy: 0.6140 - val_loss: 8.8737 - val_accuracy: 0.6190\n",
            "Epoch 37/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 8.9333 - accuracy: 0.6404 - val_loss: 8.8424 - val_accuracy: 0.6190\n",
            "Epoch 38/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 8.8685 - accuracy: 0.6491 - val_loss: 8.8093 - val_accuracy: 0.6190\n",
            "Epoch 39/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 8.8675 - accuracy: 0.6491 - val_loss: 8.7748 - val_accuracy: 0.6190\n",
            "Epoch 40/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 8.8110 - accuracy: 0.7105 - val_loss: 8.7412 - val_accuracy: 0.6190\n",
            "Epoch 41/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 8.7772 - accuracy: 0.6404 - val_loss: 8.7088 - val_accuracy: 0.6190\n",
            "Epoch 42/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 8.7582 - accuracy: 0.6667 - val_loss: 8.6780 - val_accuracy: 0.6190\n",
            "Epoch 43/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 8.7241 - accuracy: 0.6754 - val_loss: 8.6478 - val_accuracy: 0.6190\n",
            "Epoch 44/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 8.6786 - accuracy: 0.7105 - val_loss: 8.6167 - val_accuracy: 0.6190\n",
            "Epoch 45/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 8.6371 - accuracy: 0.6842 - val_loss: 8.5842 - val_accuracy: 0.6190\n",
            "Epoch 46/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 8.5674 - accuracy: 0.6930 - val_loss: 8.5508 - val_accuracy: 0.6190\n",
            "Epoch 47/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 8.5672 - accuracy: 0.6930 - val_loss: 8.5180 - val_accuracy: 0.6190\n",
            "Epoch 48/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 8.5582 - accuracy: 0.6930 - val_loss: 8.4862 - val_accuracy: 0.6190\n",
            "Epoch 49/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 8.4804 - accuracy: 0.7018 - val_loss: 8.4545 - val_accuracy: 0.6190\n",
            "Epoch 50/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 8.4675 - accuracy: 0.7281 - val_loss: 8.4222 - val_accuracy: 0.6190\n",
            "Epoch 51/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 8.4387 - accuracy: 0.7105 - val_loss: 8.3907 - val_accuracy: 0.6667\n",
            "Epoch 52/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 8.4179 - accuracy: 0.7193 - val_loss: 8.3608 - val_accuracy: 0.6667\n",
            "Epoch 53/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 8.3655 - accuracy: 0.7281 - val_loss: 8.3342 - val_accuracy: 0.6667\n",
            "Epoch 54/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 8.3273 - accuracy: 0.7456 - val_loss: 8.3083 - val_accuracy: 0.7143\n",
            "Epoch 55/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 8.3051 - accuracy: 0.7105 - val_loss: 8.2828 - val_accuracy: 0.7143\n",
            "Epoch 56/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 8.2845 - accuracy: 0.7018 - val_loss: 8.2573 - val_accuracy: 0.7143\n",
            "Epoch 57/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 8.2363 - accuracy: 0.7368 - val_loss: 8.2324 - val_accuracy: 0.7143\n",
            "Epoch 58/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 8.2372 - accuracy: 0.6667 - val_loss: 8.2059 - val_accuracy: 0.7143\n",
            "Epoch 59/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 8.1876 - accuracy: 0.7105 - val_loss: 8.1802 - val_accuracy: 0.7619\n",
            "Epoch 60/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 8.1404 - accuracy: 0.7632 - val_loss: 8.1557 - val_accuracy: 0.7619\n",
            "Epoch 61/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 8.1345 - accuracy: 0.7632 - val_loss: 8.1313 - val_accuracy: 0.7619\n",
            "Epoch 62/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 8.1077 - accuracy: 0.7456 - val_loss: 8.1074 - val_accuracy: 0.7619\n",
            "Epoch 63/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 8.1025 - accuracy: 0.7368 - val_loss: 8.0835 - val_accuracy: 0.7619\n",
            "Epoch 64/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 8.0673 - accuracy: 0.7632 - val_loss: 8.0598 - val_accuracy: 0.7619\n",
            "Epoch 65/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 8.0127 - accuracy: 0.7982 - val_loss: 8.0367 - val_accuracy: 0.7619\n",
            "Epoch 66/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 7.9944 - accuracy: 0.7632 - val_loss: 8.0156 - val_accuracy: 0.8095\n",
            "Epoch 67/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 7.9885 - accuracy: 0.7632 - val_loss: 7.9965 - val_accuracy: 0.8095\n",
            "Epoch 68/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 7.9786 - accuracy: 0.7895 - val_loss: 7.9751 - val_accuracy: 0.8095\n",
            "Epoch 69/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 7.9061 - accuracy: 0.8421 - val_loss: 7.9533 - val_accuracy: 0.8095\n",
            "Epoch 70/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 7.9076 - accuracy: 0.7895 - val_loss: 7.9308 - val_accuracy: 0.8095\n",
            "Epoch 71/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 7.9211 - accuracy: 0.7544 - val_loss: 7.9085 - val_accuracy: 0.8095\n",
            "Epoch 72/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 7.8720 - accuracy: 0.7895 - val_loss: 7.8868 - val_accuracy: 0.8571\n",
            "Epoch 73/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 7.8829 - accuracy: 0.7281 - val_loss: 7.8669 - val_accuracy: 0.8571\n",
            "Epoch 74/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 7.8346 - accuracy: 0.7719 - val_loss: 7.8470 - val_accuracy: 0.8571\n",
            "Epoch 75/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 7.8113 - accuracy: 0.8070 - val_loss: 7.8303 - val_accuracy: 0.9048\n",
            "Epoch 76/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 7.8018 - accuracy: 0.7632 - val_loss: 7.8110 - val_accuracy: 0.9048\n",
            "Epoch 77/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 7.7680 - accuracy: 0.7456 - val_loss: 7.7905 - val_accuracy: 0.9048\n",
            "Epoch 78/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 7.7476 - accuracy: 0.8070 - val_loss: 7.7710 - val_accuracy: 0.9524\n",
            "Epoch 79/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 7.7246 - accuracy: 0.8333 - val_loss: 7.7492 - val_accuracy: 0.9524\n",
            "Epoch 80/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 7.6884 - accuracy: 0.7982 - val_loss: 7.7281 - val_accuracy: 0.9524\n",
            "Epoch 81/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 7.7095 - accuracy: 0.7807 - val_loss: 7.7100 - val_accuracy: 0.9524\n",
            "Epoch 82/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 7.6936 - accuracy: 0.7807 - val_loss: 7.6890 - val_accuracy: 0.9524\n",
            "Epoch 83/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 7.6467 - accuracy: 0.7719 - val_loss: 7.6702 - val_accuracy: 0.9524\n",
            "Epoch 84/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 7.6289 - accuracy: 0.7982 - val_loss: 7.6555 - val_accuracy: 0.9524\n",
            "Epoch 85/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 7.5791 - accuracy: 0.8070 - val_loss: 7.6435 - val_accuracy: 0.9524\n",
            "Epoch 86/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 7.6132 - accuracy: 0.7807 - val_loss: 7.6304 - val_accuracy: 0.9524\n",
            "Epoch 87/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 7.5479 - accuracy: 0.8333 - val_loss: 7.6159 - val_accuracy: 0.9048\n",
            "Epoch 88/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 7.5319 - accuracy: 0.8246 - val_loss: 7.6011 - val_accuracy: 0.9048\n",
            "Epoch 89/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 7.5158 - accuracy: 0.8509 - val_loss: 7.5815 - val_accuracy: 0.9048\n",
            "Epoch 90/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 7.5288 - accuracy: 0.7719 - val_loss: 7.5581 - val_accuracy: 0.9048\n",
            "Epoch 91/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 7.4688 - accuracy: 0.8509 - val_loss: 7.5349 - val_accuracy: 0.9048\n",
            "Epoch 92/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 7.4675 - accuracy: 0.8246 - val_loss: 7.5129 - val_accuracy: 0.9048\n",
            "Epoch 93/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 7.4323 - accuracy: 0.8684 - val_loss: 7.4946 - val_accuracy: 0.9048\n",
            "Epoch 94/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 7.4152 - accuracy: 0.8070 - val_loss: 7.4761 - val_accuracy: 0.9048\n",
            "Epoch 95/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 7.4179 - accuracy: 0.7895 - val_loss: 7.4600 - val_accuracy: 0.8571\n",
            "Epoch 96/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 7.4169 - accuracy: 0.8333 - val_loss: 7.4403 - val_accuracy: 0.8571\n",
            "Epoch 97/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 7.3821 - accuracy: 0.7807 - val_loss: 7.4265 - val_accuracy: 0.8571\n",
            "Epoch 98/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 7.3388 - accuracy: 0.8333 - val_loss: 7.4129 - val_accuracy: 0.8571\n",
            "Epoch 99/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 7.3119 - accuracy: 0.8684 - val_loss: 7.3969 - val_accuracy: 0.8571\n",
            "Epoch 100/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 7.3283 - accuracy: 0.8333 - val_loss: 7.3801 - val_accuracy: 0.9048\n",
            "Epoch 101/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 7.2746 - accuracy: 0.8333 - val_loss: 7.3695 - val_accuracy: 0.9048\n",
            "Epoch 102/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 7.2747 - accuracy: 0.8596 - val_loss: 7.3590 - val_accuracy: 0.9048\n",
            "Epoch 103/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 7.2525 - accuracy: 0.8246 - val_loss: 7.3424 - val_accuracy: 0.9048\n",
            "Epoch 104/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 7.1910 - accuracy: 0.9298 - val_loss: 7.3260 - val_accuracy: 0.9048\n",
            "Epoch 105/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 7.2081 - accuracy: 0.8596 - val_loss: 7.3039 - val_accuracy: 0.9048\n",
            "Epoch 106/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 7.1756 - accuracy: 0.8421 - val_loss: 7.2817 - val_accuracy: 0.9048\n",
            "Epoch 107/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 7.1464 - accuracy: 0.8684 - val_loss: 7.2520 - val_accuracy: 0.9048\n",
            "Epoch 108/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 7.1395 - accuracy: 0.8684 - val_loss: 7.2260 - val_accuracy: 0.9048\n",
            "Epoch 109/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 7.1412 - accuracy: 0.8421 - val_loss: 7.2044 - val_accuracy: 0.9048\n",
            "Epoch 110/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 7.1550 - accuracy: 0.8070 - val_loss: 7.2012 - val_accuracy: 0.9048\n",
            "Epoch 111/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 7.0930 - accuracy: 0.8684 - val_loss: 7.2118 - val_accuracy: 0.8571\n",
            "Epoch 112/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 7.0567 - accuracy: 0.8947 - val_loss: 7.2151 - val_accuracy: 0.8571\n",
            "Epoch 113/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 7.0703 - accuracy: 0.8596 - val_loss: 7.2138 - val_accuracy: 0.8571\n",
            "Epoch 114/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 6.9966 - accuracy: 0.9123 - val_loss: 7.2098 - val_accuracy: 0.8095\n",
            "Epoch 115/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.9883 - accuracy: 0.9211 - val_loss: 7.1982 - val_accuracy: 0.8095\n",
            "Epoch 116/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.9717 - accuracy: 0.9123 - val_loss: 7.1558 - val_accuracy: 0.8571\n",
            "Epoch 117/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 6.9794 - accuracy: 0.8860 - val_loss: 7.1075 - val_accuracy: 0.8571\n",
            "Epoch 118/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.9442 - accuracy: 0.9211 - val_loss: 7.0839 - val_accuracy: 0.9048\n",
            "Epoch 119/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 6.9049 - accuracy: 0.9035 - val_loss: 7.0723 - val_accuracy: 0.8571\n",
            "Epoch 120/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.8971 - accuracy: 0.9211 - val_loss: 7.0610 - val_accuracy: 0.8571\n",
            "Epoch 121/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.8620 - accuracy: 0.9386 - val_loss: 7.0479 - val_accuracy: 0.8571\n",
            "Epoch 122/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.8648 - accuracy: 0.9035 - val_loss: 7.0347 - val_accuracy: 0.8571\n",
            "Epoch 123/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.8808 - accuracy: 0.8860 - val_loss: 7.0413 - val_accuracy: 0.8571\n",
            "Epoch 124/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.8228 - accuracy: 0.9123 - val_loss: 7.0201 - val_accuracy: 0.8571\n",
            "Epoch 125/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.7945 - accuracy: 0.9035 - val_loss: 6.9710 - val_accuracy: 0.8571\n",
            "Epoch 126/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.7612 - accuracy: 0.9386 - val_loss: 6.9498 - val_accuracy: 0.8571\n",
            "Epoch 127/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 6.7855 - accuracy: 0.9035 - val_loss: 6.9702 - val_accuracy: 0.8571\n",
            "Epoch 128/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 6.7140 - accuracy: 0.9474 - val_loss: 6.9744 - val_accuracy: 0.8571\n",
            "Epoch 129/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.7450 - accuracy: 0.9123 - val_loss: 6.9715 - val_accuracy: 0.8571\n",
            "Epoch 130/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 6.6749 - accuracy: 0.9474 - val_loss: 6.9534 - val_accuracy: 0.8571\n",
            "Epoch 131/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.6686 - accuracy: 0.9386 - val_loss: 6.9102 - val_accuracy: 0.8571\n",
            "Epoch 132/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.6997 - accuracy: 0.8772 - val_loss: 6.8291 - val_accuracy: 0.8571\n",
            "Epoch 133/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.6521 - accuracy: 0.9211 - val_loss: 6.7953 - val_accuracy: 0.8571\n",
            "Epoch 134/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 6.6242 - accuracy: 0.9386 - val_loss: 6.7710 - val_accuracy: 0.8571\n",
            "Epoch 135/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.5883 - accuracy: 0.9649 - val_loss: 6.7764 - val_accuracy: 0.8571\n",
            "Epoch 136/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 6.5768 - accuracy: 0.9561 - val_loss: 6.7718 - val_accuracy: 0.8571\n",
            "Epoch 137/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.5491 - accuracy: 0.9561 - val_loss: 6.7918 - val_accuracy: 0.8571\n",
            "Epoch 138/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.5546 - accuracy: 0.9123 - val_loss: 6.7707 - val_accuracy: 0.8571\n",
            "Epoch 139/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.5594 - accuracy: 0.9123 - val_loss: 6.7633 - val_accuracy: 0.8571\n",
            "Epoch 140/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.5216 - accuracy: 0.9123 - val_loss: 6.6967 - val_accuracy: 0.8571\n",
            "Epoch 141/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 6.5018 - accuracy: 0.9474 - val_loss: 6.6561 - val_accuracy: 0.8571\n",
            "Epoch 142/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.4389 - accuracy: 0.9825 - val_loss: 6.6009 - val_accuracy: 0.9524\n",
            "Epoch 143/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.4228 - accuracy: 0.9649 - val_loss: 6.5699 - val_accuracy: 0.9524\n",
            "Epoch 144/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.3915 - accuracy: 0.9825 - val_loss: 6.5571 - val_accuracy: 0.9524\n",
            "Epoch 145/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.4498 - accuracy: 0.9386 - val_loss: 6.5480 - val_accuracy: 0.9524\n",
            "Epoch 146/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 6.3871 - accuracy: 0.9386 - val_loss: 6.5594 - val_accuracy: 0.9048\n",
            "Epoch 147/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.3757 - accuracy: 0.9561 - val_loss: 6.5570 - val_accuracy: 0.9048\n",
            "Epoch 148/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.3286 - accuracy: 0.9737 - val_loss: 6.5440 - val_accuracy: 0.9048\n",
            "Epoch 149/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.3724 - accuracy: 0.9474 - val_loss: 6.4987 - val_accuracy: 0.9524\n",
            "Epoch 150/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.3383 - accuracy: 0.9386 - val_loss: 6.4604 - val_accuracy: 0.9524\n",
            "Epoch 151/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.2985 - accuracy: 0.9561 - val_loss: 6.4603 - val_accuracy: 0.9524\n",
            "Epoch 152/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 6.2769 - accuracy: 0.9561 - val_loss: 6.4401 - val_accuracy: 0.9048\n",
            "Epoch 153/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.2701 - accuracy: 0.9386 - val_loss: 6.4230 - val_accuracy: 0.9524\n",
            "Epoch 154/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.2227 - accuracy: 0.9825 - val_loss: 6.4251 - val_accuracy: 0.9048\n",
            "Epoch 155/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.2073 - accuracy: 0.9737 - val_loss: 6.4233 - val_accuracy: 0.8571\n",
            "Epoch 156/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 6.1748 - accuracy: 0.9912 - val_loss: 6.3852 - val_accuracy: 0.9524\n",
            "Epoch 157/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.2054 - accuracy: 0.9649 - val_loss: 6.3412 - val_accuracy: 0.9524\n",
            "Epoch 158/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.1744 - accuracy: 0.9649 - val_loss: 6.3041 - val_accuracy: 0.9524\n",
            "Epoch 159/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.2250 - accuracy: 0.9298 - val_loss: 6.2819 - val_accuracy: 0.9524\n",
            "Epoch 160/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.1033 - accuracy: 0.9912 - val_loss: 6.2590 - val_accuracy: 0.9524\n",
            "Epoch 161/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 6.1295 - accuracy: 0.9561 - val_loss: 6.2703 - val_accuracy: 0.9524\n",
            "Epoch 162/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 6.1274 - accuracy: 0.9561 - val_loss: 6.2978 - val_accuracy: 0.9048\n",
            "Epoch 163/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 6.0798 - accuracy: 0.9825 - val_loss: 6.2814 - val_accuracy: 0.9048\n",
            "Epoch 164/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.0449 - accuracy: 0.9825 - val_loss: 6.2604 - val_accuracy: 0.9524\n",
            "Epoch 165/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 6.0489 - accuracy: 0.9912 - val_loss: 6.2241 - val_accuracy: 0.9524\n",
            "Epoch 166/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 6.0517 - accuracy: 0.9649 - val_loss: 6.1929 - val_accuracy: 0.9524\n",
            "Epoch 167/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 6.0631 - accuracy: 0.9649 - val_loss: 6.1868 - val_accuracy: 0.9524\n",
            "Epoch 168/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.9988 - accuracy: 0.9825 - val_loss: 6.1903 - val_accuracy: 0.9524\n",
            "Epoch 169/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.0147 - accuracy: 0.9649 - val_loss: 6.1757 - val_accuracy: 0.9524\n",
            "Epoch 170/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.0237 - accuracy: 0.9561 - val_loss: 6.1814 - val_accuracy: 0.9524\n",
            "Epoch 171/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 5.9703 - accuracy: 0.9649 - val_loss: 6.1559 - val_accuracy: 0.9524\n",
            "Epoch 172/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.9675 - accuracy: 0.9474 - val_loss: 6.1127 - val_accuracy: 0.9524\n",
            "Epoch 173/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 5.9146 - accuracy: 0.9825 - val_loss: 6.0601 - val_accuracy: 0.9524\n",
            "Epoch 174/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 5.9262 - accuracy: 0.9825 - val_loss: 6.0331 - val_accuracy: 0.9524\n",
            "Epoch 175/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 5.9012 - accuracy: 0.9737 - val_loss: 6.0304 - val_accuracy: 0.9524\n",
            "Epoch 176/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.8828 - accuracy: 0.9825 - val_loss: 6.0183 - val_accuracy: 0.9524\n",
            "Epoch 177/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.9092 - accuracy: 0.9474 - val_loss: 6.0109 - val_accuracy: 0.9524\n",
            "Epoch 178/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.8646 - accuracy: 0.9737 - val_loss: 6.0174 - val_accuracy: 0.9524\n",
            "Epoch 179/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 5.8304 - accuracy: 0.9912 - val_loss: 5.9901 - val_accuracy: 0.9524\n",
            "Epoch 180/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 5.8321 - accuracy: 0.9737 - val_loss: 5.9452 - val_accuracy: 0.9524\n",
            "Epoch 181/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.8497 - accuracy: 0.9561 - val_loss: 5.9243 - val_accuracy: 0.9048\n",
            "Epoch 182/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 5.7997 - accuracy: 0.9825 - val_loss: 5.9186 - val_accuracy: 0.9524\n",
            "Epoch 183/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.8100 - accuracy: 0.9649 - val_loss: 5.9154 - val_accuracy: 0.9524\n",
            "Epoch 184/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.7779 - accuracy: 0.9825 - val_loss: 5.8922 - val_accuracy: 0.9524\n",
            "Epoch 185/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 5.7946 - accuracy: 0.9649 - val_loss: 5.8729 - val_accuracy: 0.9524\n",
            "Epoch 186/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 5.7512 - accuracy: 0.9825 - val_loss: 5.8695 - val_accuracy: 0.9524\n",
            "Epoch 187/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.7715 - accuracy: 0.9737 - val_loss: 5.8687 - val_accuracy: 0.9524\n",
            "Epoch 188/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 5.7532 - accuracy: 0.9737 - val_loss: 5.8504 - val_accuracy: 0.9524\n",
            "Epoch 189/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.7358 - accuracy: 0.9737 - val_loss: 5.8245 - val_accuracy: 0.9524\n",
            "Epoch 190/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.6805 - accuracy: 0.9912 - val_loss: 5.8072 - val_accuracy: 0.9524\n",
            "Epoch 191/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.7152 - accuracy: 0.9649 - val_loss: 5.8067 - val_accuracy: 0.9524\n",
            "Epoch 192/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.6563 - accuracy: 0.9912 - val_loss: 5.8048 - val_accuracy: 0.9524\n",
            "Epoch 193/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.6882 - accuracy: 0.9649 - val_loss: 5.8064 - val_accuracy: 0.9524\n",
            "Epoch 194/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 5.6306 - accuracy: 0.9912 - val_loss: 5.7732 - val_accuracy: 0.9524\n",
            "Epoch 195/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.6332 - accuracy: 0.9737 - val_loss: 5.7399 - val_accuracy: 0.9524\n",
            "Epoch 196/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 5.6053 - accuracy: 0.9912 - val_loss: 5.7174 - val_accuracy: 0.9048\n",
            "Epoch 197/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 5.6039 - accuracy: 0.9825 - val_loss: 5.7117 - val_accuracy: 0.9524\n",
            "Epoch 198/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 5.6162 - accuracy: 0.9649 - val_loss: 5.7170 - val_accuracy: 0.9524\n",
            "Epoch 199/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 5.5764 - accuracy: 0.9825 - val_loss: 5.7206 - val_accuracy: 0.9524\n",
            "Epoch 200/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.5844 - accuracy: 0.9649 - val_loss: 5.7346 - val_accuracy: 0.9524\n",
            "Epoch 201/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.5320 - accuracy: 1.0000 - val_loss: 5.7082 - val_accuracy: 0.9524\n",
            "Epoch 202/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.5790 - accuracy: 0.9561 - val_loss: 5.6427 - val_accuracy: 0.9048\n",
            "Epoch 203/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.5710 - accuracy: 0.9649 - val_loss: 5.6196 - val_accuracy: 0.9048\n",
            "Epoch 204/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 5.5373 - accuracy: 0.9561 - val_loss: 5.6171 - val_accuracy: 0.9048\n",
            "Epoch 205/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.5218 - accuracy: 0.9825 - val_loss: 5.6270 - val_accuracy: 0.9524\n",
            "Epoch 206/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 5.5112 - accuracy: 0.9825 - val_loss: 5.6208 - val_accuracy: 0.9524\n",
            "Epoch 207/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 5.4981 - accuracy: 0.9649 - val_loss: 5.6168 - val_accuracy: 0.9524\n",
            "Epoch 208/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.5042 - accuracy: 0.9561 - val_loss: 5.6134 - val_accuracy: 0.9524\n",
            "Epoch 209/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.4439 - accuracy: 0.9825 - val_loss: 5.5957 - val_accuracy: 0.9524\n",
            "Epoch 210/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.4476 - accuracy: 0.9825 - val_loss: 5.5669 - val_accuracy: 0.9524\n",
            "Epoch 211/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 5.4133 - accuracy: 0.9912 - val_loss: 5.5448 - val_accuracy: 0.9048\n",
            "Epoch 212/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 5.4028 - accuracy: 0.9825 - val_loss: 5.5369 - val_accuracy: 0.9048\n",
            "Epoch 213/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.4649 - accuracy: 0.9561 - val_loss: 5.5411 - val_accuracy: 0.9524\n",
            "Epoch 214/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 5.4223 - accuracy: 0.9649 - val_loss: 5.5527 - val_accuracy: 0.9524\n",
            "Epoch 215/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.3925 - accuracy: 0.9737 - val_loss: 5.5371 - val_accuracy: 0.9524\n",
            "Epoch 216/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 5.3651 - accuracy: 0.9825 - val_loss: 5.5098 - val_accuracy: 0.9524\n",
            "Epoch 217/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 5.3542 - accuracy: 0.9825 - val_loss: 5.4849 - val_accuracy: 0.9524\n",
            "Epoch 218/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.3459 - accuracy: 0.9737 - val_loss: 5.4671 - val_accuracy: 0.9524\n",
            "Epoch 219/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 5.3145 - accuracy: 0.9912 - val_loss: 5.4594 - val_accuracy: 0.9524\n",
            "Epoch 220/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 5.2976 - accuracy: 0.9912 - val_loss: 5.4602 - val_accuracy: 0.9524\n",
            "Epoch 221/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.3057 - accuracy: 0.9737 - val_loss: 5.4439 - val_accuracy: 0.9048\n",
            "Epoch 222/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 5.2938 - accuracy: 0.9825 - val_loss: 5.4299 - val_accuracy: 0.9048\n",
            "Epoch 223/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 5.2878 - accuracy: 0.9737 - val_loss: 5.4155 - val_accuracy: 0.9048\n",
            "Epoch 224/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 5.2891 - accuracy: 0.9737 - val_loss: 5.4095 - val_accuracy: 0.9048\n",
            "Epoch 225/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.2637 - accuracy: 0.9825 - val_loss: 5.4118 - val_accuracy: 0.9524\n",
            "Epoch 226/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.2652 - accuracy: 0.9649 - val_loss: 5.4126 - val_accuracy: 0.9524\n",
            "Epoch 227/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.2610 - accuracy: 0.9737 - val_loss: 5.3999 - val_accuracy: 0.9524\n",
            "Epoch 228/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.2173 - accuracy: 0.9912 - val_loss: 5.3824 - val_accuracy: 0.9524\n",
            "Epoch 229/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.2735 - accuracy: 0.9737 - val_loss: 5.3646 - val_accuracy: 0.9524\n",
            "Epoch 230/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.2217 - accuracy: 0.9825 - val_loss: 5.3537 - val_accuracy: 0.9524\n",
            "Epoch 231/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 5.1995 - accuracy: 0.9737 - val_loss: 5.3369 - val_accuracy: 0.9524\n",
            "Epoch 232/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 5.1791 - accuracy: 0.9825 - val_loss: 5.3238 - val_accuracy: 0.9048\n",
            "Epoch 233/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 5.1627 - accuracy: 0.9912 - val_loss: 5.3112 - val_accuracy: 0.9048\n",
            "Epoch 234/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 5.1829 - accuracy: 0.9737 - val_loss: 5.3029 - val_accuracy: 0.9048\n",
            "Epoch 235/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.1327 - accuracy: 0.9912 - val_loss: 5.2935 - val_accuracy: 0.9048\n",
            "Epoch 236/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 5.1730 - accuracy: 0.9737 - val_loss: 5.2844 - val_accuracy: 0.9524\n",
            "Epoch 237/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 5.1488 - accuracy: 0.9649 - val_loss: 5.2737 - val_accuracy: 0.9524\n",
            "Epoch 238/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 5.1477 - accuracy: 0.9649 - val_loss: 5.2586 - val_accuracy: 0.9524\n",
            "Epoch 239/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 5.0780 - accuracy: 0.9912 - val_loss: 5.2411 - val_accuracy: 0.9048\n",
            "Epoch 240/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 5.1048 - accuracy: 0.9737 - val_loss: 5.2269 - val_accuracy: 0.9048\n",
            "Epoch 241/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 5.0962 - accuracy: 0.9649 - val_loss: 5.2167 - val_accuracy: 0.9048\n",
            "Epoch 242/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.0651 - accuracy: 0.9912 - val_loss: 5.2100 - val_accuracy: 0.9048\n",
            "Epoch 243/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 5.0626 - accuracy: 0.9737 - val_loss: 5.2035 - val_accuracy: 0.9048\n",
            "Epoch 244/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 5.0304 - accuracy: 0.9912 - val_loss: 5.1963 - val_accuracy: 0.9048\n",
            "Epoch 245/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.0827 - accuracy: 0.9737 - val_loss: 5.1849 - val_accuracy: 0.9524\n",
            "Epoch 246/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.0334 - accuracy: 0.9737 - val_loss: 5.1716 - val_accuracy: 0.9524\n",
            "Epoch 247/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.0397 - accuracy: 0.9474 - val_loss: 5.1635 - val_accuracy: 0.9524\n",
            "Epoch 248/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.0444 - accuracy: 0.9561 - val_loss: 5.1534 - val_accuracy: 0.9048\n",
            "Epoch 249/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 4.9846 - accuracy: 0.9825 - val_loss: 5.1412 - val_accuracy: 0.9048\n",
            "Epoch 250/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.9832 - accuracy: 0.9737 - val_loss: 5.1323 - val_accuracy: 0.9048\n",
            "Epoch 251/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.9629 - accuracy: 0.9912 - val_loss: 5.1251 - val_accuracy: 0.9048\n",
            "Epoch 252/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 4.9710 - accuracy: 0.9825 - val_loss: 5.1174 - val_accuracy: 0.9048\n",
            "Epoch 253/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.0397 - accuracy: 0.9211 - val_loss: 5.1062 - val_accuracy: 0.9048\n",
            "Epoch 254/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 4.9561 - accuracy: 0.9825 - val_loss: 5.0920 - val_accuracy: 0.9048\n",
            "Epoch 255/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.9138 - accuracy: 0.9912 - val_loss: 5.0750 - val_accuracy: 0.9048\n",
            "Epoch 256/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 4.8914 - accuracy: 0.9912 - val_loss: 5.0670 - val_accuracy: 0.9524\n",
            "Epoch 257/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.9088 - accuracy: 0.9737 - val_loss: 5.0583 - val_accuracy: 0.9524\n",
            "Epoch 258/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.8891 - accuracy: 0.9825 - val_loss: 5.0584 - val_accuracy: 0.9524\n",
            "Epoch 259/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.8983 - accuracy: 0.9825 - val_loss: 5.0487 - val_accuracy: 0.9524\n",
            "Epoch 260/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 4.8819 - accuracy: 0.9737 - val_loss: 5.0312 - val_accuracy: 0.9048\n",
            "Epoch 261/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 4.8971 - accuracy: 0.9737 - val_loss: 5.0200 - val_accuracy: 0.9048\n",
            "Epoch 262/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 4.9423 - accuracy: 0.9474 - val_loss: 5.0159 - val_accuracy: 0.9048\n",
            "Epoch 263/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.8555 - accuracy: 0.9825 - val_loss: 5.0105 - val_accuracy: 0.9048\n",
            "Epoch 264/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 4.8419 - accuracy: 0.9825 - val_loss: 5.0050 - val_accuracy: 0.9048\n",
            "Epoch 265/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.8188 - accuracy: 0.9825 - val_loss: 4.9964 - val_accuracy: 0.9048\n",
            "Epoch 266/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.8072 - accuracy: 0.9912 - val_loss: 4.9829 - val_accuracy: 0.9048\n",
            "Epoch 267/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.7898 - accuracy: 0.9912 - val_loss: 4.9742 - val_accuracy: 0.9048\n",
            "Epoch 268/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.7981 - accuracy: 0.9825 - val_loss: 4.9464 - val_accuracy: 0.9048\n",
            "Epoch 269/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.7995 - accuracy: 0.9825 - val_loss: 4.9287 - val_accuracy: 0.9048\n",
            "Epoch 270/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.7993 - accuracy: 0.9649 - val_loss: 4.9370 - val_accuracy: 0.9048\n",
            "Epoch 271/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.7807 - accuracy: 0.9649 - val_loss: 4.9384 - val_accuracy: 0.9048\n",
            "Epoch 272/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 4.7781 - accuracy: 0.9737 - val_loss: 4.9269 - val_accuracy: 0.9048\n",
            "Epoch 273/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 4.7234 - accuracy: 0.9825 - val_loss: 4.9024 - val_accuracy: 0.9048\n",
            "Epoch 274/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.7159 - accuracy: 0.9912 - val_loss: 4.8938 - val_accuracy: 0.9048\n",
            "Epoch 275/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 4.7664 - accuracy: 0.9649 - val_loss: 4.8984 - val_accuracy: 0.9048\n",
            "Epoch 276/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.7127 - accuracy: 0.9825 - val_loss: 4.8911 - val_accuracy: 0.9048\n",
            "Epoch 277/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.6831 - accuracy: 0.9912 - val_loss: 4.8869 - val_accuracy: 0.9048\n",
            "Epoch 278/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.7112 - accuracy: 0.9825 - val_loss: 4.8789 - val_accuracy: 0.9048\n",
            "Epoch 279/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.6962 - accuracy: 0.9649 - val_loss: 4.8697 - val_accuracy: 0.9048\n",
            "Epoch 280/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.6816 - accuracy: 0.9912 - val_loss: 4.8583 - val_accuracy: 0.9048\n",
            "Epoch 281/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 4.6544 - accuracy: 0.9912 - val_loss: 4.8524 - val_accuracy: 0.9048\n",
            "Epoch 282/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 4.6799 - accuracy: 0.9737 - val_loss: 4.8353 - val_accuracy: 0.9048\n",
            "Epoch 283/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 4.6351 - accuracy: 0.9825 - val_loss: 4.8208 - val_accuracy: 0.9048\n",
            "Epoch 284/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.6417 - accuracy: 0.9737 - val_loss: 4.8083 - val_accuracy: 0.9048\n",
            "Epoch 285/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.6209 - accuracy: 0.9912 - val_loss: 4.7959 - val_accuracy: 0.9048\n",
            "Epoch 286/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.6000 - accuracy: 0.9912 - val_loss: 4.7983 - val_accuracy: 0.9048\n",
            "Epoch 287/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.6212 - accuracy: 0.9912 - val_loss: 4.7973 - val_accuracy: 0.9048\n",
            "Epoch 288/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.6151 - accuracy: 0.9825 - val_loss: 4.7908 - val_accuracy: 0.9048\n",
            "Epoch 289/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.6010 - accuracy: 0.9649 - val_loss: 4.7848 - val_accuracy: 0.9048\n",
            "Epoch 290/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.5685 - accuracy: 0.9912 - val_loss: 4.7734 - val_accuracy: 0.9048\n",
            "Epoch 291/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 4.5730 - accuracy: 0.9825 - val_loss: 4.7507 - val_accuracy: 0.9048\n",
            "Epoch 292/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.5530 - accuracy: 0.9825 - val_loss: 4.7193 - val_accuracy: 0.9048\n",
            "Epoch 293/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.5503 - accuracy: 0.9912 - val_loss: 4.7076 - val_accuracy: 0.9048\n",
            "Epoch 294/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.5786 - accuracy: 0.9737 - val_loss: 4.7167 - val_accuracy: 0.9048\n",
            "Epoch 295/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 4.5403 - accuracy: 0.9912 - val_loss: 4.7107 - val_accuracy: 0.9048\n",
            "Epoch 296/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.5543 - accuracy: 0.9649 - val_loss: 4.6992 - val_accuracy: 0.9048\n",
            "Epoch 297/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.5248 - accuracy: 0.9737 - val_loss: 4.6898 - val_accuracy: 0.9048\n",
            "Epoch 298/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.5003 - accuracy: 0.9737 - val_loss: 4.6868 - val_accuracy: 0.9048\n",
            "Epoch 299/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 4.5319 - accuracy: 0.9737 - val_loss: 4.6787 - val_accuracy: 0.9048\n",
            "Epoch 300/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 4.4610 - accuracy: 1.0000 - val_loss: 4.6677 - val_accuracy: 0.9048\n",
            "Epoch 301/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 4.4656 - accuracy: 0.9912 - val_loss: 4.6500 - val_accuracy: 0.9048\n",
            "Epoch 302/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 4.4620 - accuracy: 0.9825 - val_loss: 4.6478 - val_accuracy: 0.9048\n",
            "Epoch 303/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 4.4627 - accuracy: 0.9912 - val_loss: 4.6485 - val_accuracy: 0.9048\n",
            "Epoch 304/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 4.4467 - accuracy: 0.9825 - val_loss: 4.6417 - val_accuracy: 0.9048\n",
            "Epoch 305/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.4239 - accuracy: 0.9825 - val_loss: 4.6258 - val_accuracy: 0.9048\n",
            "Epoch 306/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.4642 - accuracy: 0.9561 - val_loss: 4.5903 - val_accuracy: 0.9048\n",
            "Epoch 307/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.4055 - accuracy: 0.9825 - val_loss: 4.5751 - val_accuracy: 0.9048\n",
            "Epoch 308/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.4612 - accuracy: 0.9737 - val_loss: 4.5814 - val_accuracy: 0.9048\n",
            "Epoch 309/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.4275 - accuracy: 0.9737 - val_loss: 4.6082 - val_accuracy: 0.9048\n",
            "Epoch 310/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 4.4038 - accuracy: 0.9825 - val_loss: 4.5986 - val_accuracy: 0.9048\n",
            "Epoch 311/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.4240 - accuracy: 0.9649 - val_loss: 4.5927 - val_accuracy: 0.9524\n",
            "Epoch 312/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 4.3793 - accuracy: 0.9825 - val_loss: 4.5837 - val_accuracy: 0.9048\n",
            "Epoch 313/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 4.3828 - accuracy: 0.9912 - val_loss: 4.5662 - val_accuracy: 0.9048\n",
            "Epoch 314/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 4.3435 - accuracy: 0.9912 - val_loss: 4.5322 - val_accuracy: 0.9048\n",
            "Epoch 315/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.3305 - accuracy: 1.0000 - val_loss: 4.5156 - val_accuracy: 0.9048\n",
            "Epoch 316/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.3511 - accuracy: 0.9825 - val_loss: 4.5213 - val_accuracy: 0.9048\n",
            "Epoch 317/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.3380 - accuracy: 0.9912 - val_loss: 4.5221 - val_accuracy: 0.9048\n",
            "Epoch 318/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.3575 - accuracy: 0.9737 - val_loss: 4.5076 - val_accuracy: 0.9048\n",
            "Epoch 319/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 4.3461 - accuracy: 0.9561 - val_loss: 4.4502 - val_accuracy: 0.9048\n",
            "Epoch 320/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 4.3119 - accuracy: 0.9825 - val_loss: 4.4371 - val_accuracy: 0.9048\n",
            "Epoch 321/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.3287 - accuracy: 0.9737 - val_loss: 4.4371 - val_accuracy: 0.9048\n",
            "Epoch 322/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.2973 - accuracy: 0.9737 - val_loss: 4.4535 - val_accuracy: 0.9048\n",
            "Epoch 323/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 4.2467 - accuracy: 1.0000 - val_loss: 4.4711 - val_accuracy: 0.9048\n",
            "Epoch 324/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.3354 - accuracy: 0.9561 - val_loss: 4.4713 - val_accuracy: 0.9048\n",
            "Epoch 325/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 4.2513 - accuracy: 0.9912 - val_loss: 4.4609 - val_accuracy: 0.9048\n",
            "Epoch 326/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 4.2556 - accuracy: 0.9737 - val_loss: 4.4482 - val_accuracy: 0.9048\n",
            "Epoch 327/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.2448 - accuracy: 0.9825 - val_loss: 4.4373 - val_accuracy: 0.9048\n",
            "Epoch 328/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.2372 - accuracy: 0.9825 - val_loss: 4.3987 - val_accuracy: 0.9048\n",
            "Epoch 329/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.2411 - accuracy: 0.9825 - val_loss: 4.3644 - val_accuracy: 0.9048\n",
            "Epoch 330/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 4.2365 - accuracy: 0.9825 - val_loss: 4.3458 - val_accuracy: 0.9048\n",
            "Epoch 331/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.2209 - accuracy: 0.9825 - val_loss: 4.3513 - val_accuracy: 0.9048\n",
            "Epoch 332/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.2185 - accuracy: 0.9737 - val_loss: 4.3985 - val_accuracy: 0.9048\n",
            "Epoch 333/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 4.2031 - accuracy: 0.9825 - val_loss: 4.3904 - val_accuracy: 0.9048\n",
            "Epoch 334/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 4.2112 - accuracy: 0.9825 - val_loss: 4.3801 - val_accuracy: 0.9048\n",
            "Epoch 335/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.1982 - accuracy: 0.9737 - val_loss: 4.3606 - val_accuracy: 0.9048\n",
            "Epoch 336/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.1558 - accuracy: 0.9912 - val_loss: 4.3179 - val_accuracy: 0.9048\n",
            "Epoch 337/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.1631 - accuracy: 0.9912 - val_loss: 4.2968 - val_accuracy: 0.9048\n",
            "Epoch 338/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 4.1968 - accuracy: 0.9649 - val_loss: 4.2899 - val_accuracy: 0.9524\n",
            "Epoch 339/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 4.3187 - accuracy: 0.9386 - val_loss: 4.2867 - val_accuracy: 0.9048\n",
            "Epoch 340/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 4.1233 - accuracy: 0.9912 - val_loss: 4.3261 - val_accuracy: 0.9048\n",
            "Epoch 341/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 4.1563 - accuracy: 0.9737 - val_loss: 4.3170 - val_accuracy: 0.9048\n",
            "Epoch 342/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 4.1171 - accuracy: 0.9912 - val_loss: 4.3032 - val_accuracy: 0.9524\n",
            "Epoch 343/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.1109 - accuracy: 0.9912 - val_loss: 4.2939 - val_accuracy: 0.9524\n",
            "Epoch 344/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 4.1057 - accuracy: 0.9737 - val_loss: 4.2912 - val_accuracy: 0.9048\n",
            "Epoch 345/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 4.1107 - accuracy: 0.9825 - val_loss: 4.2451 - val_accuracy: 0.9048\n",
            "Epoch 346/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 4.0770 - accuracy: 0.9912 - val_loss: 4.2222 - val_accuracy: 0.9048\n",
            "Epoch 347/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 4.0564 - accuracy: 0.9912 - val_loss: 4.2166 - val_accuracy: 0.9048\n",
            "Epoch 348/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 4.0796 - accuracy: 0.9825 - val_loss: 4.2255 - val_accuracy: 0.9048\n",
            "Epoch 349/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 4.0545 - accuracy: 0.9912 - val_loss: 4.2541 - val_accuracy: 0.9048\n",
            "Epoch 350/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.0713 - accuracy: 0.9561 - val_loss: 4.2511 - val_accuracy: 0.9048\n",
            "Epoch 351/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.0495 - accuracy: 0.9912 - val_loss: 4.2494 - val_accuracy: 0.9048\n",
            "Epoch 352/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.0462 - accuracy: 0.9825 - val_loss: 4.2398 - val_accuracy: 0.9048\n",
            "Epoch 353/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 4.0499 - accuracy: 0.9737 - val_loss: 4.2237 - val_accuracy: 0.9048\n",
            "Epoch 354/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.0076 - accuracy: 1.0000 - val_loss: 4.2066 - val_accuracy: 0.9048\n",
            "Epoch 355/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.0203 - accuracy: 0.9912 - val_loss: 4.2059 - val_accuracy: 0.9048\n",
            "Epoch 356/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.9895 - accuracy: 0.9912 - val_loss: 4.2009 - val_accuracy: 0.9048\n",
            "Epoch 357/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.9846 - accuracy: 0.9912 - val_loss: 4.1905 - val_accuracy: 0.9048\n",
            "Epoch 358/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.9813 - accuracy: 0.9912 - val_loss: 4.1770 - val_accuracy: 0.9048\n",
            "Epoch 359/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.9722 - accuracy: 0.9825 - val_loss: 4.1604 - val_accuracy: 0.9048\n",
            "Epoch 360/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.9511 - accuracy: 1.0000 - val_loss: 4.1493 - val_accuracy: 0.9048\n",
            "Epoch 361/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.9673 - accuracy: 0.9825 - val_loss: 4.1545 - val_accuracy: 0.9048\n",
            "Epoch 362/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.9446 - accuracy: 0.9912 - val_loss: 4.1532 - val_accuracy: 0.9048\n",
            "Epoch 363/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.9772 - accuracy: 0.9737 - val_loss: 4.1496 - val_accuracy: 0.9048\n",
            "Epoch 364/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.9492 - accuracy: 0.9912 - val_loss: 4.1550 - val_accuracy: 0.9048\n",
            "Epoch 365/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.9357 - accuracy: 0.9825 - val_loss: 4.1510 - val_accuracy: 0.9048\n",
            "Epoch 366/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.9415 - accuracy: 0.9825 - val_loss: 4.1414 - val_accuracy: 0.9048\n",
            "Epoch 367/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.9081 - accuracy: 0.9912 - val_loss: 4.1297 - val_accuracy: 0.9048\n",
            "Epoch 368/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.9189 - accuracy: 0.9737 - val_loss: 4.1180 - val_accuracy: 0.9048\n",
            "Epoch 369/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.8829 - accuracy: 1.0000 - val_loss: 4.1092 - val_accuracy: 0.9048\n",
            "Epoch 370/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.8951 - accuracy: 0.9825 - val_loss: 4.1050 - val_accuracy: 0.9048\n",
            "Epoch 371/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.8814 - accuracy: 0.9912 - val_loss: 4.1001 - val_accuracy: 0.9048\n",
            "Epoch 372/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.8789 - accuracy: 0.9825 - val_loss: 4.0958 - val_accuracy: 0.9048\n",
            "Epoch 373/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.8772 - accuracy: 0.9825 - val_loss: 4.0859 - val_accuracy: 0.9048\n",
            "Epoch 374/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.8884 - accuracy: 0.9825 - val_loss: 4.0709 - val_accuracy: 0.9048\n",
            "Epoch 375/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.8379 - accuracy: 1.0000 - val_loss: 4.0609 - val_accuracy: 0.9048\n",
            "Epoch 376/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.8683 - accuracy: 0.9737 - val_loss: 4.0556 - val_accuracy: 0.9048\n",
            "Epoch 377/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.8286 - accuracy: 1.0000 - val_loss: 4.0529 - val_accuracy: 0.9048\n",
            "Epoch 378/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.8731 - accuracy: 0.9649 - val_loss: 4.0370 - val_accuracy: 0.9048\n",
            "Epoch 379/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.8353 - accuracy: 0.9825 - val_loss: 4.0205 - val_accuracy: 0.9048\n",
            "Epoch 380/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.8121 - accuracy: 0.9912 - val_loss: 4.0031 - val_accuracy: 0.9048\n",
            "Epoch 381/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.8199 - accuracy: 1.0000 - val_loss: 3.9974 - val_accuracy: 0.9048\n",
            "Epoch 382/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.8075 - accuracy: 0.9737 - val_loss: 3.9952 - val_accuracy: 0.9048\n",
            "Epoch 383/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.8153 - accuracy: 0.9737 - val_loss: 3.9930 - val_accuracy: 0.9048\n",
            "Epoch 384/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.7879 - accuracy: 0.9912 - val_loss: 3.9996 - val_accuracy: 0.9048\n",
            "Epoch 385/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.8366 - accuracy: 0.9649 - val_loss: 3.9930 - val_accuracy: 0.9048\n",
            "Epoch 386/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.7650 - accuracy: 0.9912 - val_loss: 3.9870 - val_accuracy: 0.9048\n",
            "Epoch 387/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.7488 - accuracy: 1.0000 - val_loss: 3.9845 - val_accuracy: 0.9048\n",
            "Epoch 388/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.7755 - accuracy: 0.9737 - val_loss: 3.9699 - val_accuracy: 0.9048\n",
            "Epoch 389/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.7531 - accuracy: 0.9912 - val_loss: 3.9578 - val_accuracy: 0.9048\n",
            "Epoch 390/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.7301 - accuracy: 1.0000 - val_loss: 3.9388 - val_accuracy: 0.9048\n",
            "Epoch 391/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.7601 - accuracy: 0.9825 - val_loss: 3.9355 - val_accuracy: 0.9048\n",
            "Epoch 392/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.7360 - accuracy: 0.9912 - val_loss: 3.9470 - val_accuracy: 0.9048\n",
            "Epoch 393/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.7162 - accuracy: 1.0000 - val_loss: 3.9421 - val_accuracy: 0.9048\n",
            "Epoch 394/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.7432 - accuracy: 0.9737 - val_loss: 3.9293 - val_accuracy: 0.9048\n",
            "Epoch 395/800\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 3.7335 - accuracy: 0.9825 - val_loss: 3.9074 - val_accuracy: 0.9048\n",
            "Epoch 396/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.7364 - accuracy: 0.9737 - val_loss: 3.8870 - val_accuracy: 0.9048\n",
            "Epoch 397/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.7377 - accuracy: 0.9737 - val_loss: 3.8966 - val_accuracy: 0.9048\n",
            "Epoch 398/800\n",
            "3/3 [==============================] - 0s 60ms/step - loss: 3.7012 - accuracy: 0.9912 - val_loss: 3.9039 - val_accuracy: 0.9048\n",
            "Epoch 399/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.6718 - accuracy: 1.0000 - val_loss: 3.8905 - val_accuracy: 0.9048\n",
            "Epoch 400/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.7071 - accuracy: 0.9649 - val_loss: 3.8879 - val_accuracy: 0.9048\n",
            "Epoch 401/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.7296 - accuracy: 0.9649 - val_loss: 3.8647 - val_accuracy: 0.9048\n",
            "Epoch 402/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.6477 - accuracy: 0.9912 - val_loss: 3.8251 - val_accuracy: 0.9048\n",
            "Epoch 403/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.6692 - accuracy: 0.9912 - val_loss: 3.8169 - val_accuracy: 0.9048\n",
            "Epoch 404/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.6540 - accuracy: 0.9825 - val_loss: 3.8091 - val_accuracy: 0.9048\n",
            "Epoch 405/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.6826 - accuracy: 0.9825 - val_loss: 3.8303 - val_accuracy: 0.9048\n",
            "Epoch 406/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.6306 - accuracy: 0.9912 - val_loss: 3.8357 - val_accuracy: 0.9048\n",
            "Epoch 407/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.6479 - accuracy: 0.9561 - val_loss: 3.8322 - val_accuracy: 0.9048\n",
            "Epoch 408/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.6070 - accuracy: 1.0000 - val_loss: 3.8403 - val_accuracy: 0.9048\n",
            "Epoch 409/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.6417 - accuracy: 0.9737 - val_loss: 3.8403 - val_accuracy: 0.9048\n",
            "Epoch 410/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.5903 - accuracy: 1.0000 - val_loss: 3.8290 - val_accuracy: 0.9048\n",
            "Epoch 411/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.6048 - accuracy: 0.9825 - val_loss: 3.8065 - val_accuracy: 0.9048\n",
            "Epoch 412/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.5886 - accuracy: 0.9825 - val_loss: 3.7821 - val_accuracy: 0.9048\n",
            "Epoch 413/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.5699 - accuracy: 1.0000 - val_loss: 3.7699 - val_accuracy: 0.9048\n",
            "Epoch 414/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.6088 - accuracy: 0.9649 - val_loss: 3.7718 - val_accuracy: 0.9048\n",
            "Epoch 415/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.5858 - accuracy: 0.9825 - val_loss: 3.7461 - val_accuracy: 0.9048\n",
            "Epoch 416/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.5700 - accuracy: 0.9737 - val_loss: 3.7369 - val_accuracy: 0.9048\n",
            "Epoch 417/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.5784 - accuracy: 0.9649 - val_loss: 3.7304 - val_accuracy: 0.9048\n",
            "Epoch 418/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.5583 - accuracy: 0.9825 - val_loss: 3.7284 - val_accuracy: 0.9048\n",
            "Epoch 419/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.5491 - accuracy: 0.9912 - val_loss: 3.7516 - val_accuracy: 0.9048\n",
            "Epoch 420/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.5452 - accuracy: 0.9912 - val_loss: 3.7606 - val_accuracy: 0.9048\n",
            "Epoch 421/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.5208 - accuracy: 1.0000 - val_loss: 3.7662 - val_accuracy: 0.9048\n",
            "Epoch 422/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.5500 - accuracy: 0.9737 - val_loss: 3.7558 - val_accuracy: 0.9048\n",
            "Epoch 423/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.5079 - accuracy: 1.0000 - val_loss: 3.7407 - val_accuracy: 0.9048\n",
            "Epoch 424/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.5033 - accuracy: 0.9912 - val_loss: 3.7264 - val_accuracy: 0.9048\n",
            "Epoch 425/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.5003 - accuracy: 0.9825 - val_loss: 3.7088 - val_accuracy: 0.9048\n",
            "Epoch 426/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.4835 - accuracy: 1.0000 - val_loss: 3.6890 - val_accuracy: 0.9048\n",
            "Epoch 427/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.4997 - accuracy: 0.9912 - val_loss: 3.6760 - val_accuracy: 0.9048\n",
            "Epoch 428/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.4926 - accuracy: 0.9912 - val_loss: 3.6766 - val_accuracy: 0.9048\n",
            "Epoch 429/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.4745 - accuracy: 0.9825 - val_loss: 3.6868 - val_accuracy: 0.9048\n",
            "Epoch 430/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.4795 - accuracy: 0.9825 - val_loss: 3.6962 - val_accuracy: 0.9048\n",
            "Epoch 431/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.4480 - accuracy: 1.0000 - val_loss: 3.6986 - val_accuracy: 0.9048\n",
            "Epoch 432/800\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.4744 - accuracy: 0.9737 - val_loss: 3.7063 - val_accuracy: 0.9048\n",
            "Epoch 433/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.5006 - accuracy: 0.9649 - val_loss: 3.7005 - val_accuracy: 0.9048\n",
            "Epoch 434/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.5012 - accuracy: 0.9737 - val_loss: 3.6891 - val_accuracy: 0.9048\n",
            "Epoch 435/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.4416 - accuracy: 0.9825 - val_loss: 3.6575 - val_accuracy: 0.9048\n",
            "Epoch 436/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.4627 - accuracy: 0.9737 - val_loss: 3.6336 - val_accuracy: 0.9048\n",
            "Epoch 437/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.4205 - accuracy: 1.0000 - val_loss: 3.6252 - val_accuracy: 0.9048\n",
            "Epoch 438/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.4162 - accuracy: 0.9912 - val_loss: 3.6191 - val_accuracy: 0.9048\n",
            "Epoch 439/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.4313 - accuracy: 0.9912 - val_loss: 3.6275 - val_accuracy: 0.9048\n",
            "Epoch 440/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.3964 - accuracy: 1.0000 - val_loss: 3.6476 - val_accuracy: 0.9048\n",
            "Epoch 441/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.4106 - accuracy: 0.9912 - val_loss: 3.6434 - val_accuracy: 0.9048\n",
            "Epoch 442/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.4364 - accuracy: 0.9649 - val_loss: 3.6351 - val_accuracy: 0.9048\n",
            "Epoch 443/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.3997 - accuracy: 0.9912 - val_loss: 3.6216 - val_accuracy: 0.9048\n",
            "Epoch 444/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.3887 - accuracy: 0.9912 - val_loss: 3.6101 - val_accuracy: 0.9048\n",
            "Epoch 445/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.3947 - accuracy: 0.9912 - val_loss: 3.6001 - val_accuracy: 0.9048\n",
            "Epoch 446/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.3728 - accuracy: 0.9912 - val_loss: 3.5956 - val_accuracy: 0.9048\n",
            "Epoch 447/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.4072 - accuracy: 0.9649 - val_loss: 3.5825 - val_accuracy: 0.9048\n",
            "Epoch 448/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.4085 - accuracy: 0.9649 - val_loss: 3.5699 - val_accuracy: 0.9048\n",
            "Epoch 449/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.3442 - accuracy: 0.9912 - val_loss: 3.5547 - val_accuracy: 0.9048\n",
            "Epoch 450/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.3486 - accuracy: 1.0000 - val_loss: 3.5392 - val_accuracy: 0.9048\n",
            "Epoch 451/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.3555 - accuracy: 0.9912 - val_loss: 3.5370 - val_accuracy: 0.9048\n",
            "Epoch 452/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.3458 - accuracy: 0.9825 - val_loss: 3.5454 - val_accuracy: 0.9048\n",
            "Epoch 453/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.3368 - accuracy: 0.9912 - val_loss: 3.5534 - val_accuracy: 0.9048\n",
            "Epoch 454/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.3241 - accuracy: 0.9912 - val_loss: 3.5444 - val_accuracy: 0.9048\n",
            "Epoch 455/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.3328 - accuracy: 0.9825 - val_loss: 3.5407 - val_accuracy: 0.9524\n",
            "Epoch 456/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.3045 - accuracy: 0.9912 - val_loss: 3.5343 - val_accuracy: 0.9524\n",
            "Epoch 457/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.3325 - accuracy: 0.9912 - val_loss: 3.5343 - val_accuracy: 0.9048\n",
            "Epoch 458/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.3005 - accuracy: 0.9912 - val_loss: 3.5326 - val_accuracy: 0.9048\n",
            "Epoch 459/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.3044 - accuracy: 0.9825 - val_loss: 3.5117 - val_accuracy: 0.9048\n",
            "Epoch 460/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.2830 - accuracy: 0.9912 - val_loss: 3.4770 - val_accuracy: 0.9048\n",
            "Epoch 461/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.3000 - accuracy: 0.9912 - val_loss: 3.4657 - val_accuracy: 0.9048\n",
            "Epoch 462/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.2856 - accuracy: 0.9912 - val_loss: 3.4822 - val_accuracy: 0.9048\n",
            "Epoch 463/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.3133 - accuracy: 0.9649 - val_loss: 3.5024 - val_accuracy: 0.9048\n",
            "Epoch 464/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.3023 - accuracy: 0.9825 - val_loss: 3.5142 - val_accuracy: 0.9048\n",
            "Epoch 465/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.2725 - accuracy: 0.9825 - val_loss: 3.5111 - val_accuracy: 0.9048\n",
            "Epoch 466/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.2633 - accuracy: 0.9825 - val_loss: 3.4973 - val_accuracy: 0.9048\n",
            "Epoch 467/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.2793 - accuracy: 0.9737 - val_loss: 3.4852 - val_accuracy: 0.9048\n",
            "Epoch 468/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.2320 - accuracy: 0.9912 - val_loss: 3.4801 - val_accuracy: 0.9048\n",
            "Epoch 469/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.2639 - accuracy: 0.9737 - val_loss: 3.4720 - val_accuracy: 0.9048\n",
            "Epoch 470/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.2113 - accuracy: 1.0000 - val_loss: 3.4675 - val_accuracy: 0.9048\n",
            "Epoch 471/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.2252 - accuracy: 0.9912 - val_loss: 3.4614 - val_accuracy: 0.9048\n",
            "Epoch 472/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.2388 - accuracy: 0.9825 - val_loss: 3.4455 - val_accuracy: 0.9048\n",
            "Epoch 473/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.2617 - accuracy: 0.9737 - val_loss: 3.4261 - val_accuracy: 0.9048\n",
            "Epoch 474/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.2295 - accuracy: 0.9825 - val_loss: 3.4145 - val_accuracy: 0.9048\n",
            "Epoch 475/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.2162 - accuracy: 0.9825 - val_loss: 3.4073 - val_accuracy: 0.9048\n",
            "Epoch 476/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.2049 - accuracy: 0.9737 - val_loss: 3.3968 - val_accuracy: 0.9048\n",
            "Epoch 477/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.1857 - accuracy: 0.9912 - val_loss: 3.3548 - val_accuracy: 0.9048\n",
            "Epoch 478/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.2010 - accuracy: 0.9737 - val_loss: 3.3518 - val_accuracy: 0.9524\n",
            "Epoch 479/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.1856 - accuracy: 0.9912 - val_loss: 3.3513 - val_accuracy: 0.9048\n",
            "Epoch 480/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.1673 - accuracy: 0.9912 - val_loss: 3.3550 - val_accuracy: 0.9048\n",
            "Epoch 481/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.1797 - accuracy: 0.9737 - val_loss: 3.3814 - val_accuracy: 0.9048\n",
            "Epoch 482/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.1883 - accuracy: 0.9737 - val_loss: 3.3965 - val_accuracy: 0.9048\n",
            "Epoch 483/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.1812 - accuracy: 0.9649 - val_loss: 3.4007 - val_accuracy: 0.9048\n",
            "Epoch 484/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.1649 - accuracy: 0.9825 - val_loss: 3.3944 - val_accuracy: 0.9048\n",
            "Epoch 485/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.1551 - accuracy: 0.9825 - val_loss: 3.3832 - val_accuracy: 0.9048\n",
            "Epoch 486/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.1721 - accuracy: 0.9825 - val_loss: 3.3660 - val_accuracy: 0.9048\n",
            "Epoch 487/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.1526 - accuracy: 0.9825 - val_loss: 3.3417 - val_accuracy: 0.9048\n",
            "Epoch 488/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.1287 - accuracy: 0.9825 - val_loss: 3.3309 - val_accuracy: 0.9048\n",
            "Epoch 489/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.1404 - accuracy: 0.9825 - val_loss: 3.3116 - val_accuracy: 0.9048\n",
            "Epoch 490/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.1815 - accuracy: 0.9649 - val_loss: 3.3056 - val_accuracy: 0.9048\n",
            "Epoch 491/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.1496 - accuracy: 0.9912 - val_loss: 3.3348 - val_accuracy: 0.9048\n",
            "Epoch 492/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.1141 - accuracy: 0.9912 - val_loss: 3.3342 - val_accuracy: 0.9048\n",
            "Epoch 493/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.0984 - accuracy: 0.9912 - val_loss: 3.3230 - val_accuracy: 0.9048\n",
            "Epoch 494/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.0922 - accuracy: 0.9912 - val_loss: 3.3159 - val_accuracy: 0.9048\n",
            "Epoch 495/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.1247 - accuracy: 0.9737 - val_loss: 3.3161 - val_accuracy: 0.9048\n",
            "Epoch 496/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.0852 - accuracy: 1.0000 - val_loss: 3.2877 - val_accuracy: 0.9048\n",
            "Epoch 497/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.1109 - accuracy: 0.9737 - val_loss: 3.2543 - val_accuracy: 0.9048\n",
            "Epoch 498/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.0745 - accuracy: 0.9912 - val_loss: 3.2450 - val_accuracy: 0.9524\n",
            "Epoch 499/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.1318 - accuracy: 0.9649 - val_loss: 3.2712 - val_accuracy: 0.9048\n",
            "Epoch 500/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.0828 - accuracy: 0.9825 - val_loss: 3.2955 - val_accuracy: 0.9048\n",
            "Epoch 501/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.0588 - accuracy: 0.9912 - val_loss: 3.2926 - val_accuracy: 0.9048\n",
            "Epoch 502/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.0697 - accuracy: 0.9649 - val_loss: 3.2856 - val_accuracy: 0.9048\n",
            "Epoch 503/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.0472 - accuracy: 1.0000 - val_loss: 3.2442 - val_accuracy: 0.9048\n",
            "Epoch 504/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.0526 - accuracy: 0.9912 - val_loss: 3.2267 - val_accuracy: 0.9048\n",
            "Epoch 505/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.0311 - accuracy: 0.9912 - val_loss: 3.2260 - val_accuracy: 0.9048\n",
            "Epoch 506/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.0579 - accuracy: 0.9912 - val_loss: 3.2334 - val_accuracy: 0.9048\n",
            "Epoch 507/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.0239 - accuracy: 1.0000 - val_loss: 3.2458 - val_accuracy: 0.9048\n",
            "Epoch 508/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.0597 - accuracy: 0.9825 - val_loss: 3.2650 - val_accuracy: 0.9048\n",
            "Epoch 509/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.0100 - accuracy: 0.9912 - val_loss: 3.2590 - val_accuracy: 0.9048\n",
            "Epoch 510/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.0566 - accuracy: 0.9561 - val_loss: 3.2565 - val_accuracy: 0.9048\n",
            "Epoch 511/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.0240 - accuracy: 0.9825 - val_loss: 3.2444 - val_accuracy: 0.9048\n",
            "Epoch 512/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.0165 - accuracy: 0.9825 - val_loss: 3.1921 - val_accuracy: 0.9048\n",
            "Epoch 513/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.0267 - accuracy: 0.9737 - val_loss: 3.1778 - val_accuracy: 0.9048\n",
            "Epoch 514/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.0142 - accuracy: 0.9825 - val_loss: 3.1656 - val_accuracy: 0.9524\n",
            "Epoch 515/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.0114 - accuracy: 0.9912 - val_loss: 3.1585 - val_accuracy: 0.9048\n",
            "Epoch 516/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.9865 - accuracy: 0.9825 - val_loss: 3.1571 - val_accuracy: 0.9048\n",
            "Epoch 517/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.0169 - accuracy: 0.9737 - val_loss: 3.1781 - val_accuracy: 0.9048\n",
            "Epoch 518/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.9697 - accuracy: 0.9912 - val_loss: 3.1783 - val_accuracy: 0.9048\n",
            "Epoch 519/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.0039 - accuracy: 0.9737 - val_loss: 3.1679 - val_accuracy: 0.9048\n",
            "Epoch 520/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.9596 - accuracy: 0.9912 - val_loss: 3.1602 - val_accuracy: 0.9048\n",
            "Epoch 521/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 2.9612 - accuracy: 0.9825 - val_loss: 3.1572 - val_accuracy: 0.9048\n",
            "Epoch 522/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.9486 - accuracy: 1.0000 - val_loss: 3.1606 - val_accuracy: 0.9048\n",
            "Epoch 523/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.9477 - accuracy: 0.9912 - val_loss: 3.1670 - val_accuracy: 0.9048\n",
            "Epoch 524/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.9599 - accuracy: 0.9737 - val_loss: 3.1591 - val_accuracy: 0.9048\n",
            "Epoch 525/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.9834 - accuracy: 0.9737 - val_loss: 3.1517 - val_accuracy: 0.9048\n",
            "Epoch 526/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.9457 - accuracy: 0.9912 - val_loss: 3.1529 - val_accuracy: 0.9048\n",
            "Epoch 527/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.9619 - accuracy: 0.9737 - val_loss: 3.1520 - val_accuracy: 0.9048\n",
            "Epoch 528/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.9397 - accuracy: 0.9912 - val_loss: 3.1420 - val_accuracy: 0.9048\n",
            "Epoch 529/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.9663 - accuracy: 0.9561 - val_loss: 3.1341 - val_accuracy: 0.9048\n",
            "Epoch 530/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.9095 - accuracy: 1.0000 - val_loss: 3.1336 - val_accuracy: 0.9048\n",
            "Epoch 531/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.9171 - accuracy: 0.9825 - val_loss: 3.1233 - val_accuracy: 0.9048\n",
            "Epoch 532/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.9485 - accuracy: 0.9737 - val_loss: 3.0969 - val_accuracy: 0.9048\n",
            "Epoch 533/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.9158 - accuracy: 0.9825 - val_loss: 3.0999 - val_accuracy: 0.9048\n",
            "Epoch 534/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.9067 - accuracy: 0.9825 - val_loss: 3.1076 - val_accuracy: 0.9048\n",
            "Epoch 535/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.9469 - accuracy: 0.9737 - val_loss: 3.1289 - val_accuracy: 0.9048\n",
            "Epoch 536/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.8807 - accuracy: 0.9912 - val_loss: 3.1213 - val_accuracy: 0.9048\n",
            "Epoch 537/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.9142 - accuracy: 0.9649 - val_loss: 3.1090 - val_accuracy: 0.9048\n",
            "Epoch 538/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.8789 - accuracy: 0.9912 - val_loss: 3.1082 - val_accuracy: 0.9048\n",
            "Epoch 539/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.8543 - accuracy: 1.0000 - val_loss: 3.1000 - val_accuracy: 0.9048\n",
            "Epoch 540/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.8836 - accuracy: 0.9737 - val_loss: 3.0898 - val_accuracy: 0.9048\n",
            "Epoch 541/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 2.8579 - accuracy: 0.9912 - val_loss: 3.0673 - val_accuracy: 0.9048\n",
            "Epoch 542/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 2.8816 - accuracy: 0.9825 - val_loss: 3.0465 - val_accuracy: 0.9048\n",
            "Epoch 543/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.8512 - accuracy: 0.9912 - val_loss: 3.0351 - val_accuracy: 0.9048\n",
            "Epoch 544/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.8681 - accuracy: 0.9825 - val_loss: 3.0278 - val_accuracy: 0.9524\n",
            "Epoch 545/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.8398 - accuracy: 0.9912 - val_loss: 3.0361 - val_accuracy: 0.9048\n",
            "Epoch 546/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.8243 - accuracy: 1.0000 - val_loss: 3.0596 - val_accuracy: 0.9048\n",
            "Epoch 547/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.8348 - accuracy: 0.9825 - val_loss: 3.0806 - val_accuracy: 0.9048\n",
            "Epoch 548/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.8376 - accuracy: 0.9912 - val_loss: 3.0957 - val_accuracy: 0.9048\n",
            "Epoch 549/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.8367 - accuracy: 0.9825 - val_loss: 3.0903 - val_accuracy: 0.9048\n",
            "Epoch 550/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.8543 - accuracy: 0.9649 - val_loss: 3.0847 - val_accuracy: 0.9048\n",
            "Epoch 551/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.8209 - accuracy: 0.9912 - val_loss: 3.0374 - val_accuracy: 0.9048\n",
            "Epoch 552/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.8392 - accuracy: 0.9737 - val_loss: 3.0063 - val_accuracy: 0.9048\n",
            "Epoch 553/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.8122 - accuracy: 0.9912 - val_loss: 3.0404 - val_accuracy: 0.9048\n",
            "Epoch 554/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.8097 - accuracy: 0.9912 - val_loss: 3.0639 - val_accuracy: 0.9048\n",
            "Epoch 555/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.8021 - accuracy: 0.9825 - val_loss: 3.0684 - val_accuracy: 0.9048\n",
            "Epoch 556/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.8008 - accuracy: 0.9912 - val_loss: 3.0644 - val_accuracy: 0.9048\n",
            "Epoch 557/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.8112 - accuracy: 0.9825 - val_loss: 3.0082 - val_accuracy: 0.9048\n",
            "Epoch 558/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.8049 - accuracy: 0.9825 - val_loss: 2.9839 - val_accuracy: 0.9048\n",
            "Epoch 559/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.8130 - accuracy: 0.9737 - val_loss: 2.9874 - val_accuracy: 0.9048\n",
            "Epoch 560/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.7784 - accuracy: 0.9912 - val_loss: 3.0302 - val_accuracy: 0.9048\n",
            "Epoch 561/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.7971 - accuracy: 0.9825 - val_loss: 3.0357 - val_accuracy: 0.9048\n",
            "Epoch 562/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 2.7899 - accuracy: 0.9825 - val_loss: 3.0196 - val_accuracy: 0.9048\n",
            "Epoch 563/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.8023 - accuracy: 0.9649 - val_loss: 3.0165 - val_accuracy: 0.9048\n",
            "Epoch 564/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.7772 - accuracy: 0.9825 - val_loss: 2.9529 - val_accuracy: 0.9048\n",
            "Epoch 565/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.7554 - accuracy: 1.0000 - val_loss: 2.9449 - val_accuracy: 0.9524\n",
            "Epoch 566/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.7945 - accuracy: 0.9912 - val_loss: 2.9651 - val_accuracy: 0.9048\n",
            "Epoch 567/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.7348 - accuracy: 1.0000 - val_loss: 2.9892 - val_accuracy: 0.9048\n",
            "Epoch 568/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.7485 - accuracy: 0.9912 - val_loss: 2.9824 - val_accuracy: 0.9048\n",
            "Epoch 569/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.7473 - accuracy: 0.9825 - val_loss: 2.9631 - val_accuracy: 0.9048\n",
            "Epoch 570/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.7350 - accuracy: 0.9825 - val_loss: 2.9472 - val_accuracy: 0.9048\n",
            "Epoch 571/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.7693 - accuracy: 0.9737 - val_loss: 2.9377 - val_accuracy: 0.9048\n",
            "Epoch 572/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.7472 - accuracy: 0.9912 - val_loss: 2.9357 - val_accuracy: 0.9048\n",
            "Epoch 573/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.7221 - accuracy: 0.9825 - val_loss: 2.9597 - val_accuracy: 0.9048\n",
            "Epoch 574/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.7197 - accuracy: 0.9912 - val_loss: 2.9648 - val_accuracy: 0.9048\n",
            "Epoch 575/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.7151 - accuracy: 0.9825 - val_loss: 2.9406 - val_accuracy: 0.9048\n",
            "Epoch 576/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.7208 - accuracy: 0.9825 - val_loss: 2.9356 - val_accuracy: 0.9048\n",
            "Epoch 577/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.7429 - accuracy: 0.9825 - val_loss: 2.9336 - val_accuracy: 0.9048\n",
            "Epoch 578/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.7199 - accuracy: 0.9737 - val_loss: 2.9159 - val_accuracy: 0.9048\n",
            "Epoch 579/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.7089 - accuracy: 0.9737 - val_loss: 2.9124 - val_accuracy: 0.9048\n",
            "Epoch 580/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.7399 - accuracy: 0.9825 - val_loss: 2.9357 - val_accuracy: 0.9048\n",
            "Epoch 581/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.7062 - accuracy: 0.9912 - val_loss: 2.9374 - val_accuracy: 0.9048\n",
            "Epoch 582/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.6976 - accuracy: 0.9825 - val_loss: 2.9273 - val_accuracy: 0.9048\n",
            "Epoch 583/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.6841 - accuracy: 0.9825 - val_loss: 2.8841 - val_accuracy: 0.9048\n",
            "Epoch 584/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.6960 - accuracy: 0.9737 - val_loss: 2.8596 - val_accuracy: 0.9048\n",
            "Epoch 585/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.7031 - accuracy: 0.9737 - val_loss: 2.8576 - val_accuracy: 0.9048\n",
            "Epoch 586/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.6774 - accuracy: 0.9912 - val_loss: 2.8593 - val_accuracy: 0.9048\n",
            "Epoch 587/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.6835 - accuracy: 0.9912 - val_loss: 2.8633 - val_accuracy: 0.9048\n",
            "Epoch 588/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.6792 - accuracy: 0.9825 - val_loss: 2.8625 - val_accuracy: 0.9048\n",
            "Epoch 589/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.6583 - accuracy: 0.9912 - val_loss: 2.8617 - val_accuracy: 0.9048\n",
            "Epoch 590/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.6478 - accuracy: 0.9912 - val_loss: 2.8650 - val_accuracy: 0.9048\n",
            "Epoch 591/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.6533 - accuracy: 0.9825 - val_loss: 2.8719 - val_accuracy: 0.9048\n",
            "Epoch 592/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.6475 - accuracy: 0.9825 - val_loss: 2.8747 - val_accuracy: 0.9048\n",
            "Epoch 593/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.6460 - accuracy: 0.9912 - val_loss: 2.8673 - val_accuracy: 0.9048\n",
            "Epoch 594/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.6373 - accuracy: 0.9912 - val_loss: 2.8479 - val_accuracy: 0.9048\n",
            "Epoch 595/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 2.6270 - accuracy: 0.9912 - val_loss: 2.8410 - val_accuracy: 0.9048\n",
            "Epoch 596/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.6742 - accuracy: 0.9737 - val_loss: 2.8642 - val_accuracy: 0.9048\n",
            "Epoch 597/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.6350 - accuracy: 0.9825 - val_loss: 2.8684 - val_accuracy: 0.9048\n",
            "Epoch 598/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.6456 - accuracy: 0.9825 - val_loss: 2.8646 - val_accuracy: 0.9048\n",
            "Epoch 599/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.6346 - accuracy: 0.9825 - val_loss: 2.8633 - val_accuracy: 0.9048\n",
            "Epoch 600/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.6195 - accuracy: 0.9825 - val_loss: 2.8475 - val_accuracy: 0.9048\n",
            "Epoch 601/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.6638 - accuracy: 0.9649 - val_loss: 2.8570 - val_accuracy: 0.9048\n",
            "Epoch 602/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.6370 - accuracy: 0.9825 - val_loss: 2.8419 - val_accuracy: 0.9048\n",
            "Epoch 603/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.6094 - accuracy: 0.9737 - val_loss: 2.8220 - val_accuracy: 0.9524\n",
            "Epoch 604/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.6226 - accuracy: 0.9649 - val_loss: 2.8155 - val_accuracy: 0.9048\n",
            "Epoch 605/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.6107 - accuracy: 0.9825 - val_loss: 2.7962 - val_accuracy: 0.9048\n",
            "Epoch 606/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 2.6094 - accuracy: 0.9737 - val_loss: 2.7761 - val_accuracy: 0.9048\n",
            "Epoch 607/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.6747 - accuracy: 0.9649 - val_loss: 2.7565 - val_accuracy: 0.9048\n",
            "Epoch 608/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.6093 - accuracy: 0.9649 - val_loss: 2.7837 - val_accuracy: 0.9048\n",
            "Epoch 609/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.5891 - accuracy: 0.9912 - val_loss: 2.7996 - val_accuracy: 0.9048\n",
            "Epoch 610/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 2.5591 - accuracy: 1.0000 - val_loss: 2.7964 - val_accuracy: 0.9048\n",
            "Epoch 611/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.6246 - accuracy: 0.9561 - val_loss: 2.7929 - val_accuracy: 0.9048\n",
            "Epoch 612/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.5650 - accuracy: 0.9912 - val_loss: 2.7791 - val_accuracy: 0.9048\n",
            "Epoch 613/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.5772 - accuracy: 0.9912 - val_loss: 2.7690 - val_accuracy: 0.9048\n",
            "Epoch 614/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.5456 - accuracy: 0.9912 - val_loss: 2.7561 - val_accuracy: 0.9048\n",
            "Epoch 615/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.5622 - accuracy: 0.9825 - val_loss: 2.7474 - val_accuracy: 0.9048\n",
            "Epoch 616/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.5713 - accuracy: 0.9825 - val_loss: 2.7438 - val_accuracy: 0.9048\n",
            "Epoch 617/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.5357 - accuracy: 1.0000 - val_loss: 2.7386 - val_accuracy: 0.9048\n",
            "Epoch 618/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.5434 - accuracy: 0.9825 - val_loss: 2.7312 - val_accuracy: 0.9048\n",
            "Epoch 619/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.5611 - accuracy: 0.9825 - val_loss: 2.7503 - val_accuracy: 0.9048\n",
            "Epoch 620/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.5230 - accuracy: 0.9912 - val_loss: 2.7536 - val_accuracy: 0.9048\n",
            "Epoch 621/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.5625 - accuracy: 0.9649 - val_loss: 2.7571 - val_accuracy: 0.9048\n",
            "Epoch 622/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.5547 - accuracy: 0.9737 - val_loss: 2.7575 - val_accuracy: 0.9048\n",
            "Epoch 623/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.5401 - accuracy: 0.9825 - val_loss: 2.7585 - val_accuracy: 0.9048\n",
            "Epoch 624/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.5307 - accuracy: 0.9825 - val_loss: 2.7405 - val_accuracy: 0.9048\n",
            "Epoch 625/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 2.5336 - accuracy: 0.9737 - val_loss: 2.7233 - val_accuracy: 0.9048\n",
            "Epoch 626/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.5160 - accuracy: 0.9912 - val_loss: 2.7208 - val_accuracy: 0.9048\n",
            "Epoch 627/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.5369 - accuracy: 0.9825 - val_loss: 2.7393 - val_accuracy: 0.9048\n",
            "Epoch 628/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 2.5232 - accuracy: 0.9912 - val_loss: 2.7444 - val_accuracy: 0.9048\n",
            "Epoch 629/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.5203 - accuracy: 0.9825 - val_loss: 2.7353 - val_accuracy: 0.9048\n",
            "Epoch 630/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.5223 - accuracy: 0.9737 - val_loss: 2.7159 - val_accuracy: 0.9048\n",
            "Epoch 631/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.5255 - accuracy: 0.9737 - val_loss: 2.6988 - val_accuracy: 0.9048\n",
            "Epoch 632/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.4935 - accuracy: 0.9825 - val_loss: 2.6943 - val_accuracy: 0.9048\n",
            "Epoch 633/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.5246 - accuracy: 0.9825 - val_loss: 2.6849 - val_accuracy: 0.9048\n",
            "Epoch 634/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.4948 - accuracy: 0.9825 - val_loss: 2.6776 - val_accuracy: 0.9048\n",
            "Epoch 635/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.5105 - accuracy: 0.9825 - val_loss: 2.6677 - val_accuracy: 0.9048\n",
            "Epoch 636/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.4955 - accuracy: 0.9825 - val_loss: 2.6710 - val_accuracy: 0.9048\n",
            "Epoch 637/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.5012 - accuracy: 0.9825 - val_loss: 2.6859 - val_accuracy: 0.9048\n",
            "Epoch 638/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.4925 - accuracy: 0.9825 - val_loss: 2.6874 - val_accuracy: 0.9048\n",
            "Epoch 639/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 2.5284 - accuracy: 0.9649 - val_loss: 2.6599 - val_accuracy: 0.9048\n",
            "Epoch 640/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.4689 - accuracy: 0.9737 - val_loss: 2.6451 - val_accuracy: 0.9048\n",
            "Epoch 641/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.4687 - accuracy: 0.9825 - val_loss: 2.6397 - val_accuracy: 0.9048\n",
            "Epoch 642/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.4668 - accuracy: 0.9912 - val_loss: 2.6473 - val_accuracy: 0.9048\n",
            "Epoch 643/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.4569 - accuracy: 0.9912 - val_loss: 2.6608 - val_accuracy: 0.9048\n",
            "Epoch 644/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.4655 - accuracy: 0.9649 - val_loss: 2.6540 - val_accuracy: 0.9048\n",
            "Epoch 645/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.4761 - accuracy: 0.9737 - val_loss: 2.6509 - val_accuracy: 0.9048\n",
            "Epoch 646/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.4672 - accuracy: 0.9825 - val_loss: 2.6525 - val_accuracy: 0.9048\n",
            "Epoch 647/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.4498 - accuracy: 0.9737 - val_loss: 2.6376 - val_accuracy: 0.9048\n",
            "Epoch 648/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.4383 - accuracy: 0.9912 - val_loss: 2.6141 - val_accuracy: 0.9048\n",
            "Epoch 649/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.4314 - accuracy: 0.9825 - val_loss: 2.6163 - val_accuracy: 0.9048\n",
            "Epoch 650/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.4563 - accuracy: 0.9912 - val_loss: 2.6231 - val_accuracy: 0.9048\n",
            "Epoch 651/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.4133 - accuracy: 0.9912 - val_loss: 2.6296 - val_accuracy: 0.9048\n",
            "Epoch 652/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.4712 - accuracy: 0.9737 - val_loss: 2.6275 - val_accuracy: 0.9048\n",
            "Epoch 653/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.4418 - accuracy: 0.9649 - val_loss: 2.6319 - val_accuracy: 0.9048\n",
            "Epoch 654/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.4130 - accuracy: 0.9912 - val_loss: 2.6440 - val_accuracy: 0.9048\n",
            "Epoch 655/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.4098 - accuracy: 1.0000 - val_loss: 2.6405 - val_accuracy: 0.9048\n",
            "Epoch 656/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.3881 - accuracy: 1.0000 - val_loss: 2.6318 - val_accuracy: 0.9048\n",
            "Epoch 657/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.3952 - accuracy: 1.0000 - val_loss: 2.6267 - val_accuracy: 0.9048\n",
            "Epoch 658/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.4241 - accuracy: 0.9825 - val_loss: 2.6261 - val_accuracy: 0.9048\n",
            "Epoch 659/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.3978 - accuracy: 0.9912 - val_loss: 2.6220 - val_accuracy: 0.9048\n",
            "Epoch 660/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.4008 - accuracy: 0.9825 - val_loss: 2.6008 - val_accuracy: 0.9048\n",
            "Epoch 661/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.3848 - accuracy: 0.9912 - val_loss: 2.5946 - val_accuracy: 0.9048\n",
            "Epoch 662/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.4229 - accuracy: 0.9825 - val_loss: 2.6145 - val_accuracy: 0.9048\n",
            "Epoch 663/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.3682 - accuracy: 0.9912 - val_loss: 2.6387 - val_accuracy: 0.9048\n",
            "Epoch 664/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.3776 - accuracy: 0.9912 - val_loss: 2.6297 - val_accuracy: 0.9048\n",
            "Epoch 665/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.3789 - accuracy: 0.9825 - val_loss: 2.6362 - val_accuracy: 0.9048\n",
            "Epoch 666/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.3794 - accuracy: 0.9825 - val_loss: 2.6323 - val_accuracy: 0.9048\n",
            "Epoch 667/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.3628 - accuracy: 1.0000 - val_loss: 2.5949 - val_accuracy: 0.9048\n",
            "Epoch 668/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 2.3532 - accuracy: 1.0000 - val_loss: 2.5655 - val_accuracy: 0.9048\n",
            "Epoch 669/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.3635 - accuracy: 0.9825 - val_loss: 2.5541 - val_accuracy: 0.9048\n",
            "Epoch 670/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.3516 - accuracy: 0.9912 - val_loss: 2.5448 - val_accuracy: 0.9048\n",
            "Epoch 671/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.3594 - accuracy: 0.9912 - val_loss: 2.5486 - val_accuracy: 0.9048\n",
            "Epoch 672/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.3710 - accuracy: 0.9825 - val_loss: 2.5572 - val_accuracy: 0.9048\n",
            "Epoch 673/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.3428 - accuracy: 0.9912 - val_loss: 2.5829 - val_accuracy: 0.9048\n",
            "Epoch 674/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.3527 - accuracy: 0.9825 - val_loss: 2.6125 - val_accuracy: 0.9048\n",
            "Epoch 675/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.3408 - accuracy: 1.0000 - val_loss: 2.6129 - val_accuracy: 0.9048\n",
            "Epoch 676/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.3989 - accuracy: 0.9649 - val_loss: 2.5752 - val_accuracy: 0.9048\n",
            "Epoch 677/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.3369 - accuracy: 0.9825 - val_loss: 2.5383 - val_accuracy: 0.9048\n",
            "Epoch 678/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.3520 - accuracy: 0.9825 - val_loss: 2.5378 - val_accuracy: 0.9048\n",
            "Epoch 679/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.3200 - accuracy: 0.9912 - val_loss: 2.5460 - val_accuracy: 0.9048\n",
            "Epoch 680/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.3334 - accuracy: 0.9825 - val_loss: 2.5516 - val_accuracy: 0.9048\n",
            "Epoch 681/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.3132 - accuracy: 1.0000 - val_loss: 2.5578 - val_accuracy: 0.9048\n",
            "Epoch 682/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.3188 - accuracy: 0.9912 - val_loss: 2.5613 - val_accuracy: 0.9048\n",
            "Epoch 683/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.3154 - accuracy: 0.9912 - val_loss: 2.5578 - val_accuracy: 0.9048\n",
            "Epoch 684/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.3324 - accuracy: 0.9825 - val_loss: 2.5443 - val_accuracy: 0.9048\n",
            "Epoch 685/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.3043 - accuracy: 1.0000 - val_loss: 2.5070 - val_accuracy: 0.9048\n",
            "Epoch 686/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.3066 - accuracy: 0.9825 - val_loss: 2.5029 - val_accuracy: 0.9048\n",
            "Epoch 687/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.3188 - accuracy: 0.9912 - val_loss: 2.5215 - val_accuracy: 0.9048\n",
            "Epoch 688/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.2992 - accuracy: 0.9825 - val_loss: 2.5441 - val_accuracy: 0.9048\n",
            "Epoch 689/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.3102 - accuracy: 0.9912 - val_loss: 2.5501 - val_accuracy: 0.9048\n",
            "Epoch 690/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.2954 - accuracy: 0.9825 - val_loss: 2.5395 - val_accuracy: 0.9048\n",
            "Epoch 691/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.3005 - accuracy: 0.9825 - val_loss: 2.5019 - val_accuracy: 0.9048\n",
            "Epoch 692/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.2857 - accuracy: 0.9912 - val_loss: 2.4890 - val_accuracy: 0.9048\n",
            "Epoch 693/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 2.3045 - accuracy: 0.9912 - val_loss: 2.4992 - val_accuracy: 0.9048\n",
            "Epoch 694/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.2719 - accuracy: 0.9912 - val_loss: 2.5298 - val_accuracy: 0.9048\n",
            "Epoch 695/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.2767 - accuracy: 0.9912 - val_loss: 2.5473 - val_accuracy: 0.9048\n",
            "Epoch 696/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.2980 - accuracy: 0.9737 - val_loss: 2.5414 - val_accuracy: 0.9048\n",
            "Epoch 697/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.2639 - accuracy: 1.0000 - val_loss: 2.5044 - val_accuracy: 0.9048\n",
            "Epoch 698/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.2627 - accuracy: 1.0000 - val_loss: 2.4737 - val_accuracy: 0.9048\n",
            "Epoch 699/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.2805 - accuracy: 0.9737 - val_loss: 2.4592 - val_accuracy: 0.9524\n",
            "Epoch 700/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.2750 - accuracy: 0.9825 - val_loss: 2.4572 - val_accuracy: 0.9048\n",
            "Epoch 701/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.2695 - accuracy: 0.9825 - val_loss: 2.4799 - val_accuracy: 0.9048\n",
            "Epoch 702/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.2612 - accuracy: 0.9912 - val_loss: 2.4983 - val_accuracy: 0.9048\n",
            "Epoch 703/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.2597 - accuracy: 0.9912 - val_loss: 2.4875 - val_accuracy: 0.9048\n",
            "Epoch 704/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.2595 - accuracy: 0.9825 - val_loss: 2.4959 - val_accuracy: 0.9048\n",
            "Epoch 705/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.2556 - accuracy: 0.9912 - val_loss: 2.4871 - val_accuracy: 0.9048\n",
            "Epoch 706/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.2435 - accuracy: 0.9912 - val_loss: 2.4839 - val_accuracy: 0.9048\n",
            "Epoch 707/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.2486 - accuracy: 0.9825 - val_loss: 2.4625 - val_accuracy: 0.9048\n",
            "Epoch 708/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.2596 - accuracy: 0.9912 - val_loss: 2.4430 - val_accuracy: 0.9048\n",
            "Epoch 709/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 2.2685 - accuracy: 0.9825 - val_loss: 2.4343 - val_accuracy: 0.9048\n",
            "Epoch 710/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.2331 - accuracy: 0.9912 - val_loss: 2.4538 - val_accuracy: 0.9048\n",
            "Epoch 711/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.2431 - accuracy: 0.9825 - val_loss: 2.4462 - val_accuracy: 0.9048\n",
            "Epoch 712/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.2438 - accuracy: 0.9825 - val_loss: 2.4413 - val_accuracy: 0.9048\n",
            "Epoch 713/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.2596 - accuracy: 0.9825 - val_loss: 2.4414 - val_accuracy: 0.9048\n",
            "Epoch 714/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 2.2266 - accuracy: 0.9825 - val_loss: 2.4398 - val_accuracy: 0.9048\n",
            "Epoch 715/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.2570 - accuracy: 0.9737 - val_loss: 2.4327 - val_accuracy: 0.9048\n",
            "Epoch 716/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.2203 - accuracy: 0.9912 - val_loss: 2.4268 - val_accuracy: 0.9048\n",
            "Epoch 717/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 2.2381 - accuracy: 0.9737 - val_loss: 2.4195 - val_accuracy: 0.9048\n",
            "Epoch 718/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.1972 - accuracy: 1.0000 - val_loss: 2.4206 - val_accuracy: 0.9048\n",
            "Epoch 719/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.2183 - accuracy: 0.9825 - val_loss: 2.4127 - val_accuracy: 0.9048\n",
            "Epoch 720/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.1899 - accuracy: 1.0000 - val_loss: 2.3960 - val_accuracy: 0.9048\n",
            "Epoch 721/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.2155 - accuracy: 0.9912 - val_loss: 2.3902 - val_accuracy: 0.9048\n",
            "Epoch 722/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.1992 - accuracy: 0.9825 - val_loss: 2.3976 - val_accuracy: 0.9048\n",
            "Epoch 723/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.1918 - accuracy: 0.9912 - val_loss: 2.4066 - val_accuracy: 0.9048\n",
            "Epoch 724/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.1883 - accuracy: 1.0000 - val_loss: 2.4024 - val_accuracy: 0.9048\n",
            "Epoch 725/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.2241 - accuracy: 0.9825 - val_loss: 2.4131 - val_accuracy: 0.9048\n",
            "Epoch 726/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 2.2020 - accuracy: 0.9737 - val_loss: 2.4160 - val_accuracy: 0.9048\n",
            "Epoch 727/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.2132 - accuracy: 0.9737 - val_loss: 2.4186 - val_accuracy: 0.9048\n",
            "Epoch 728/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.1881 - accuracy: 0.9912 - val_loss: 2.4237 - val_accuracy: 0.9048\n",
            "Epoch 729/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.1709 - accuracy: 1.0000 - val_loss: 2.4169 - val_accuracy: 0.9048\n",
            "Epoch 730/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.1715 - accuracy: 0.9912 - val_loss: 2.4093 - val_accuracy: 0.9048\n",
            "Epoch 731/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.1626 - accuracy: 0.9912 - val_loss: 2.4190 - val_accuracy: 0.9048\n",
            "Epoch 732/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.1711 - accuracy: 0.9912 - val_loss: 2.4220 - val_accuracy: 0.9048\n",
            "Epoch 733/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.2189 - accuracy: 0.9649 - val_loss: 2.4170 - val_accuracy: 0.9048\n",
            "Epoch 734/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.1971 - accuracy: 0.9737 - val_loss: 2.3966 - val_accuracy: 0.9048\n",
            "Epoch 735/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.1945 - accuracy: 0.9912 - val_loss: 2.3767 - val_accuracy: 0.9048\n",
            "Epoch 736/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.1538 - accuracy: 0.9912 - val_loss: 2.3738 - val_accuracy: 0.9048\n",
            "Epoch 737/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.1761 - accuracy: 0.9912 - val_loss: 2.3883 - val_accuracy: 0.9048\n",
            "Epoch 738/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.1511 - accuracy: 0.9825 - val_loss: 2.4213 - val_accuracy: 0.9048\n",
            "Epoch 739/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.1417 - accuracy: 0.9912 - val_loss: 2.4252 - val_accuracy: 0.9048\n",
            "Epoch 740/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.1466 - accuracy: 0.9912 - val_loss: 2.4211 - val_accuracy: 0.9048\n",
            "Epoch 741/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.1412 - accuracy: 1.0000 - val_loss: 2.4202 - val_accuracy: 0.9048\n",
            "Epoch 742/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.1300 - accuracy: 1.0000 - val_loss: 2.3973 - val_accuracy: 0.9048\n",
            "Epoch 743/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.1505 - accuracy: 0.9912 - val_loss: 2.3844 - val_accuracy: 0.9048\n",
            "Epoch 744/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.1398 - accuracy: 0.9825 - val_loss: 2.3720 - val_accuracy: 0.9048\n",
            "Epoch 745/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.1576 - accuracy: 0.9737 - val_loss: 2.3556 - val_accuracy: 0.9048\n",
            "Epoch 746/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.1224 - accuracy: 1.0000 - val_loss: 2.3661 - val_accuracy: 0.9048\n",
            "Epoch 747/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.1146 - accuracy: 0.9912 - val_loss: 2.3675 - val_accuracy: 0.9048\n",
            "Epoch 748/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.1425 - accuracy: 0.9912 - val_loss: 2.3401 - val_accuracy: 0.9048\n",
            "Epoch 749/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.1404 - accuracy: 0.9825 - val_loss: 2.3147 - val_accuracy: 0.9048\n",
            "Epoch 750/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.1705 - accuracy: 0.9737 - val_loss: 2.3036 - val_accuracy: 0.9524\n",
            "Epoch 751/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.1409 - accuracy: 0.9737 - val_loss: 2.3027 - val_accuracy: 0.9048\n",
            "Epoch 752/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.1181 - accuracy: 0.9912 - val_loss: 2.3168 - val_accuracy: 0.9048\n",
            "Epoch 753/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.1657 - accuracy: 0.9474 - val_loss: 2.3516 - val_accuracy: 0.9048\n",
            "Epoch 754/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.2024 - accuracy: 0.9474 - val_loss: 2.3620 - val_accuracy: 0.9048\n",
            "Epoch 755/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 2.1180 - accuracy: 0.9737 - val_loss: 2.3265 - val_accuracy: 0.9048\n",
            "Epoch 756/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.1018 - accuracy: 0.9912 - val_loss: 2.3116 - val_accuracy: 0.9048\n",
            "Epoch 757/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.1187 - accuracy: 0.9825 - val_loss: 2.3493 - val_accuracy: 0.9048\n",
            "Epoch 758/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.1514 - accuracy: 0.9737 - val_loss: 2.3705 - val_accuracy: 0.9048\n",
            "Epoch 759/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.0858 - accuracy: 1.0000 - val_loss: 2.3718 - val_accuracy: 0.9048\n",
            "Epoch 760/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.1144 - accuracy: 0.9825 - val_loss: 2.3708 - val_accuracy: 0.9048\n",
            "Epoch 761/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.0971 - accuracy: 0.9825 - val_loss: 2.3344 - val_accuracy: 0.9048\n",
            "Epoch 762/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.0930 - accuracy: 0.9825 - val_loss: 2.3063 - val_accuracy: 0.9048\n",
            "Epoch 763/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.0754 - accuracy: 1.0000 - val_loss: 2.3127 - val_accuracy: 0.9048\n",
            "Epoch 764/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.0736 - accuracy: 1.0000 - val_loss: 2.3268 - val_accuracy: 0.9048\n",
            "Epoch 765/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 2.0871 - accuracy: 0.9825 - val_loss: 2.3583 - val_accuracy: 0.9048\n",
            "Epoch 766/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.0982 - accuracy: 0.9825 - val_loss: 2.3665 - val_accuracy: 0.9048\n",
            "Epoch 767/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.0874 - accuracy: 0.9737 - val_loss: 2.3683 - val_accuracy: 0.9048\n",
            "Epoch 768/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.0903 - accuracy: 0.9912 - val_loss: 2.3593 - val_accuracy: 0.9048\n",
            "Epoch 769/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.0887 - accuracy: 0.9825 - val_loss: 2.3302 - val_accuracy: 0.9048\n",
            "Epoch 770/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.0741 - accuracy: 0.9825 - val_loss: 2.2866 - val_accuracy: 0.9048\n",
            "Epoch 771/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.0698 - accuracy: 0.9825 - val_loss: 2.2863 - val_accuracy: 0.9048\n",
            "Epoch 772/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.0794 - accuracy: 0.9825 - val_loss: 2.2918 - val_accuracy: 0.9048\n",
            "Epoch 773/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.0554 - accuracy: 1.0000 - val_loss: 2.2848 - val_accuracy: 0.9048\n",
            "Epoch 774/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.0659 - accuracy: 0.9737 - val_loss: 2.2927 - val_accuracy: 0.9048\n",
            "Epoch 775/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.0907 - accuracy: 0.9737 - val_loss: 2.2698 - val_accuracy: 0.9048\n",
            "Epoch 776/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.0380 - accuracy: 1.0000 - val_loss: 2.2555 - val_accuracy: 0.9048\n",
            "Epoch 777/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.0825 - accuracy: 0.9737 - val_loss: 2.2517 - val_accuracy: 0.9524\n",
            "Epoch 778/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.0598 - accuracy: 0.9912 - val_loss: 2.2477 - val_accuracy: 0.9524\n",
            "Epoch 779/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.0871 - accuracy: 0.9825 - val_loss: 2.2535 - val_accuracy: 0.9048\n",
            "Epoch 780/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 2.0644 - accuracy: 0.9737 - val_loss: 2.2694 - val_accuracy: 0.9048\n",
            "Epoch 781/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.0494 - accuracy: 0.9912 - val_loss: 2.2839 - val_accuracy: 0.9048\n",
            "Epoch 782/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.0278 - accuracy: 1.0000 - val_loss: 2.2971 - val_accuracy: 0.9048\n",
            "Epoch 783/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.0318 - accuracy: 0.9912 - val_loss: 2.3046 - val_accuracy: 0.9048\n",
            "Epoch 784/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 2.0322 - accuracy: 1.0000 - val_loss: 2.2896 - val_accuracy: 0.9048\n",
            "Epoch 785/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.0414 - accuracy: 0.9825 - val_loss: 2.2778 - val_accuracy: 0.9048\n",
            "Epoch 786/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.0463 - accuracy: 0.9825 - val_loss: 2.2755 - val_accuracy: 0.9048\n",
            "Epoch 787/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.0265 - accuracy: 0.9912 - val_loss: 2.2714 - val_accuracy: 0.9048\n",
            "Epoch 788/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.0510 - accuracy: 0.9825 - val_loss: 2.2521 - val_accuracy: 0.9048\n",
            "Epoch 789/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.0127 - accuracy: 1.0000 - val_loss: 2.2309 - val_accuracy: 0.9048\n",
            "Epoch 790/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.0132 - accuracy: 0.9912 - val_loss: 2.2316 - val_accuracy: 0.9048\n",
            "Epoch 791/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.0214 - accuracy: 0.9912 - val_loss: 2.2424 - val_accuracy: 0.9048\n",
            "Epoch 792/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.0075 - accuracy: 1.0000 - val_loss: 2.2608 - val_accuracy: 0.9048\n",
            "Epoch 793/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.0254 - accuracy: 0.9912 - val_loss: 2.2592 - val_accuracy: 0.9048\n",
            "Epoch 794/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.0216 - accuracy: 0.9912 - val_loss: 2.2230 - val_accuracy: 0.9048\n",
            "Epoch 795/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.0038 - accuracy: 0.9912 - val_loss: 2.2028 - val_accuracy: 0.9524\n",
            "Epoch 796/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.0038 - accuracy: 0.9912 - val_loss: 2.2012 - val_accuracy: 0.9524\n",
            "Epoch 797/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.0209 - accuracy: 0.9825 - val_loss: 2.2164 - val_accuracy: 0.9048\n",
            "Epoch 798/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.0002 - accuracy: 0.9912 - val_loss: 2.2367 - val_accuracy: 0.9048\n",
            "Epoch 799/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.9849 - accuracy: 1.0000 - val_loss: 2.2385 - val_accuracy: 0.9048\n",
            "Epoch 800/800\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 1.9930 - accuracy: 0.9912 - val_loss: 2.2403 - val_accuracy: 0.9048\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gccWcGCz-QO8",
        "colab_type": "text"
      },
      "source": [
        "#### Plot the learning curves\n",
        "\n",
        "Let's now plot the loss and accuracy for the training and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8uieP3K-QO9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "9a9dcc06-9418-43e2-acf2-f6fefb16c4f5"
      },
      "source": [
        "#Run this cell to plot the new accuracy vs epoch graph\n",
        "\n",
        "try:\n",
        "    plt.plot(reg_history.history['accuracy'])\n",
        "    plt.plot(reg_history.history['val_accuracy'])\n",
        "except KeyError:\n",
        "    plt.plot(reg_history.history['acc'])\n",
        "    plt.plot(reg_history.history['val_acc'])\n",
        "plt.title('Accuracy vs. epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='lower right')\n",
        "plt.show() "
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpgy4mVP-QO_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "69336a75-a175-4c52-f750-2b33eba992bf"
      },
      "source": [
        "#Run this cell to plot the new loss vs epoch graph\n",
        "\n",
        "plt.plot(reg_history.history['loss'])\n",
        "plt.plot(reg_history.history['val_loss'])\n",
        "plt.title('Loss vs. epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper right')\n",
        "plt.show() "
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "na0xiTpm-QPB",
        "colab_type": "text"
      },
      "source": [
        "We can see that the regularisation has helped to reduce the overfitting of the network.\n",
        "You will now incorporate callbacks into a new training run that implements early stopping and learning rate reduction on plateaux.\n",
        "\n",
        "Fill in the function below so that:\n",
        "\n",
        "* It creates an `EarlyStopping` callback object and a `ReduceLROnPlateau` callback object\n",
        "* The early stopping callback is used and monitors validation loss with the mode set to `\"min\"` and patience of 30.\n",
        "* The learning rate reduction on plateaux is used with a learning rate factor of 0.2 and a patience of 20."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18JaoKcd-QPC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### GRADED CELL ####\n",
        "\n",
        "# Complete the following function. \n",
        "# Make sure to not change the function name or arguments.\n",
        "\n",
        "def get_callbacks():\n",
        "    \"\"\"\n",
        "    This function should create and return a tuple (early_stopping, learning_rate_reduction) callbacks.\n",
        "    The callbacks should be instantiated according to the above requirements.\n",
        "    \"\"\"\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', mode = 'min', patience = 30)\n",
        "    learning_rate_reduction = tf.keras.callbacks.ReduceLROnPlateau(factor = 0.2, patience = 20)\n",
        "    return (early_stopping, learning_rate_reduction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqi6pF-v-QPD",
        "colab_type": "text"
      },
      "source": [
        "Run the cell below to instantiate and train the regularised model with the callbacks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emW-CYSd-QPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "call_model = get_regularised_model(train_data[0].shape, 0.3, 0.0001)\n",
        "compile_model(call_model)\n",
        "early_stopping, learning_rate_reduction = get_callbacks()\n",
        "call_history = call_model.fit(train_data, train_targets, epochs=800, validation_split=0.15,\n",
        "                         callbacks=[early_stopping, learning_rate_reduction], verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtuDazML-QPG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "231c099c-d451-44df-b454-a74ba94905f2"
      },
      "source": [
        "learning_rate_reduction.patience"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zhsqvtL-QPJ",
        "colab_type": "text"
      },
      "source": [
        "Finally, let's replot the accuracy and loss graphs for our new model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOPSJT7w-QPJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "e0b56183-c2a9-420e-ab94-21d18720acd4"
      },
      "source": [
        "try:\n",
        "    plt.plot(call_history.history['accuracy'])\n",
        "    plt.plot(call_history.history['val_accuracy'])\n",
        "except KeyError:\n",
        "    plt.plot(call_history.history['acc'])\n",
        "    plt.plot(call_history.history['val_acc'])\n",
        "plt.title('Accuracy vs. epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='lower right')\n",
        "plt.show() "
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w5NOgER-QPL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "501476f8-05c8-4919-823e-2bbba82a4455"
      },
      "source": [
        "plt.plot(call_history.history['loss'])\n",
        "plt.plot(call_history.history['val_loss'])\n",
        "plt.title('Loss vs. epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper right')\n",
        "plt.show() "
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsBmI_qM5CYh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9448e6ff-7abf-4edc-ed8d-11b52f0720cd"
      },
      "source": [
        "# Evaluate the model on the test set\n",
        "\n",
        "test_loss, test_acc = call_model.evaluate(test_data, test_targets, verbose=0)\n",
        "print(\"Test loss: {:.3f}\\nTest accuracy: {:.2f}%\".format(test_loss, 100 * test_acc))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 1.712\n",
            "Test accuracy: 100.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqBMocM0-QPM",
        "colab_type": "text"
      },
      "source": [
        "Congratulations for completing this programming assignment! In the next week of the course we will learn how to save and load pre-trained models."
      ]
    }
  ]
}